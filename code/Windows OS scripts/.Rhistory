}
# Calculate overall average ROH hotspot threshold for each selection coefficient
for (selection_coefficient in names(ROH_freq_tables_Selection_Model)) {
all_thresholds <- unlist(lapply(ROH_freq_tables_Selection_Model[[selection_coefficient]], function(table) table$ROH_Hotspot_threshold))
overall_avg_threshold <- mean(all_thresholds)
ROH_freq_tables_Selection_Model[[selection_coefficient]]$Avg_ROH_hotspot_threshold <- overall_avg_threshold
# Calculate the confidence interval of the point estimate ROH-hotspot threshold across all technical replicates simulations
ROH_freq_tables_Selection_Model[[selection_coefficient]]$SE_CI_ROH_hotspot_threshold <- standard_error_confidence_interval_fun(all_thresholds)
}
# View the resulting nested structure
#View(ROH_freq_tables_Selection_Model)
# cat("ROH-hotspot selection testing results://n")
# Initialize an empty vector to store F_ROH values for the different selection coefficients
selection_model_values_list <- c()
selection_model_names_list <- c()
selection_model_lower_ci <- c()
selection_model_upper_ci <- c()
# Loop through each selection_coefficient in ROH_freq_tables_Selection_Model
for (selection_coefficient in names(ROH_freq_tables_Selection_Model)) {
# Extract the Avg_ROH_hotspot_threshold value from the selection_coefficient
Avg_ROH_hotspot_threshold <- round(100*ROH_freq_tables_Selection_Model[[selection_coefficient]]$Avg_ROH_hotspot_threshold,ROH_frequency_decimals)
CI <- ROH_freq_tables_Selection_Model[[selection_coefficient]]$SE_CI_ROH_hotspot_threshold
# Formatting the selection coefficient for when displaying it. Removing "chr[0-9]" and adding a decimal point to the selection coefficient
formatted_selection_coefficient_labels <- sub(tolower("^.*_s(0?)(\\d+)_chr\\d+$"), tolower("s=\\1.\\2"), tolower(selection_coefficient))
# Append values to the lists
selection_model_values_list <- c(selection_model_values_list, Avg_ROH_hotspot_threshold)
selection_model_lower_ci <- c(selection_model_lower_ci, 100*CI[1])
selection_model_upper_ci <- c(selection_model_upper_ci, 100*CI[2])
selection_model_names_list <- c(selection_model_names_list, formatted_selection_coefficient_labels)
}
# Add overAvg_ROH_hotspot_threshold from ROH_freq_tables_Neutral_Model
neutral_model_value <- round(100*ROH_freq_tables_Neutral_Model[["Avg_ROH_hotspot_threshold"]],ROH_frequency_decimals)
# neutral_lower_ci <- round(100*ROH_freq_tables_Neutral_Model$SE_CI_ROH_hotspot_threshold[1],ROH_frequency_decimals)
neutral_lower_ci <- round(100*ROH_freq_tables_Neutral_Model[["SE_CI_ROH_hotspot_threshold"]][1],ROH_frequency_decimals)
neutral_upper_ci <- round(100*ROH_freq_tables_Neutral_Model[["SE_CI_ROH_hotspot_threshold"]][2],ROH_frequency_decimals)
# Add Avg_ROH_hotspot_threshold from ROH_freq_table_Empirical_Data
empirical_model_value <- round(100*ROH_freq_table_Empirical_Data[["ROH_hotspot_threshold"]],ROH_frequency_decimals)
empirical_lower_ci <- NA # Placeholder for confidence interval lower bound
empirical_upper_ci <- NA # Placeholder for confidence interval upper bound
# Combine all values into a data frame
ROH_hotspot_threshold_values <- data.frame(
Model = c(rep("Selection", length(selection_model_values_list)), "Neutral", "Empirical"),
Avg_ROH_hotspot_threshold = c(selection_model_values_list, neutral_model_value, empirical_model_value),
Lower_CI = c(selection_model_lower_ci, neutral_lower_ci, empirical_lower_ci),
Upper_CI = c(selection_model_upper_ci, neutral_upper_ci, empirical_upper_ci)
)
# FOrmatting the confidence interval values
ROH_hotspot_threshold_values$Lower_CI <- round(ROH_hotspot_threshold_values$Lower_CI,ROH_frequency_decimals)
ROH_hotspot_threshold_values$Upper_CI <- round(ROH_hotspot_threshold_values$Upper_CI,ROH_frequency_decimals)
# Update the Model column for selection models
ROH_hotspot_threshold_values$Model[ROH_hotspot_threshold_values$Model == "Selection"] <- selection_model_names_list
# Sort the data frame based on the ROH-hotspot threshold
ROH_hotspot_threshold_values_sorted <- ROH_hotspot_threshold_values[order(ROH_hotspot_threshold_values$Avg_ROH_hotspot_threshold), ]
# Define the filename with the output directory path
filename <- file.path(output_dir, paste("ROH-hotspot_threshold_comparison",".csv", sep = ""))
# Write data to CSV file without quotes
write.table(ROH_hotspot_threshold_values_sorted, file = filename, sep = ",", row.names = FALSE, quote = FALSE)
# Use the write_latex_table() function to write the data to a LaTeX-compatible text file
write_latex_table(
data_frame = ROH_hotspot_threshold_values,
sort_column = "Avg_ROH_hotspot_threshold",
output_dir = output_dir,
output_filename = "ROH-hotspot_threshold_comparison"  # File name without extension
)
# Print the table using knitr::kable()
knitr::kable(ROH_hotspot_threshold_values_sorted, row.names = FALSE)
# setwd(Empirical_data_ROH_hotspots_dir)
# Pattern for finding files containing "F_ROH" and ending with ".tsv"
pattern <- "^.*ROH_Hotspot_windows*.bed$"
empirical_roh_hotspot_bed_files <- list.files(path = Empirical_data_ROH_hotspots_dir, pattern = pattern)
# chromosome_number_pattern <- "^german_shepherd_CHR(\\d+)_.*"
chromosome_number_pattern <- paste0("^",empirical_breed,"_chr(\\d+)_.*")
# Extract chromosome numbers
chr_numbers <- sub(tolower(chromosome_number_pattern), "\\1", tolower(empirical_roh_hotspot_bed_files))
# Sort the files based on chromosome numbers
empirical_roh_hotspot_bed_files <- empirical_roh_hotspot_bed_files[order(as.numeric(chr_numbers))]
# Create an empty list to store information for the different ROH-hotspots in
empirical_hotspot_tables <- list()
# Loop through each .bed file (ROH-hotspot allele frequency window-file)
for (file in empirical_roh_hotspot_bed_files) {
file_path <- file.path(Empirical_data_ROH_hotspots_dir,file)
# Extract chromosome number and window number from file name
chromosome <- as.numeric(sub(tolower(chromosome_number_pattern), "\\1", tolower(file)))
column_names <- c("CHR","POS1","POS2")
# Read the .bed file into a data frame, skipping commented lines
chromosome_bed_file_data <- read.table(file_path, header = FALSE, comment.char = "#", stringsAsFactors = FALSE, col.names = column_names)
# Loop through each hotspot for the current chromosome
for (i in 1:nrow(chromosome_bed_file_data)) {
Hotspot_region_data <- data.frame(CHR = chromosome_bed_file_data[i, ][1],POS1 = chromosome_bed_file_data[i, ][2],POS2 = chromosome_bed_file_data[i, ][3])
Hotspot_length_bp <- Hotspot_region_data$POS2-Hotspot_region_data$POS1 + 1
Hotspot_length_Mb <- Hotspot_length_bp / 1e6
Hotspot_name <- paste("Hotspot_chr",chromosome, "_window_",i, sep = "")
# Find the row where the variant_position_bp is within POS1 and POS2, and CHR equals chr_number
roh_freq_windows_in_hotspot <- ROH_freq_table_Empirical_Data[[chromosome]][["data"]][ Hotspot_region_data$POS1 <= ROH_freq_table_Empirical_Data[[chromosome]][["data"]]$POS1 & ROH_freq_table_Empirical_Data[[chromosome]][["data"]]$POS2 <= Hotspot_region_data$POS2, ]
avg_frequency <- mean(roh_freq_windows_in_hotspot$FREQUENCY)
# Check if the selection coefficient already exists in the list
if (!(Hotspot_name %in% names(empirical_hotspot_tables))) {
# If it doesn't exist, create an empty data frame
empirical_hotspot_tables[[Hotspot_name]] <- data.frame()
}
# Create a list with table name and corresponding data frame
table_info <- list(Filename = file,Hotspot_length_bp=Hotspot_length_bp,Hotspot_length_Mb=Hotspot_length_Mb,Avg_frequency = avg_frequency, Hotspot_region_data = Hotspot_region_data)
# Append the table info to the list under selection_scenario
empirical_hotspot_tables[[Hotspot_name]] <- c(empirical_hotspot_tables[[Hotspot_name]], table_info)
}
}
# View(empirical_hotspot_tables)
# setwd(Empirical_data_H_e_dir)
# Pattern for finding the specific file containing "5th_percentiles_of_H_e_distribution.tsv"
pattern <- "^.*H_e_distribution_.*.tsv$"
empirical_H_e_distribution_file <- list.files(path = Empirical_data_H_e_dir, pattern = pattern)
# Check if exactly one file is found
if (length(empirical_H_e_distribution_file) != 1) {
stop("There should be exactly one file matching the pattern.")
}
# Read the file
file <- empirical_H_e_distribution_file[1]
file_path <- file.path(Empirical_data_H_e_dir,file)
# Read the .tsv file into a data frame
empirical_H_e_distribution_table <- read.table(file_path, header = TRUE, sep = "\t", stringsAsFactors = FALSE)
# View(empirical_H_e_distribution_table)
# # Set the working directory to the directory containing the H_e files for the empirical data
# setwd(Empirical_data_H_e_dir)
#
# # List all PNG files in the directory
# # png_files <- list.files(pattern = "//.png$", full.names = TRUE)
# png_files <- list.files(pattern = "//.png$")
#
# # Display each PNG file
# for (file in png_files) {
#   cat("File:", file, "/n")
#   # Open a PNG device
#   png::png(filename = file)
#   # Display image using readPNG() from the png package
#   raster <- png::readPNG(file)
#   graphics::plot.new()
#   graphics::plot.window(xlim = c(0, 1), ylim = c(0, 1), asp = 1)
#   graphics::rasterImage(raster, 0, 0, 1, 1)
#   # Close the PNG device
#   dev.off()
# }
#
# setwd(Neutral_model_H_e_dir)
# Pattern for finding the specific file containing "5th_percentiles_of_H_e_distribution.tsv"
pattern <- "^.*5th_percentiles_of_H_e_distribution.tsv$"
neutral_model_5th_percentiles_of_H_e_files <- list.files(path = Neutral_model_H_e_dir, pattern = pattern)
# Check if exactly one file is found
if (length(neutral_model_5th_percentiles_of_H_e_files) != 1) {
stop("There should be exactly one file matching the pattern.")
}
# Read the file
file <- neutral_model_5th_percentiles_of_H_e_files[1]
file_path <- file.path(Neutral_model_H_e_dir,file)
# Read the .tsv file into a data frame
data <- read.table(file_path, header = TRUE, sep = "\t", stringsAsFactors = FALSE)
# Store the data frame in a list as a subtable called "data"
H_e_5th_percentiles_Neutral_model <- list(results = data)
H_e_5th_percentiles_Neutral_model$Estimated_Mean_H_e_5th_percentile <- mean(H_e_5th_percentiles_Neutral_model[["results"]][["Fifth_Percentile"]])
# Calculate the Standard Error confidence interval of the point estimate F_ROH across all technical replicates simulations
# Store the Standard Error confidence interval in the F_ROH_tables_Neutral_Model
H_e_5th_percentiles_Neutral_model$SE_CI_Estimated_Mean_H_e_5th_percentile <- standard_error_confidence_interval_fun(H_e_5th_percentiles_Neutral_model[["results"]][["Fifth_Percentile"]])
#View(H_e_5th_percentiles_Neutral_model)
# setwd(Neutral_model_H_e_dir)
# # Set the working directory to the directory containing the H_e files for the Neutral Model
# new_dir <- file.path(Neutral_model_H_e_dir,"test")
# #setwd(Neutral_model_H_e_dir)
# setwd(new_dir)
# # List all PNG files in the directory
# #png_files <- list.files(pattern = "//.png$", full.names = TRUE)
# png_files <- list.files(pattern = "//.png$")
#
# library(png)
#
#
# # Display each PNG file
# for (file in png_files) {
#   file_path <- file.path(new_dir, file)
#   cat("File:", file, "/n")
#   # Display the image using include_graphics() from the knitr package
#   knitr::include_graphics(file_path)
# }
#
# knitr::include_graphics("img",/rmarkdown_hex.png")
# # Display each PNG file
# for (file in png_files) {
#   cat("File:", file, "/n")
#   file_path <- file.path(Neutral_model_H_e_dir,file)
#   # Open a PNG device
#   png(filename = file_path)
#   # Display image using base R graphics functions
#   img <- readPNG(file)
#   graphics::plot.new()
#   graphics::plot.window(xlim = c(0, 1), ylim = c(0, 1), asp = 1)
#   graphics::rasterImage(img, 0, 0, 1, 1)
#   #Close the PNG device
#   dev.off()
# }
# setwd(Selection_model_H_e_dir)
# Pattern for finding the specific file containing "5th_percentiles_of_H_e_distribution.tsv"
pattern <- "^.*5th_percentiles_of_H_e_distribution.tsv$"
selection_model_5th_percentiles_of_H_e_files <- list.files(path = Selection_model_H_e_dir, pattern = pattern)
# Initialize an empty list to store H_e_5th_percentiles_Selection_models
H_e_5th_percentiles_Selection_models <- list()
# Loop through each selection coefficient and its associated file
for (i in seq_along(selection_model_5th_percentiles_of_H_e_files)) {
file_path <- file.path(Selection_model_H_e_dir,selection_model_5th_percentiles_of_H_e_files[i])
# Extract the selection coefficient from the file name
selection_coefficient <- sub(tolower(".*(selection_model_s\\d+_chr\\d+).*"), "\\1", tolower(selection_model_5th_percentiles_of_H_e_files[i]))
# Read the .tsv file into a data frame
subtable <- read.table(file_path, header = TRUE,sep = "\t", stringsAsFactors = FALSE)
H_e_5th_percentiles_Selection_models[[selection_coefficient]]$file_name <- selection_model_5th_percentiles_of_H_e_files[i]
# Add the subtable to the list with the selection coefficient as its name
H_e_5th_percentiles_Selection_models[[selection_coefficient]]$results <- subtable
}
# Loop through each selection_coefficient
for (selection_coefficient in names(H_e_5th_percentiles_Selection_models)) {
# Calculate the point estimate F_ROH across all technical replicates simulations for the current selection coefficient
H_e_5th_percentiles_Selection_models[[selection_coefficient]]$Estimated_Mean_H_e_5th_percentile <- mean(H_e_5th_percentiles_Selection_models[[selection_coefficient]][["results"]][["Fifth_Percentile"]])
# Calculate the Standard Error confidence interval of the point estimate F_ROH across all technical replicates simulations for the current selection coefficient
# Store the Standard Error confidence interval in the H_e_5th_percentiles_Selection_models table
H_e_5th_percentiles_Selection_models[[selection_coefficient]]$SE_CI_Estimated_Mean_H_e_5th_percentile <- standard_error_confidence_interval_fun(H_e_5th_percentiles_Selection_models[[selection_coefficient]][["results"]][["Fifth_Percentile"]])
}
# View the dataframe
# View(H_e_5th_percentiles_Selection_models)
# Initialize vectors to store F_ROH values and CI bounds for the different selection coefficients
selection_model_avg_values <- c()
selection_model_lower_ci <- c()
selection_model_upper_ci <- c()
selection_model_names <- c(rownames(summary(H_e_5th_percentiles_Selection_models)))
# Loop through each selection_coefficient in H_es_Selection_models
for (selection_coefficient in H_e_5th_percentiles_Selection_models) {
selection_coefficient$Estimated_Mean_Population_H_e <- mean(selection_coefficient$results$Avg_H_e)
CI <- standard_error_confidence_interval_fun(selection_coefficient$results$Avg_H_e)
# Append values to the lists
selection_model_avg_values <- c(selection_model_avg_values, selection_coefficient$Estimated_Mean_Population_H_e)
selection_model_lower_ci <- c(selection_model_lower_ci, CI[1])
selection_model_upper_ci <- c(selection_model_upper_ci, CI[2])
}
# Extract neutral model values and CI bounds
H_e_5th_percentiles_Neutral_model$Estimated_Mean_Population_H_e <- mean(H_e_5th_percentiles_Neutral_model[["results"]][["Avg_H_e"]])
H_e_5th_percentiles_Neutral_model$SE_CI_Estimated_Mean_H_e <- standard_error_confidence_interval_fun(H_e_5th_percentiles_Neutral_model[["results"]][["Avg_H_e"]])
neutral_avg_H_e <- H_e_5th_percentiles_Neutral_model$Estimated_Mean_Population_H_e
neutral_lower_ci <- H_e_5th_percentiles_Neutral_model$SE_CI_Estimated_Mean_H_e[1]
neutral_upper_ci <- H_e_5th_percentiles_Neutral_model$SE_CI_Estimated_Mean_H_e[2]
# Extract empirical model value
empirical_avg_H_e <- empirical_H_e_distribution_table$Avg_H_e
empirical_lower_ci <- NA # Placeholder for confidence interval lower bound
empirical_upper_ci <- NA # Placeholder for confidence interval upper bound
# Combine all values into a data frame
H_e_values <- data.frame(
Model = c(rep("Selection", length(selection_model_avg_values)), "Neutral", "Empirical"),
H_e = c(selection_model_avg_values, neutral_avg_H_e, empirical_avg_H_e),
Lower_CI = c(selection_model_lower_ci, neutral_lower_ci, empirical_lower_ci),
Upper_CI = c(selection_model_upper_ci, neutral_upper_ci, empirical_upper_ci)
)
# Format all numeric values to 5 decimal places
H_e_values$H_e <- round(H_e_values$H_e, H_e_values_decimals)
H_e_values$Lower_CI <- round(H_e_values$Lower_CI,H_e_values_decimals)
H_e_values$Upper_CI <- round(H_e_values$Upper_CI,H_e_values_decimals)
formatted_selection_coefficient_labels <-sub(tolower("s(\\d)(\\d+)_.*"), tolower("s=\\1.\\2"), tolower(selection_model_names))
formatted_selection_coefficient_labels <- sub(tolower("selection_model_"), "", tolower(formatted_selection_coefficient_labels))
H_e_values$Model[1:length(selection_model_names)] <- formatted_selection_coefficient_labels
H_e_values$H_e <- as.numeric(round(H_e_values$H_e,H_e_values_decimals))
# Sort the data frame based on H_e column
H_e_values_sorted <- H_e_values[order(as.numeric(H_e_values$H_e)), ]
# Define the filename with the output directory path
filename <- file.path(output_dir, paste("Genomic_Average_Expected_Heterozygosity_Summary",".csv", sep = ""))
# Write data to CSV file without quotes
write.table(H_e_values_sorted, file = filename, sep = ",", row.names = FALSE, quote = FALSE)
# # Use the write_latex_table() function to write the data to a LaTeX-compatible text file
# write_latex_table(
#   data_frame = H_e_values,
#   sort_column = "H_e",  # Column used for sorting
#   output_dir = output_dir,
#   output_filename = "Expected_Heterozygosity_Summary"  # File name without extension
# )
# Print the table using knitr::kable()
knitr::kable(H_e_values_sorted, row.names = FALSE)
# Initialize vectors to store F_ROH values and CI bounds for the different selection coefficients
selection_model_avg_values <- c()
selection_model_lower_ci <- c()
selection_model_upper_ci <- c()
selection_model_names <- c(rownames(summary(window_H_e_causative_variant_tables)))
# Loop through each selection_coefficient in H_e_5th_percentiles_Selection_models
for (selection_coefficient in H_e_5th_percentiles_Selection_models) {
CI <- selection_coefficient$SE_CI_Estimated_Mean_H_e_5th_percentile
# Append values to the lists
selection_model_avg_values <- c(selection_model_avg_values, selection_coefficient$Estimated_Mean_H_e_5th_percentile)
selection_model_lower_ci <- c(selection_model_lower_ci, CI[1])
selection_model_upper_ci <- c(selection_model_upper_ci, CI[2])
}
# Extract neutral model values and CI bounds
neutral_avg_H_e_5th_percentile <- H_e_5th_percentiles_Neutral_model[["Estimated_Mean_H_e_5th_percentile"]]
neutral_lower_ci <- H_e_5th_percentiles_Neutral_model[["SE_CI_Estimated_Mean_H_e_5th_percentile"]][1]
neutral_upper_ci <- H_e_5th_percentiles_Neutral_model[["SE_CI_Estimated_Mean_H_e_5th_percentile"]][2]
# Extract empirical model value
empirical_avg_H_e_5th_percentile <- empirical_H_e_distribution_table$Fifth_Percentile
empirical_lower_ci <- NA # Placeholder for confidence interval lower bound
empirical_upper_ci <- NA # Placeholder for confidence interval upper bound
# Combine all values into a data frame
H_e_5th_percentile_values <- data.frame(
Model = c(rep("Selection", length(selection_model_avg_values)), "Neutral", "Empirical"),
H_e_5th_percentile = c(selection_model_avg_values, neutral_avg_H_e_5th_percentile, empirical_avg_H_e_5th_percentile),
Lower_CI = c(selection_model_lower_ci, neutral_lower_ci, empirical_lower_ci),
Upper_CI = c(selection_model_upper_ci, neutral_upper_ci, empirical_upper_ci)
)
# Format all numeric values to 5 decimal places
H_e_5th_percentile_values$H_e_5th_percentile <- round(H_e_5th_percentile_values$H_e_5th_percentile, H_e_values_decimals)
H_e_5th_percentile_values$Lower_CI <- round(H_e_5th_percentile_values$Lower_CI,H_e_values_decimals)
H_e_5th_percentile_values$Upper_CI <- round(H_e_5th_percentile_values$Upper_CI,H_e_values_decimals)
# Formatting the selection coefficient for when displaying it. Removing "chr[0-9]" and adding a decimal point to the selection coefficient
formatted_selection_coefficient_labels <-sub(tolower("s(\\d)(\\d+)_.*"), tolower("s=\\1.\\2"), tolower(selection_model_names))
H_e_5th_percentile_values$Model[1:length(selection_model_names)] <- formatted_selection_coefficient_labels
H_e_5th_percentile_values$H_e_5th_percentile <- as.numeric(round(H_e_5th_percentile_values$H_e_5th_percentile,H_e_values_decimals))
# Sort the data frame based on H_e_5th_percentile column
H_e_5th_percentile_values_sorted <- H_e_5th_percentile_values[order(as.numeric(H_e_5th_percentile_values$H_e_5th_percentile)), ]
# Define the filename with the output directory path
filename <- file.path(output_dir, paste("Expected_Heterozygosity_Summary",".csv", sep = ""))
# Write data to CSV file without quotes
write.table(H_e_5th_percentile_values_sorted, file = filename, sep = ",", row.names = FALSE, quote = FALSE)
# Use the write_latex_table() function to write the data to a LaTeX-compatible text file
write_latex_table(
data_frame = H_e_5th_percentile_values,
sort_column = "H_e_5th_percentile",  # Column used for sorting
output_dir = output_dir,
output_filename = "Expected_Heterozygosity_Summary"  # File name without extension
)
# Print the table using knitr::kable()
knitr::kable(H_e_5th_percentile_values_sorted, row.names = FALSE)
generate_vbo_links <- function(vbo_string) {
vbo_list <- trimws(unlist(strsplit(vbo_string, ",")))  # Split by comma and trim spaces
# base_url <- "https://www.ebi.ac.uk/ols4/search?lang=en&q=VBO%3A"
base_url <- "http://purl.obolibrary.org/obo/VBO_" # http://purl.obolibrary.org/obo/VBO_0200800
vbo_list <- sapply(vbo_list, function(id) {
if (grepl("^VBO_", id)) {  # Check if it starts with "VBO_"
vbo_number <- sub("VBO_", "", id)  # Extract number
} else if (grepl("^VBO:", id)) {  # Check if it starts with "VBO:"
vbo_number <- sub("VBO:", "", id)  # Extract number
} else {
return(id)  # Return unchanged if not a VBO ID
}
url <- paste0(base_url, vbo_number)
return(paste0('<a href="', url, '" target="_blank">', id, '</a>'))  # Create hyperlink
}, USE.NAMES = FALSE)
return(paste(vbo_list, collapse = ", "))  # Join back into a string
}
generate_ensembl_gene_links <- function(gene_name) {
# base_url <- "https://www.ensembl.org/Multi/Search/Results?q=" #https://www.ensembl.org/Multi/Search/Results?q=DCC
base_url <- "https://www.ncbi.nlm.nih.gov/gene/?term=" #https://www.ncbi.nlm.nih.gov/gene/?term=DCC
url <- paste0(base_url, gene_name)
return(paste0('<a href="', url, '" target="_blank">', gene_name, '</a>'))  # Use gene_name instead of id
}
vertebrate_breed_ontology_ids_vector <- unlist(strsplit(vertebrate_breed_ontology_ids, ","))
file <- file.path(omia_phenotypes_filepath)
#  # Read the header (the line starting with #)
header_line <- readLines(file, n = 1)  # Read the first line
header <- unlist(strsplit(sub("^#", "", header_line), "\t"))  # Remove the "#" and split by tab
# Read the data (skip the first line since it's the header)
omia_phenotype_data <- read.table(file, header = FALSE, comment.char = "#", stringsAsFactors = FALSE, sep = "\t", skip = 1)
# Assign the extracted header as column names
colnames(omia_phenotype_data) <- header
# ---- Rename Columns for POS1 and POS2 ----
colnames(omia_phenotype_data)[1] <- "CHR"  # V5 as POS1 (start position)
colnames(omia_phenotype_data)[2] <- "POS1"  # V5 as POS1 (start position)
colnames(omia_phenotype_data)[3] <- "POS2"  # V6 as POS2 (end position)
colnames(omia_phenotype_data)[4] <- "PHENE"
colnames(omia_phenotype_data)[5] <- "PHENE_CATEGORY"
colnames(omia_phenotype_data)[6] <- "SINGLE_GENE_TRAIT_OR_DISORDER"
colnames(omia_phenotype_data)[7] <- "DISEASE_RELATED"
colnames(omia_phenotype_data)[8] <- "GENE_SYMBOL"
colnames(omia_phenotype_data)[9] <- "GENE_DESCRIPTION"
colnames(omia_phenotype_data)[10] <- "PHENE_URL"
colnames(omia_phenotype_data)[11] <- "GENE_DETAILS_URL"
colnames(omia_phenotype_data)[12] <- "BREEDS"
# ---- Ensure POS1 and POS2 are Numeric ----
omia_phenotype_data$POS1 <- as.numeric(omia_phenotype_data$POS1)
omia_phenotype_data$POS2 <- as.numeric(omia_phenotype_data$POS2)
# omia_phenotype_data$BREEDS <- generate_vbo_links(omia_phenotype_data$BREEDS)
omia_phenotype_data$BREEDS <- sapply(omia_phenotype_data$BREEDS, generate_vbo_links)
omia_phenotype_data$GENE_SYMBOL <- sapply(omia_phenotype_data$GENE_SYMBOL, generate_ensembl_gene_links)
View(omia_phenotype_data)
# Read header and data
header_line <- readLines(omia_scraped_phenotypes_data_filepath, n = 1)
header <- unlist(strsplit(sub("^#", "", header_line), ","))
omia_raw_phenotype_data <- read.table(omia_scraped_phenotypes_data_filepath,
header = FALSE,
comment.char = "#",
stringsAsFactors = FALSE,
sep = ",",
skip = 1)
colnames(omia_raw_phenotype_data) <- header
omia_raw_phenotype_data[[12]] <- sapply(omia_raw_phenotype_data[[12]], generate_vbo_links)
omia_raw_phenotype_data[[8]] <- sapply(omia_raw_phenotype_data[[8]], generate_ensembl_gene_links)
# Print VBO IDs used
cat("\n\n **The following Vertebrate Breed Ontology (VBO) ID(s) were used for associating, or could potentially be associated with the empirical dataset:**\n\n",
generate_vbo_links(vertebrate_breed_ontology_ids), "\n\n")
cat("\n\n**Below are the non-defect phenotypes discovered on OMIA, associated with these VBO IDs.**\n\n",
"These phenotypes include cases where no known links to a specific genomic region or breed have been reported on OMIA so far.",
"Additionally, some phenotypes may have genomic coordinates mapped to a different reference assembly, which could result in misalignment relative to the identified ROH hotspot regions, and thus, may be misclassified as 'not overlapping with any ROH hotspot region'. ",
"\n\nTherefore, these table(s) could serve as a valuable resource for identifying phenotypes that   otherwise may have been overlooked due to incomplete genomic mappings or lack of direct breed associations.\n They offer an opportunity for further investigation, particularly (if applicable) through re-mapping coordinates using a LiftOver process to potentially align them with the discovered ROH hotspot regions.")
# Create list to hold phenotype tables
Breed_phenotypes_tables <- list()
for (i in seq_along(vertebrate_breed_ontology_ids_vector)) {
current_id <- vertebrate_breed_ontology_ids_vector[i]
if (tolower(current_id) == "unspecified") {
matching_OMIA_phenotypes <- omia_raw_phenotype_data[
omia_raw_phenotype_data[, 12] == "" &
tolower(omia_raw_phenotype_data$DISEASE_RELATED) == "no", ]
matching_OMIA_phenotypes[, 12] <- "Unspecified"
matching_OMIA_phenotypes <- matching_OMIA_phenotypes[!grepl("disease", matching_OMIA_phenotypes[, 5], ignore.case = TRUE), ]
matching_OMIA_phenotypes <- matching_OMIA_phenotypes[order(as.numeric(matching_OMIA_phenotypes$CHR)), ]
} else {
matching_OMIA_phenotypes <- omia_raw_phenotype_data[
grepl(current_id, omia_raw_phenotype_data[, 12]) &
tolower(omia_raw_phenotype_data$DISEASE_RELATED) != "yes", ]
}
Breed_phenotypes_tables[[current_id]] <- matching_OMIA_phenotypes
}
# Loop through each table and render with kableExtra for improved styling
for(tbl in Breed_phenotypes_tables) {
if (nrow(tbl) > 0) {
# Create a styled HTML table
table_html <- knitr::kable(tbl, format = "html",
row.names = FALSE,
digits = kable_table_digits,
escape = FALSE,
table.attr = "class='table table-bordered table-striped'") %>%
kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover", "condensed")) %>%
# Adjust column width; change "3cm" to a width that suits your data
column_spec(1:ncol(tbl), width = "3cm")
# Output the table and add spacing
cat(table_html)
cat("<br><br>\n")
}
}
View(omia_raw_phenotype_data)
# View(empirical_hotspot_tables)
for (i in seq_along(empirical_hotspot_tables)) {
# Extract chromosome and hotspot region boundaries
CHR <- empirical_hotspot_tables[[i]][["Hotspot_region_data"]][["CHR"]]
POS1 <- empirical_hotspot_tables[[i]][["Hotspot_region_data"]][["POS1"]]
POS2 <- empirical_hotspot_tables[[i]][["Hotspot_region_data"]][["POS2"]]
# cat("Hotspot Window -> POS1:", POS1, " POS2:", POS2, "\n")
# Find phenotypes that partially or fully overlap the hotspot region
overlapping_phenotypes <- omia_phenotype_data[
omia_phenotype_data$CHR == CHR &
omia_phenotype_data$POS2 >= POS1 &  # Phenotype end is after or at the region start
omia_phenotype_data$POS1 <= POS2,   # Phenotype start is before or at the region end
]
# Compute Overlap_Percentage for each phenotype
if (nrow(overlapping_phenotypes) > 0) {
overlapping_phenotypes$Overlap_Percentage <- apply(overlapping_phenotypes, 1, function(phenotype) {
phenotype_start <- as.numeric(phenotype["POS1"])
phenotype_end <- as.numeric(phenotype["POS2"])
phenotype_length <- phenotype_end - phenotype_start + 1  # Total phenotype length
# Compute upstream and downstream outside portions
upstream_outside <- max(0, POS1 - phenotype_start)  # If phenotype starts before hotspot
downstream_outside <- max(0, phenotype_end - POS2)  # If phenotype ends after hotspot
outside_portion <- upstream_outside + downstream_outside
# Compute Overlap Percentage
Overlap_Percentage <- 100 * (1 - (outside_portion / phenotype_length))
return(Overlap_Percentage)
})
} else {
overlapping_phenotypes$Hotspot_Overlap_Perc <- numeric(0)  # Empty case
}
# Store results
empirical_hotspot_tables[[i]][["Hotspot_species_phenotypes"]] <- overlapping_phenotypes
}
# Initialize the empty list
All_phenotypes_for_all_hotspots <- list()
hotspots_with_overlapping_phenotypes <- ""
# Loop through each hotspot and filter under selection
for (hotspot in names(empirical_hotspot_tables)) {
# Extract the phenotypes for the selected hotspot
phenotypes_data <- empirical_hotspot_tables[[hotspot]][["Hotspot_species_phenotypes"]]
if (!is.null(phenotypes_data) && nrow(phenotypes_data) > 0) {
All_phenotypes_for_all_hotspots[[hotspot]] <- phenotypes_data
hotspots_with_overlapping_phenotypes <- paste0(hotspots_with_overlapping_phenotypes,", ", hotspot)
}
}
# All_phenotypes_for_all_hotspots[[hotspot]] <- Breed_phenotypes_tables[[1]] # Debugging purposes
# hotspots_with_overlapping_phenotypes <- "" # Debugging purposes
# Check if there are any phenotypes under selection and display a message with the tables
if (length(All_phenotypes_for_all_hotspots) > 0) {
# Print a phenotyperal message before displaying tables
cat("\n\nThe following table(s) shows all defect and non-defect phenotypes (for the studied species) overlapping with the empirical ROH hotspots. \n\n**The hotspots are displayed in the following order:**\n\n",hotspots_with_overlapping_phenotypes,"")
# # Display the entire table for all hotspots
# knitr::kable(All_phenotypes_for_all_hotspots, row.names = FALSE,
#              caption = "All defect and non-defect phenotypes (for the studied species) overlapping with the empirical ROH hotspots")
# Loop through each table and render with kableExtra for improved styling
for(tbl in All_phenotypes_for_all_hotspots) {
if (nrow(tbl) > 0) {
# Create a styled HTML table
table_html <- knitr::kable(tbl, format = "html",
row.names = FALSE,
digits = kable_table_digits,
escape = FALSE,
table.attr = "class='table table-bordered table-striped'") %>%
kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover", "condensed")) %>%
# Adjust column width; change "3cm" to a width that suits your data
column_spec(1:ncol(tbl), width = "3cm")
# Output the table and add spacing
cat(table_html)
cat("<br><br>\n")
}
}
} else {
cat("\n\n**Result:**\n\nNo non-defect (non-disease) species-specific phenotypes were found to overlap with the empirical ROH hotspot regions.\n")
}
View(omia_phenotype_data)
View(omia_raw_phenotype_data)
