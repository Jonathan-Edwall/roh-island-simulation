---
output:
  html_document:
    toc: true
  pdf_document:
    toc: true
editor_options: 
  chunk_output_type: inline
---

<!-- # 0: Preparation -->

<!-- Defining the input and output directories -->

```{r setup, echo = FALSE,results= 'hide',warning = FALSE}

# Clean the working environment
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE)

####################################  
# Defining the working directory
#################################### 
# Set the path to your GitHub folder
YOUR_GITHUB_ROOT_DIRECTORY <- "C:/Users/jonat/GitHub"
# Defining the relative path in the repository
repository_path <- file.path(YOUR_GITHUB_ROOT_DIRECTORY,"roh-island-simulation")
#################################### 
# Defining Input parameters
#################################### 
### Defining the Title ###
# empirical_species <- "German Shepherd"
empirical_breed <- "labrador_retriever"
empirical_species <- paste(toupper(substring(unlist(strsplit(empirical_breed, "_")), 1, 1)),
                             substring(unlist(strsplit(empirical_breed, "_")), 2),
                             sep = "", collapse = " ")

document_title <- paste0("ROH Island Simulation Results for the ",empirical_species," Dataset")

### Defining the Subtitle ###

MAF_pruning_used <- TRUE
min_MAF_selection_testing <- "0.01"

if (MAF_pruning_used == FALSE) {
  MAF_settings_text <- paste0("No MAF-based pruning of markers were performed") 
} else {
  MAF_settings_text <- paste0("Markers with MAF < ",min_MAF_selection_testing," were pruned before computing Expected Heterozygosity ($H_{e}$) ") 
}

document_sub <- MAF_settings_text

### Defining General Simulation Settings ###
n_simulation_replicates <- 50
Introduce_mutations <- "TRUE"
reference_population_for_snp_chip <- "last_breed_formation_generation" 

### Defining the Population History parameters for the simulations ###
Inbred_ancestral_population <- "FALSE"
Ne_burn_in <- 3185 
N_bottleneck <- 5
n_generations_bottleneck <- 1
n_simulated_generations_breed_formation <- 110
n_individuals_breed_formation <- 330

### Defining the Selection Model Simulation Settings ###
Simulate_Hard_Sweep <- "TRUE"
allele_copies_threshold <- "1"
Variant_One_Individual_Origin <- "TRUE"
fixation_threshold_causative_variant <- 0.99

if (tolower(Simulate_Hard_Sweep) == "true") {
  sweep_type_text <- paste0(
    "**Hard Sweep Scenario** *(Simulate_Hard_Sweep = TRUE)*: ",
    "In the simulated selection scenario, the causative variant was drawn from the set of alleles present in the post-bottleneck generation that had exactly one allele copy in the population."
  )
} else {
  if (tolower(Variant_One_Individual_Origin) == "true") {
    sweep_type_text <- paste0(
      "**Soft Sweep Scenario (Single Individual Origin)** *(Simulate_Hard_Sweep = FALSE, Variant_One_Individual_Origin = TRUE)*: ",
      "In the simulated selection scenario, the causative variant was drawn from the set of alleles in the post-bottleneck generation that originated from a single homozygous individual. ",
      "These alleles had exactly ", allele_copies_threshold, " copies in the population (*allele_copies_threshold*)."
    )
  } else {
    sweep_type_text <- paste0(
      "**Soft Sweep Scenario (Multiple Individual Origin)** *(Simulate_Hard_Sweep = FALSE, Variant_One_Individual_Origin = FALSE)*: ",
      "In the simulated selection scenario, the causative variant was drawn from the set of alleles in the post-bottleneck generation that originated from heterozygous individuals. ",
      "These alleles also had exactly ", allele_copies_threshold, " copies in the population (*allele_copies_threshold*)."
    )
  }
}

# Parameters used for displaying the result
ROH_frequency_decimals <- 1
H_e_values_decimals <- 3
F_ROH_values_decimals <- 3
Window_lengths_decimals <- 2

histogram_line_sizes <- 3
empirical_data_color <- "darkgreen"
neutral_model_color <- "blue" 
selection_model_color <- "purple"
kable_table_digits <- 2
####################################  
# Defining the Input Directories
#################################### 
simulated_data_dir_basename <- "simulated-chr1_3185_Ne_50TC"
results_dir <- file.path(repository_path,"results_chr1_3185_Ne_50TC")
plink_ROH_dir <- file.path(results_dir,"PLINK/ROH")
# expected_heterozygosity_dir <- file.path(results_dir,"expected_heterozygosity_No_MAF")
expected_heterozygosity_dir <- file.path(results_dir,"expected_heterozygosity_MAF_0_01")
# expected_heterozygosity_dir <- file.path(results_dir,"expected_heterozygosity_MAF_0_05")
ROH_hotspots_dir <- file.path(results_dir,"ROH-Hotspots")
# Selection_strength_test_dir <- file.path(ROH_hotspots_dir,"selection_strength_test_No_MAF")
Selection_strength_test_dir <- file.path(ROH_hotspots_dir,"selection_strength_test_MAF_0_01")
# Selection_strength_test_dir <- file.path(ROH_hotspots_dir,"selection_strength_test_MAF_0_05")
# Sweep_test_dir <- file.path(ROH_hotspots_dir,"sweep_test_No_MAF")
Sweep_test_dir <- file.path(ROH_hotspots_dir,"sweep_test_MAF_0_01")
#¤¤¤¤¤¤¤¤ Simulated Data ¤¤¤¤¤¤¤¤
raw_data_dir <- file.path(repository_path,"data/raw")
raw_simulated_data_dir <- file.path(raw_data_dir,simulated_data_dir_basename)

############### 
## Empirical ###
###############
### ROH hotspots ###
Empirical_data_ROH_hotspots_dir  <- file.path(ROH_hotspots_dir,"empirical",empirical_breed)
Empirical_data_autosome_ROH_freq_dir <- file.path(Empirical_data_ROH_hotspots_dir,"Gosling_plots/autosome_roh_freq")
### Inbreeding coefficient ###
Empirical_data_F_ROH_dir  <- file.path(plink_ROH_dir,"empirical",empirical_breed,"F_ROH")
### Expected Heterozygosity distribution ###
Empirical_data_H_e_dir <- file.path(expected_heterozygosity_dir,"empirical",empirical_breed)

### OMIA phenotype data ###
preprocessed_data_dir <- file.path(repository_path,"data/preprocessed")


omia_scraped_phenotypes_data_filepath <- "C:/Users/jonat/GitHub/roh-island-simulation/data/raw/empirical/omia_scraped_phene_data/OMIA_dog_phenotype_data_raw.csv"


omia_phenotypes_filepath <-"C:/Users/jonat/GitHub/roh-island-simulation/data/preprocessed/empirical/omia_phenotype_data/All_dog_phenotypes.bed"
vertebrate_breed_ontology_ids <- "VBO_0200800,Unspecified" # Identifying phenotypes labeled as either related to "Labrador retriever dog" or "unidentified breed"

### Gene Detection ###
Empirical_data_hotspot_gene_mapping_dir <- file.path(Empirical_data_ROH_hotspots_dir,"hotspot_gene_mapping")
gene_annotations_filepath <- "roh-island-simulation/data/preprocessed/empirical/gene_annotations/canFam3.ncbiRefSeq.gtf.gz" 

############### 
## Simulated ###
###############
### ROH hotspots ###
Neutral_model_ROH_hotspots_dir  <- file.path(ROH_hotspots_dir,"simulated/neutral")
Neutral_model_autosome_ROH_freq_dir <- file.path(Neutral_model_ROH_hotspots_dir,"Gosling_plots/autosome_roh_freq")

Selection_model_ROH_hotspots_dir  <- file.path(ROH_hotspots_dir,"simulated/selection")
Selection_model_autosome_ROH_freq_dir <- file.path(Selection_model_ROH_hotspots_dir,"Gosling_plots/autosome_roh_freq")
### Inbreeding coefficient ###
Neutral_model_F_ROH_dir  <- file.path(plink_ROH_dir,"simulated/neutral_model/F_ROH")
Selection_model_F_ROH_dir  <- file.path(plink_ROH_dir,"simulated/selection_model/F_ROH")

### Expected Heterozygosity distribution ###
Neutral_model_H_e_dir <- file.path(expected_heterozygosity_dir,"simulated/neutral_model")
Selection_model_H_e_dir <- file.path(expected_heterozygosity_dir,"simulated/selection_model")
# Causative variant
Selection_causative_variant_windows_dir <- file.path(results_dir,"causative_variant_windows")
# causative_variant_windows_H_e_dir <- file.path(Selection_causative_variant_windows_dir,"H_e_No_MAF")
causative_variant_windows_H_e_dir <- file.path(Selection_causative_variant_windows_dir,"H_e_MAF_0_01")
# causative_variant_windows_H_e_dir <- file.path(Selection_causative_variant_windows_dir,"H_e_MAF_0_05")

raw_selection_dir <- file.path(raw_simulated_data_dir,"selection_model")
variant_freq_plots_dir <- file.path(raw_selection_dir,"variant_freq_plots")
variant_position_dir <- file.path(raw_selection_dir,"variant_position")
pruned_replicates_count_dir <- file.path(raw_selection_dir,"pruned_counts")
##################################### 
## Defining the Output Directory
##################################### 
output_dir <- file.path(results_dir,"Pipeline_results")

if (!dir.exists(output_dir)) {
  # Create the directory
  dir.create(output_dir, recursive = TRUE)
}

```

---
title: "`r document_title`"
subtitle: "`r document_sub`"
output:
  html_document:
    toc: true
    toc_depth: 3  
date: "`r Sys.Date()`"
editor_options: 
  markdown: 
    wrap: 72
    
---

## Simulation Settings

### General Simulation Settings:
- **Number of Simulated Technical Replicates**: `r n_simulation_replicates` 
- **New Random Mutations Added to Offspring**: `r Introduce_mutations` 
- **Reference Population for SNP-chip**: `r reference_population_for_snp_chip`  

### Population History Parameters:
- **Inbred Ancestral Population**: `r Inbred_ancestral_population` 
- **$N_{e}$ Burn-in Population**: `r Ne_burn_in` Individuals
- **Bottleneck Scenario**: 
  - **Population Size  ($N$)**: `r N_bottleneck` Individuals
  - **Duration of Bottleneck Scenario**: `r n_generations_bottleneck` Generation(s)
- **Breed Formation**: 
  - **Population Size  ($N$)**: `r n_individuals_breed_formation` Individuals
  - **Duration of Breed Formation Scenario**: `r n_simulated_generations_breed_formation` Generation(s)


### Selection Model Settings:
- `r sweep_type_text`
- **Frequency Threshold for Fixation of the Allele of the Causative Variant:** `r fixation_threshold_causative_variant`



<!-- ## Loading Libraries --> 

```{r Loading Libraries, echo = FALSE, results= 'hide', warning = FALSE}
if (!require(knitr)) install.packages("knitr", dependencies = TRUE)
library(knitr)
if (!require(kableExtra)) install.packages("kableExtra", dependencies = TRUE)
library(kableExtra) 
if (!require(ggplot2)) install.packages("ggplot2", dependencies = TRUE)
library(ggplot2)
if (!require(scatterplot3d)) install.packages("scatterplot3d", dependencies = TRUE)
library(scatterplot3d) # For generating the 3d plots 
if (!require(RColorBrewer)) install.packages("RColorBrewer", dependencies = TRUE)
library(RColorBrewer) # For generating a color palette
```
<!-- # Latex Formatting Function --> 

```{r Latex formatting function,echo = FALSE, results= 'hide', warning = FALSE}
# Function to format and write a data frame to a LaTeX-compatible text file
write_latex_table <- function(data_frame, sort_column, output_dir, output_filename) {
  # Sort the data frame based on the specified column
  sorted_df <- data_frame[order(data_frame[[sort_column]]), ]
  # Define the complete file path
  file_path <- file.path(output_dir, paste(output_filename, ".txt", sep = ""))
  # Open a connection to the file for writing
  file_conn <- file(file_path, open = "wt")

  # Loop through each row in the sorted DataFrame
  for (i in 1:nrow(sorted_df)) {
    # Format the row with & separator and \\ at the end
    formatted_row <- paste(sorted_df[i, ], collapse = " & ")
    formatted_row <- paste(formatted_row, "\\\\", sep = "")
    # Write the formatted row to the file
    cat(formatted_row, file = file_conn, sep = "\n")
  }
  # Close the file connection
  close(file_conn)
  # Return the file path for reference
  return(file_path)
}
```

<!-- # Standard Error Confidence Interval Function --> 

```{r Standard Error Confidence interval function,echo = FALSE}
# Function to calculate standard error and its confidence interval
standard_error_confidence_interval_fun <- function(observed_data, confidence_level = 0.95) {
  if ( length(observed_data) > 1 ) {
    # Calculate standard error
    n <- length(observed_data)
    standard_deviation <- sd(observed_data)
    standard_error <- standard_deviation / sqrt(n - 1)
    # Calculate confidence interval based on standard error
    alpha <- (1 - confidence_level) / 2
    margin_of_error <- qnorm(1 - alpha) * standard_error
    mean_estimate <- mean(observed_data)
    # Calculate the percentiles for the confidence interval
    confidence_interval_lower_bound <- mean_estimate - margin_of_error # 2.5th percentile (2σ)
    confidence_interval_upper_bound <- mean_estimate + margin_of_error # 97.5th percentile (2σ)
    # Return confidence interval
    return(c(confidence_interval_lower_bound, confidence_interval_upper_bound))
  } else {
    return(c(NA,NA)) 
    }
} 
```

# 1: Causative Variant (Selection Models)
This section presents the simulation results for the simulated selection models.
The models simulate selection on a causative variant under varying selection pressures (selection coefficient values). These results serve as a reference for estimating the selection coefficient of an identified candidate region for selection in the empirical dataset.

## 1.1: Variant Fixation 
<!-- ### 1.1.1: Fixation probability -->
```{r 1.1.1: Fixation probability,echo = FALSE,results= 'hide',warning = FALSE}
# setwd(pruned_replicates_count_dir)
# Pattern for finding files containing "pruned_replicates_count" and ending with ".tsv"
pattern <- ".*pruned_replicates_count.*\\.tsv$"
pruned_replicates_count_files <- list.files(path = pruned_replicates_count_dir, pattern = pattern)
# Extract simulation numbers from the filename
sim_number_pattern <- ".*sim_(\\d+)_.*"
sim_name_pattern <- "^(.*)\\.tsv$"
sim_numbers <- as.numeric(gsub(tolower(sim_number_pattern), "\\1", tolower(pruned_replicates_count_files)))
sim_name <- sub(tolower("^(.*?)_pruned_replicates_count_.*"), "\\1", tolower(pruned_replicates_count_files))
# Combine simulation name, number, and file name
sim_info <- data.frame(sim_name = sim_name, file_name = pruned_replicates_count_files, stringsAsFactors = FALSE)
# Initialize an empty list to store the selection model tables
non_fixated_causative_variant_count_tables <- list()

# Loop through each .tsv file
for (i in 1:length(sim_info$sim_name)) {
  # Get the file name
  file <- sim_info$file_name[i]
  file_path <- file.path(pruned_replicates_count_dir,file)
  column_names <- c("Sim_name","Non_fixated_variant_count")
  # Read the .tsv frequency file into a data frame
  causative_variant_not_fixated_count <- read.table(file_path, header = FALSE, comment.char = "#", stringsAsFactors = FALSE,col.names = column_names, sep = "\t")
  # Add simulation_number as an attribute to the data frame
  sim_num <- as.numeric(gsub(tolower(sim_number_pattern), "\\1", tolower(file)))
  attr(causative_variant_not_fixated_count, "Simulation_number") <- sim_num
  # Extract the selection coefficient from the file name
  selection_coefficient <- sub(tolower("^.*_(s\\d+_chr\\d+).*$"), "\\1", tolower(file))

  # Check if the selection coefficient already exists in the list
  if (!(selection_coefficient %in% names(non_fixated_causative_variant_count_tables))) {
    # If it doesn't exist, create an empty data frame
    non_fixated_causative_variant_count_tables[[selection_coefficient]] <- data.frame()
  }

  # Append the data frame to the list under the selection coefficient
  non_fixated_causative_variant_count_tables[[selection_coefficient]] <- rbind(non_fixated_causative_variant_count_tables[[selection_coefficient]], causative_variant_not_fixated_count)
}

#View(non_fixated_causative_variant_count_tables)
```


<!-- ### 1.1.2: Fixation time  -->
```{r 1.1.2: Fixation time,echo = FALSE}
# Function to determine the number of rows until fixation is reached
time_to_fixation <- function(data, threshold = 0.9) {
  # Find the index of the first row where the allele frequency is 0.9 or higher
  fixation_index <- which(data$allele_frequency >= threshold)[1]
  # Return the number of rows until fixation is reached
  return(fixation_index - 1)
}
```

```{r Causative Variant fixation time,echo = FALSE,warning = FALSE}
# setwd(variant_freq_plots_dir)
# Pattern for finding files containing "causative_variant_window_lengths" and ending with ".tsv"
pattern <- ".*\\.txt$"
causative_variant_fixation_files <- list.files(path = variant_freq_plots_dir, pattern = pattern)

# Extract simulation numbers from the filename
sim_number_pattern <- ".*sim_(\\d+)_.*"
sim_name_pattern <- "^(.*)\\.txt$"
# Extract everything before the ".txt" extension from the filename
sim_name <- sub(tolower(sim_name_pattern), "\\1", tolower(causative_variant_fixation_files))
# Combine simulation name, number, and file name
sim_info <- data.frame(sim_name = sim_name, file_name = causative_variant_fixation_files, stringsAsFactors = FALSE)
# Initialize an empty list to store the selection model tables
fixation_data_causative_variant_tables <- list()

# Loop through each .tsv file
for (i in 1:length(sim_info$sim_name)) {
  # Get the file name
  file <- sim_info$file_name[i]
  file_path <- file.path(variant_freq_plots_dir,file)
  simname_from_file <- sim_info$sim_name[i]
  # Split the cleaned header into column names
  column_names <- c("allele_frequency")
  # Read the .tsv file into a data frame, using the cleaned column names
  allele_freq_data <- read.table(file_path, header = FALSE, comment.char = "", stringsAsFactors = FALSE, col.names = column_names, sep = " ")
  # Adding a "generation" column
  allele_freq_data$generation <- seq_len(nrow(allele_freq_data))
  # Calculate the fixation time of the causative variant
  fixation_time <- time_to_fixation(allele_freq_data)
  # Add simulation_number as an attribute to the data frame
  sim_num <- as.numeric(gsub(tolower(sim_number_pattern), "\\1", tolower(file)))
  attr(allele_freq_data, "Simulation_number") <- sim_num
  # Extract the selection scenario from the file name
  selection_scenario <- sub(tolower(".*(selection_model_s\\d+_chr\\d+).*"), "\\1", tolower(file))

  # Check if the selection coefficient already exists in the list
  if (!(selection_scenario %in% names(fixation_data_causative_variant_tables))) {
    # If it doesn't exist, create an empty data frame
    fixation_data_causative_variant_tables[[selection_scenario]] <- data.frame()
  }
  # Extract the selection coefficient from the file name
  selection_coefficient <- sub(tolower("^.*_(s\\d+_chr\\d+).*$"), "\\1", tolower(file))
  ###### Find the pruned counts for the current simulation  ######
  matching_simulation_prune_count_row <- non_fixated_causative_variant_count_tables[[selection_coefficient]][non_fixated_causative_variant_count_tables[[selection_coefficient]]$Sim_name == simname_from_file, ]
  # Extract the FREQUENCY of the matching row
  if (nrow(matching_simulation_prune_count_row) > 0) {
    non_fixated_causative_variant_count_simulation <- matching_simulation_prune_count_row$Non_fixated_variant_count
  } else {
    print("No matching row found")
  }

 # Create a list with table name and corresponding data frame
 table_info <- list(Sim_name = simname_from_file, filename = file,fixation_time = fixation_time, non_fixated_causative_variant_count = non_fixated_causative_variant_count_simulation, allele_freq_data = allele_freq_data) 
 # Append the table info to the list under selection_scenario
 fixation_data_causative_variant_tables[[selection_scenario]] <- c(fixation_data_causative_variant_tables[[selection_scenario]], list(table_info))
 }

# Calculate overall statistics for each selection coefficient
for (selection_scenario in names(fixation_data_causative_variant_tables)) {
  # Extract all tables for the current selection scenario
  tables <- fixation_data_causative_variant_tables[[selection_scenario]]
  # Calculate average fixation time
  all_fixation_times <- unlist(lapply(tables, function(table) table$fixation_time))
  avg_fixation_time <-  mean(all_fixation_times)
  min_fixation_time <- min(all_fixation_times)
  max_fixation_time <- max(all_fixation_times)
  all_non_fixation_events <- unlist(lapply(tables, function(table) table$non_fixated_causative_variant_count))
  fixation_probability <- length(tables) / (sum(all_non_fixation_events)+length(tables))
  # Store the calculated values back into the main list
  fixation_data_causative_variant_tables[[selection_scenario]]$Avg_fixation_time <- avg_fixation_time
  fixation_data_causative_variant_tables[[selection_scenario]]$Min_fixation_time <- min_fixation_time
  fixation_data_causative_variant_tables[[selection_scenario]]$Max_fixation_time <- max_fixation_time
  fixation_data_causative_variant_tables[[selection_scenario]]$Fixation_probability <- fixation_probability

}
#View(fixation_data_causative_variant_tables)
```

### 1.1.3: Variant Fixation Summary 
Summary of the (near) complete sweeps of the causative variant for the different selection models. 
The summarizing table below presents the following:

- **Column 1** shows the selection coefficient of the selection model.

- **Column 2** shows the fixation probability, i.e., the likelihood of a randomly selected causative variant to reach fixation at the predefined fixation threshold (`r fixation_threshold_causative_variant`) during a simulation run.

- **Columns 3-5** display fixation time statistics for these conditional simulations regarding the average, minimum and maximum number of generations required for fixation in the forward-in-time simulations. 

The table is sorted in ascending order by selection coefficient.

```{r 1.1.3: Variant Fixation Summary, echo = FALSE,warning = FALSE, results='asis'}
# Initialize an empty data frame to store the results
result_df <- data.frame()

# Loop through each selection scenario
for (selection_scenario in names(fixation_data_causative_variant_tables)) {
  # Extract selection coefficent from the selection scenario
  selection_coefficient <- sub(tolower("^.*_(s\\d+_chr\\d+)$"), "\\1", tolower(selection_scenario))
  # Formatting the selection coefficient for when displaying it. Removing "chr[0-9]" and adding a decimal point to the selection coefficient 
  formatted_selection_coefficient <- sub(tolower("^.*_s(0?)(\\d+)_chr\\d+$"), tolower("s=\\1.\\2"), tolower(selection_scenario))
  # Extract the average causative window length for the current selection scenario
  Avg_fixation_time <- fixation_data_causative_variant_tables[[selection_scenario]]$Avg_fixation_time
  Min_fixation_time <- fixation_data_causative_variant_tables[[selection_scenario]]$Min_fixation_time
  Max_fixation_time  <- fixation_data_causative_variant_tables[[selection_scenario]]$Max_fixation_time 
  Fixation_probability <- round(100*fixation_data_causative_variant_tables[[selection_scenario]]$Fixation_probability,1)
  # Add the selection scenario and average causative window length to the result data frame
  result_df <- rbind(result_df, data.frame(Selection_coefficient = formatted_selection_coefficient,Fixation_probability=Fixation_probability, Avg_Fixation_time = Avg_fixation_time, Min_fixation_time = Min_fixation_time,
  Max_fixation_time =  Max_fixation_time                                         
                                         ))
}
# Showing the average fixation time as an integer
result_df$Avg_Fixation_time <- round(result_df$Avg_Fixation_time,0)
# Sort the data frame based on average fixation time, in descending order
result_df_sorted <- result_df[order(-result_df$Avg_Fixation_time), ]
# Define the filename with the output directory path
filename <- file.path(output_dir, paste("Causative_variant_Fixation_summary",".csv", sep = ""))
# Write data to TSV file without quotes and with tab separation
write.table(result_df_sorted, file = filename, sep = ",", row.names = FALSE, quote = FALSE)

# Example usage with your first data frame
write_latex_table(
  data_frame = result_df,
  sort_column = "Avg_Fixation_time",
  output_dir = output_dir,
  output_filename = "Causative_variant_Fixation_summary"
)
# Print the table using kable
kable(result_df_sorted)
```

## 1.2: Causative Variant Windows
This section presents the *causative variant window* for each selection model. This window is initially defined by a subwindow consisting of a 100 kbp region centered around the causative variant (referred to as the *Original 100 kbp Causative Variant Subwindow*), where the average ROH frequency of this subwindow is referred to as the *initial threshold*.
The window then expands upstream and downstream until the ROH frequency in both directions drops more than 10 percentage points below the *initial threshold*. In other words, this window captures the region impacted by the causative variant under selection and is designed to mimic the characteristics of ROH hotspot regions.

<!-- ### 1.2.1: Variant position  --> 

```{r 1.2.1: Variant position, echo = FALSE,results= 'hide',warning = FALSE}
# setwd(variant_position_dir)
# Pattern for finding files containing "causative_variant_window_lengths" and ending with ".tsv"
pattern <- ".*variant_position.*\\.tsv$"
causative_variant_position_files <- list.files(path = variant_position_dir, pattern = pattern)
# Extract simulation numbers from the filename
sim_number_pattern <- ".*sim_(\\d+)_.*"
sim_name_pattern <- "^(.*)\\.tsv$"
sim_numbers <- as.numeric(gsub(tolower(sim_number_pattern), "\\1", tolower(causative_variant_position_files)))
sim_name <- sub(tolower("^(.*?)_causative_variant_window.*"), "\\1", tolower(causative_variant_position_files))
# Combine simulation name, number, and file name
sim_info <- data.frame(sim_name = sim_name, file_name = causative_variant_position_files, stringsAsFactors = FALSE)
# Initialize an empty list to store the selection model tables
position_causative_variant_tables <- list()

# Loop through each .tsv file
for (i in 1:length(sim_info$sim_name)) {
  # Get the file name
  file <- sim_info$file_name[i]
  file_path <- file.path(variant_position_dir,file)
  column_names <- c("Sim_name","Variant_Position")
  # Read the .tsv frequency file into a data frame
  causative_variant_position_data <- read.table(file_path, header = FALSE, comment.char = "#", stringsAsFactors = FALSE,col.names = column_names, sep = "\t")
  # Add simulation_number as an attribute to the data frame
  sim_num <- as.numeric(gsub(tolower(sim_number_pattern), "\\1", tolower(file)))
  attr(causative_variant_position_data, "Simulation_number") <- sim_num
  # Extract the selection coefficient from the file name
  selection_coefficient <- sub(tolower("^.*_(s\\d+_chr\\d+).*$"), "\\1", tolower(file))
  # Check if the selection coefficient already exists in the list
  if (!(selection_coefficient %in% names(position_causative_variant_tables))) {
    # If it doesn't exist, create an empty data frame
    position_causative_variant_tables[[selection_coefficient]] <- data.frame()
  }
  # Append the data frame to the list under the selection coefficient
  position_causative_variant_tables[[selection_coefficient]] <- rbind(position_causative_variant_tables[[selection_coefficient]], causative_variant_position_data)
}

#View(position_causative_variant_tables)
```

<!-- ### 1.2.2: Window lengths  -->

```{r 1.2.2: Window lengths, echo = FALSE,results= 'hide',warning = FALSE}
# setwd(Selection_causative_variant_windows_dir)
# Pattern for finding files containing "causative_variant_window_lengths" and ending with ".tsv"
pattern <- ".*causative_variant_window_lengths.*\\.tsv$"
causative_variant_window_lengths_files <- list.files(path = Selection_causative_variant_windows_dir, pattern = pattern)
# Extract simulation numbers from the filename
sim_number_pattern <- ".*sim_(\\d+)_.*"
sim_numbers <- as.numeric(gsub(tolower(sim_number_pattern), "\\1", tolower(causative_variant_window_lengths_files)))
sim_name <- sub(tolower("^(.*?)_causative_variant_window.*"), "\\1", tolower(causative_variant_window_lengths_files))
# Combine simulation name, number, and file name
sim_info <- data.frame(sim_name = sim_name, file_name = causative_variant_window_lengths_files, stringsAsFactors = FALSE)
# Initialize an empty list to store the selection model tables
window_lengths_causative_variant_tables <- list()

# Loop through each .tsv file
for (i in 1:length(sim_info$sim_name)) {
  # Get the file name
  file <- sim_info$file_name[i]
  file_path <- file.path(Selection_causative_variant_windows_dir,file)
  # Read the header line
  con <- file(file_path, "r")
  header <- readLines(con, n = 1)
  close(con)
  # Remove "#" from the header
  clean_header <- gsub("^#", "", header)
  # Split the cleaned header into column names
  column_names <- strsplit(sub("#", "", header), "\t")[[1]]
  # Read the .tsv file into a data frame, using the cleaned column names
  causative_variant_window_lengths_data <- read.table(file_path, header = FALSE, comment.char = "#", stringsAsFactors = FALSE,col.names = column_names, sep = "\t")
  # Alter the column names manually
  colnames(causative_variant_window_lengths_data) <- c("Simulation_name", "Length_bp")
  # Add simulation_number as an attribute to the data frame
  sim_num <- as.numeric(gsub(tolower(sim_number_pattern), "\\1", tolower(file)))
  attr(causative_variant_window_lengths_data, "Simulation_number") <- sim_num
  # Extract the selection coefficient from the file name
  selection_coefficient <- sub(tolower("^.*_(s\\d+_chr\\d+).*$"), "\\1", tolower(file))

  # Check if the selection coefficient already exists in the list
  if (!(selection_coefficient %in% names(window_lengths_causative_variant_tables))) {
    # If it doesn't exist, create an empty data frame
    window_lengths_causative_variant_tables[[selection_coefficient]] <- data.frame()
  }
  # Append the data frame to the list under the selection coefficient
  window_lengths_causative_variant_tables[[selection_coefficient]] <- rbind(window_lengths_causative_variant_tables[[selection_coefficient]], causative_variant_window_lengths_data)
}

#View(window_lengths_causative_variant_tables)
```

### 1.2.3: ROH Frequency

To see ROH-frequency plots of the created Causative Variant Windows, uncomment the block of code between "Start plot code" and "End plot code" and then rerun the script.

```{r 1.2.3: ROH Frequency, echo = FALSE,warning = FALSE, results='asis'}
# setwd(Selection_causative_variant_windows_dir)
# Pattern for finding files containing "causative_variant_window" and ending with ".bed"
pattern <- ".*causative_variant_window.*\\.bed$"
selection_model_causative_variant_window_files <- list.files(path = Selection_causative_variant_windows_dir, pattern = pattern)
# Extract simulation numbers from the filename
sim_number_pattern <- ".*sim_(\\d+)_.*" 
sim_numbers <- as.numeric(gsub(tolower(sim_number_pattern), "\\1", tolower(selection_model_causative_variant_window_files)))
sim_name <- sub(tolower("^(.*?)_causative_variant_window.*"), "\\1", tolower(selection_model_causative_variant_window_files))
# Preallocate sim_info as an empty data frame
sim_info <- data.frame(sim_name = character(), simulation_number = numeric(), file_name = character(), stringsAsFactors = FALSE)
# Combine simulation name, number, and file name
sim_info <- data.frame(sim_name = sim_name, simulation_number = sim_numbers, file_name =selection_model_causative_variant_window_files)
sim_info <- sim_info[order(sim_info$simulation_number), ]
# Initialize an empty list to store the selection model tables
causative_variant_window_tables_Selection_Model <- list()

# Loop through each sorted .tsv file
for (i in 1:length(sim_info$sim_name)) {
  # Get the file name
  file <- sim_info$file_name[i]
  file_path <- file.path(Selection_causative_variant_windows_dir,file)
  # Extract simname from the file name
  simname_from_file <- sub(tolower("^(.*?)_causative_variant_window.*"), "\\1", tolower(file))
  # Check if the simname from the file matches with the simname from the dataframe
  if (simname_from_file != sim_info$sim_name[i]) {
    print(paste0("simname_from_file:", simname_from_file))
    print(paste0("sim_info$sim_name[i]:", sim_info$sim_name[i]))
    stop("Error: Simname from file does not match with simname from dataframe.")
  }
  # Read the header line
  con <- file(file_path, "r")
  header <- readLines(con, n = 1)
  close(con)
  # Remove "#" from the header
  clean_header <- gsub("^#", "", header)
  separator_causative_variant_window_file <- "\t"
  # Split the cleaned header into column names
  column_names <- strsplit(clean_header, separator_causative_variant_window_file)[[1]]
  # Read the .tsv frequency file into a data frame
  causative_variant_window_data <- read.table(file_path, header = FALSE, comment.char = "#", stringsAsFactors = FALSE, col.names = column_names,sep = separator_causative_variant_window_file)
  min_freq <- min(causative_variant_window_data[["FREQUENCY"]])
  max_freq <- max(causative_variant_window_data[["FREQUENCY"]])
  average_freq <- mean(causative_variant_window_data[["FREQUENCY"]])
  causative_variant_window_data[["FREQUENCY"]]
  # Add simulation_number as an attribute to the data frame
  sim_num <- as.numeric(gsub(tolower(sim_number_pattern), "\\1", tolower(file)))
  attr(causative_variant_window_data, "Simulation_number") <- sim_num
  # Extract the selection scenario from the file name
  selection_scenario <- sub(tolower(".*(selection_model_s\\d+_chr\\d+).*"), "\\1", tolower(file))
  # Check if the selection coefficient already exists in the list
  if (!(selection_scenario %in% names(causative_variant_window_tables_Selection_Model))) {
    # If it doesn't exist, create a list for it
    causative_variant_window_tables_Selection_Model[[selection_scenario]] <- list()
  }
  # Extract selection coefficent from the selection scenario
  selection_coefficient <- sub(tolower("^.*_(s\\d+_chr\\d+)$"), "\\1", tolower(selection_scenario))
  ###### Find the window_lengths of the causative variant in this window!! ######
  # Directly find the row where Simulation.name matches simname_from_file
  matching_causative_variant_window_row <- window_lengths_causative_variant_tables[[selection_coefficient]][window_lengths_causative_variant_tables[[selection_coefficient]]$Simulation_name == simname_from_file, ]
  # Extract the Variant_Position for the matching row
  if (nrow(matching_causative_variant_window_row) > 0) {
    length_bp_value <- matching_causative_variant_window_row$Length_bp
    # print(variant_position)
  } else {
    print("No matching row found for matching_causative_variant_window_row ")
  }
  ###### Find the position of the causative variant  ######
  # Find the row that matches simname_from_file
  matching_causative_variant_position_row <- position_causative_variant_tables[[selection_coefficient]][
    position_causative_variant_tables[[selection_coefficient]]$Sim_name == simname_from_file, ]
  # Extract the Variant_Position for the matching row
  if (nrow(matching_causative_variant_position_row) > 0) {
    variant_position <- matching_causative_variant_position_row$Variant_Position
    # print(variant_position)
  } else {
    print("No matching row found for matching_causative_variant_position_row")
  }
  ###### Find the frequency of the window the causative variant lies in  ######
  # Find the row where POS1 <= variant_position <= POS2
  matching_row_causative_variant_freq <- causative_variant_window_data[
    causative_variant_window_data$POS1 <= variant_position & causative_variant_window_data$POS2 >= variant_position, ]
  # Extract the FREQUENCY of the matching row
  if (nrow(matching_row_causative_variant_freq) > 0) {
    variant_100k_window_frequency <- matching_row_causative_variant_freq$FREQUENCY
  } else {
    print("No matching row found")
  }
  

# ###### Uncomment code below to generate ROH-frequency plot of each Causative Variant Window ######
# ######  Start plot code ###### 
# # Create scatter plot
# plot(causative_variant_window_data[["POS1"]],
#      causative_variant_window_data[["FREQUENCY"]],
#      main = paste("Causative Variant Window plot for", simname_from_file),
#      xlab = "POS1", ylab = "Frequency",
#      col = "blue", pch = 16)
# # Add horizontal line for variant_100k_subwindow_frequency
# abline(h = variant_100k_window_frequency, col = "red")
# # Add a point for the causative variant window
# points(matching_row_causative_variant_freq$POS1, variant_100k_window_frequency, col = "cyan", pch = 16)
# legend("topright", legend = paste("Causative Variant 100k Window Freq:", variant_100k_window_frequency),
#        col = rgb(0, 1, 1, alpha = 0.5), pch = 16, text.font = 2, cex = 0.7)
# ######  End plot code ###### 



# Create a list with table name and corresponding data frame
table_info <- list(Sim_name = simname_from_file, filename = file, length_bp = length_bp_value,
                     min_freq = min_freq,max_freq = max_freq,avg_freq = average_freq,variant_position = variant_position, variant_100k_subwindow_frequency = variant_100k_window_frequency,
                     causative_window_data = causative_variant_window_data)  # Added ROH_Hotspot_threshold here
# Append the table info to the list under selection_scenario
causative_variant_window_tables_Selection_Model[[selection_scenario]] <- c(causative_variant_window_tables_Selection_Model[[selection_scenario]], list(table_info))
}

```

 <!-- #### 1.2.3.1: Calculating Summary Statistics  --> 

```{r 1.2.3.1: Calculating Summary Statistics, echo = FALSE, warning = FALSE}
# Calculate overall statistics for each selection coefficient
for (selection_scenario in names(causative_variant_window_tables_Selection_Model)) {
  # Extract all tables for the current selection scenario
  tables <- causative_variant_window_tables_Selection_Model[[selection_scenario]]
  # Calculate average length in bp
  all_causative_window_lengths_bp <- unlist(lapply(tables, function(table) table$length_bp))
  # Calculate minimum window frequency
  all_causative_window_min_freq <- unlist(lapply(tables, function(table) table$min_freq))
  # Calculate maximum window frequency
  all_causative_window_max_freq <- unlist(lapply(tables, function(table) table$max_freq))
  # Calculate mean window frequency
  all_causative_window_avg_freq <- unlist(lapply(tables, function(table) table$avg_freq))
  # Calculate average variant_100k_subwindow_frequency:
  all_variant_100k_subwindow_frequencies <- unlist(lapply(tables, function(table) table$variant_100k_subwindow_frequency))
  # Store the calculated values back into the main list
  causative_variant_window_tables_Selection_Model[[selection_scenario]]$Avg_causative_window_length_bp <- mean(all_causative_window_lengths_bp)
  causative_variant_window_tables_Selection_Model[[selection_scenario]]$Avg_causative_window_length_Mb <- mean(all_causative_window_lengths_bp) / 1e6
  causative_variant_window_tables_Selection_Model[[selection_scenario]]$Min_causative_window_freq <- min(all_causative_window_min_freq)
  causative_variant_window_tables_Selection_Model[[selection_scenario]]$Max_causative_window_freq <- max(all_causative_window_max_freq)
  causative_variant_window_tables_Selection_Model[[selection_scenario]]$Avg_causative_window_freq <- mean(all_causative_window_avg_freq)
  causative_variant_window_tables_Selection_Model[[selection_scenario]]$Avg_variant_100k_subwindow_frequency <- mean(all_variant_100k_subwindow_frequencies)
  
  causative_variant_window_tables_Selection_Model[[selection_scenario]]$Window_length_bp_CI <- standard_error_confidence_interval_fun(all_causative_window_lengths_bp)
  causative_variant_window_tables_Selection_Model[[selection_scenario]]$Window_length_Mb_CI <- standard_error_confidence_interval_fun(all_causative_window_lengths_bp/1e6)
  
  causative_variant_window_tables_Selection_Model[[selection_scenario]]$Avg_ROH_freq_CI <- standard_error_confidence_interval_fun(100*all_causative_window_avg_freq)
  causative_variant_window_tables_Selection_Model[[selection_scenario]]$subwindow_Avg_ROH_freq_CI <- standard_error_confidence_interval_fun(100*all_variant_100k_subwindow_frequencies)
  
}
```

### 1.2.4: Expected Heterozygosity ($H_{e}$) - Causative Variant Windows

```{r 1.2.4: Expected Heterozygosity - Causative Variant Windows, echo = FALSE, warning = FALSE, results='asis'}
# setwd(causative_variant_windows_H_e_dir)
# Pattern for finding files containing "avg_H_e" and ending with ".tsv"
pattern <- ".*avg_H_e.*\\.tsv$"
causative_variant_window_H_e_files <- list.files(path = causative_variant_windows_H_e_dir, pattern = pattern)

# Extract simulation numbers from the filename
sim_number_pattern <- ".*sim_(\\d+)_.*"
sim_numbers <- as.numeric(gsub(tolower(sim_number_pattern), "\\1", tolower(causative_variant_window_H_e_files)))
sim_name <- sub(tolower("^(.*?)_causative_variant_window.*"), "\\1", tolower(causative_variant_window_H_e_files))
# Combine simulation name, number, and file name
sim_info <- data.frame(sim_name = sim_name, file_name = causative_variant_window_H_e_files, stringsAsFactors = FALSE)
# Initialize an empty list to store the selection model tables
window_H_e_causative_variant_tables <- list()

# Loop through each .tsv file
for (i in 1:length(sim_info$sim_name)) {
  # Get the file from the filename and direcotry path
  file <- sim_info$file_name[i]
  file_path <- file.path(causative_variant_windows_H_e_dir,file)
  # Read the .tsv file into a data frame, using the cleaned column names
  causative_variant_window_H_e_data <- read.table(file_path, header = TRUE, comment.char = "#", stringsAsFactors = FALSE, sep = "\t")
  # Extract the selection coefficient from the file name
  selection_coefficient <- sub(tolower("^.*_(s\\d+_chr\\d+).*$"), "\\1",tolower(file))
  # Check if the selection coefficient already exists in the list
  if (!(selection_coefficient %in% names(window_H_e_causative_variant_tables))) {
    # If it doesn't exist, create an empty data frame
    window_H_e_causative_variant_tables[[selection_coefficient]] <- data.frame()
  }
  # Create a list with table name and corresponding data frame
  table_info <- list(filename=file, data =causative_variant_window_H_e_data) 
  # Append the table info to the list under selection_scenario
  window_H_e_causative_variant_tables[[selection_coefficient]] <- c(window_H_e_causative_variant_tables[[selection_coefficient]], table_info)

}

# Loop through each selection_coefficient and compute Standard Error confidence intervals for the 5th percentile
for (selection_coefficient in names(window_H_e_causative_variant_tables)) {
  All_Population_Causative_window_Avg_H_e <- window_H_e_causative_variant_tables[[selection_coefficient]][["data"]][["Avg_He"]]
  # Remove any non-numeric values
  All_Population_Causative_window_Avg_H_e <- All_Population_Causative_window_Avg_H_e[!is.na(All_Population_Causative_window_Avg_H_e) & is.numeric(All_Population_Causative_window_Avg_H_e)]
  # Calculate the point estimate H_e across all technical replicates simulations for the current selection coefficient
  window_H_e_causative_variant_tables[[selection_coefficient]]$Estimated_Mean_Population_H_e <-
  mean(All_Population_Causative_window_Avg_H_e)
  # Calculate the standard error-based confidence interval of the point estimate H_e across all technical replicates simulations for the current selection coefficient
  # Store the standard error-based confidence interval in the window_H_e_causative_variant_tables table
  window_H_e_causative_variant_tables[[selection_coefficient]]$SE_CI_Estimated_Mean_Population_H_e <- standard_error_confidence_interval_fun(All_Population_Causative_window_Avg_H_e)  
  # # Print the Point estimate of H_e across all technical replicates simulations
  # cat("Point estimate H_e across all technical replicates simulations for ",selection_coefficient,":", window_H_e_causative_variant_tables[[selection_coefficient]]$Estimated_Mean_Population_H_e, "//n")
  # print(paste("standard error-based 95% Confidence Interval: [", 
  # window_H_e_causative_variant_tables[[selection_coefficient]]$SE_CI_Estimated_Mean_Population_H_e[1], ", ", 
  # window_H_e_causative_variant_tables[[selection_coefficient]]$SE_CI_Estimated_Mean_Population_H_e[2], "]", sep = ""))
}
# View(window_H_e_causative_variant_tables)
```

### 1.2.5: Causative Variant Windows - Summary
Summary of causative variant windows from the simulated selection scenarios, presenting
averages and confidence intervals (CI) for window length, ROH frequency and expected
heterozygosity $H_{e}$. The table also includes minimum and maximum ranges of ROH frequency values
and shows the average ROH frequency and its CI for the *Original 100 kbp Causative Variant Subwindow*. The table is sorted in ascending order by selection coefficient.

```{r 1.2.5: Causative Variant Windows - Summary, echo = FALSE,warning = FALSE, results='asis'}
setwd(output_dir)
# Initialize an empty data frame to store the results
causative_variant_window_results_df <- data.frame()

# Loop through each selection scenario
for (selection_scenario in names(causative_variant_window_tables_Selection_Model)) {
  for (sel_coeff in names(window_H_e_causative_variant_tables)) {
      if (sub(tolower("selection_model_"), "", tolower(selection_scenario)) == tolower(sel_coeff)) {
        causative_window_avg_H_e <- round(window_H_e_causative_variant_tables[[sel_coeff]][["Estimated_Mean_Population_H_e"]],H_e_values_decimals)
        causative_window_avg_H_e_lower_CI <- round(window_H_e_causative_variant_tables[[sel_coeff]][["SE_CI_Estimated_Mean_Population_H_e"]][1],H_e_values_decimals)
        causative_window_avg_H_e_upper_CI <- round(window_H_e_causative_variant_tables[[sel_coeff]][["SE_CI_Estimated_Mean_Population_H_e"]][2],H_e_values_decimals)
      }
    }
  # Extract selection coefficent from the selection scenario
  selection_coefficient <- sub(tolower("^.*_(s\\d+_chr\\d+)$"), "\\1", tolower(selection_scenario))
  # Formatting the selection coefficient for when displaying it. Removing "chr[0-9]" and adding a decimal point to the selection coefficient 
  formatted_selection_coefficient <- sub(tolower("^.*_s(0?)(\\d+)_chr\\d+$"), tolower("s=\\1.\\2"), tolower(selection_scenario))
  # Extract the average causative window length for the current selection scenario
  avg_causative_window_length <- round(causative_variant_window_tables_Selection_Model[[selection_scenario]]$Avg_causative_window_length_Mb,Window_lengths_decimals)
 causative_window_length_lower_ci <- round(causative_variant_window_tables_Selection_Model[[selection_scenario]]$Window_length_Mb_CI[1],Window_lengths_decimals)
 causative_window_length_upper_ci <- round(causative_variant_window_tables_Selection_Model[[selection_scenario]]$Window_length_Mb_CI[2],Window_lengths_decimals)
  
  Min_window_freq <- round(100*causative_variant_window_tables_Selection_Model[[selection_scenario]]$Min_causative_window_freq,ROH_frequency_decimals) 
  Max_window_freq <- round(100*causative_variant_window_tables_Selection_Model[[selection_scenario]]$Max_causative_window_freq,ROH_frequency_decimals)
  Avg_window_freq <- round(100*causative_variant_window_tables_Selection_Model[[selection_scenario]]$Avg_causative_window_freq,ROH_frequency_decimals)
  Avg_freq_variant_100k_window <- round(100*causative_variant_window_tables_Selection_Model[[selection_scenario]]$Avg_variant_100k_subwindow_frequency,ROH_frequency_decimals)
  ROH_freq_lower_CI <- round(causative_variant_window_tables_Selection_Model[[selection_scenario]]$Avg_ROH_freq_CI[1],ROH_frequency_decimals)
  ROH_freq_upper_CI <- round(causative_variant_window_tables_Selection_Model[[selection_scenario]]$Avg_ROH_freq_CI[2],ROH_frequency_decimals)

  subwindow_ROH_freq_lower_CI <- round(causative_variant_window_tables_Selection_Model[[selection_scenario]]$subwindow_Avg_ROH_freq_CI[1],ROH_frequency_decimals)
  subwindow_ROH_freq_upper_CI <- round(causative_variant_window_tables_Selection_Model[[selection_scenario]]$subwindow_Avg_ROH_freq_CI[2],ROH_frequency_decimals)
# Add the selection scenario and average causative window length to the result data frame
causative_variant_window_results_df <- rbind(causative_variant_window_results_df, data.frame(Sel.coeff = formatted_selection_coefficient, Length_Mb = avg_causative_window_length,Length_lower_CI = causative_window_length_lower_ci,Length_Upper_CI = causative_window_length_upper_ci,
  ROH_freq = Avg_window_freq,ROH_freq_lower_CI = ROH_freq_lower_CI,ROH_freq_upper_CI = ROH_freq_upper_CI , Min_freq = Min_window_freq,
  Max_freq =  Max_window_freq,
  variant_subwindow_freq = Avg_freq_variant_100k_window, variant_subwindow_freq_lower_CI = subwindow_ROH_freq_lower_CI, variant_subwindow_freq_upper_CI = subwindow_ROH_freq_upper_CI,
  Avg_H_e=causative_window_avg_H_e,H_e_lower_CI = causative_window_avg_H_e_lower_CI, H_e_upper_CI=causative_window_avg_H_e_upper_CI      ))
}
# Formatting the length  column to 2 decimals
causative_variant_window_results_df$Length_Mb <- round(causative_variant_window_results_df$Length_Mb,Window_lengths_decimals)
# Sort the data frame based on the average length of the causative window of each selection coefficient
causative_variant_window_results_df_sorted <- causative_variant_window_results_df[order(causative_variant_window_results_df$Sel.coeff), ]
# Define the filename with the output directory path
filename <- file.path(output_dir, paste("Causative_variant_windows_summary",".csv", sep = ""))
# Write data to TSV file without quotes and with tab separation
write.table(causative_variant_window_results_df_sorted, file = filename, sep = ",", row.names = FALSE, quote = FALSE)
# Example usage with your second data frame
write_latex_table(
  data_frame = causative_variant_window_results_df,
  sort_column = "Sel.coeff",
  output_dir = output_dir,
  output_filename = "Causative_variant_windows_summary"
)
# Print the table using kable
kable(causative_variant_window_results_df_sorted,row.names = FALSE)
```

# 2: ROH Frequency

## 2.1: Autosomal Genomewide ROH Frequencies


<!-- ### 2.1.1: Empirical - ROH frequency  --> 

```{r 2.1.1: Empirical - ROH frequency,echo = FALSE,results= 'hide',warning = FALSE}
# setwd(Empirical_data_autosome_ROH_freq_dir)
# Pattern for finding files containing "F_ROH" and ending with ".tsv"
pattern <- ".*ROH_freq.*\\.tsv$"
population_ROH_freq_files <- list.files(path = Empirical_data_autosome_ROH_freq_dir, pattern = pattern)

#population_ROH_freq_files
# Extracting the ROH-hotspot threshold value from the suffix of the filename
parts <- unlist(strsplit(population_ROH_freq_files[1], "threshold_")) # Split the string by "threshold_"
# Extract the decimal number using regular expressions
Empirical_data_ROH_hotspot_threshold <- as.numeric(gsub("\\.tsv", "", unlist(strsplit(parts[length(parts)], "_"))[1]))
# Extract chromosome numbers from filenames
chr_numbers <- as.numeric(gsub(tolower(".*CHR(\\d+)_.*"), "\\1", tolower(population_ROH_freq_files)))
# cat("CHR Values:", chr_numbers, "\n")
# Sort filenames based on chromosome numbers
sorted_population_ROH_freq_files <- population_ROH_freq_files[order(chr_numbers)]
# Initialize an empty list to store the ROH-frequency data
ROH_freq_table_Empirical_Data <- list()

# Loop through each sorted .tsv file
for (file in sorted_population_ROH_freq_files) {
  file_name <- file
  file_path <- file.path(Empirical_data_autosome_ROH_freq_dir,file) 
  ROH_freq_data <- read.table(file_path, header = TRUE, comment.char = "#", stringsAsFactors = FALSE, sep = "\t")
  ROH_freq_data <- ROH_freq_data[1:(nrow(ROH_freq_data)/2), ]
  # Renaming POS to POS1 and add POS2 = POS1 + 1e5
  ROH_freq_data <- transform(ROH_freq_data, POS1 = POS, POS2 = POS + 1e5 -1)
  # Remove the original POS column
  ROH_freq_data <- ROH_freq_data[, c("CHR", "POS1", "POS2", "COUNT", "FREQUENCY")]
  # Add chromosome_name as an attribute to the data frame
  chr_num <- as.numeric(gsub(tolower(".*CHR(\\d+)_.*"), "\\1", tolower(file)))
  attr(ROH_freq_data, "chromosome_name") <- chr_num
  # Create a list with table name and corresponding data frame
  table_info <- list(chromosome_name = chr_num, filename = file_name, data = ROH_freq_data)  # Added chromosome_name here
  # Append the table info to the list
  ROH_freq_table_Empirical_Data <- c(ROH_freq_table_Empirical_Data, list(table_info))
}
ROH_freq_table_Empirical_Data$ROH_hotspot_threshold <- Empirical_data_ROH_hotspot_threshold
# View(ROH_freq_table_Empirical_Data)
```

<!-- ### 2.1.2: Neutral Model - ROH frequency  --> 

```{r 2.1.2: Neutral Model - ROH frequency,echo = FALSE,results= 'hide',warning = FALSE}
# setwd(Neutral_model_autosome_ROH_freq_dir)
# Pattern for finding files containing "F_ROH" and ending with """.tsv"""
pattern <- ".*ROH_freq.*\\.tsv$"
neutral_model_ROH_freq_files <- list.files(path = Neutral_model_autosome_ROH_freq_dir, pattern = pattern)
# Extract simulation numbers from the filename
sim_number_pattern <- ".*sim_(\\d+)_.*" 
sim_numbers <- as.numeric(gsub(tolower(sim_number_pattern), "\\1", tolower(neutral_model_ROH_freq_files)))
# cat("CHR Values:", chr_numbers, "\n")
# Sort filenames based on chromosome numbers
sorted_neutral_model_ROH_freq_files <- neutral_model_ROH_freq_files[order(sim_numbers)]
# Initialize an empty list to store the ROH-frequency data
ROH_freq_tables_Neutral_Model <- list()



# Loop through each sorted .tsv file
for (file in sorted_neutral_model_ROH_freq_files) {
  # Extracting the ROH-hotspot threshold value from the suffix of the filename
  parts <- unlist(strsplit(file, "threshold_")) # Split the string by "threshold_"
  file_path <- file.path(Neutral_model_autosome_ROH_freq_dir,file)
  # Extract the decimal number using regular expressions
  simulation_ROH_hotspot_threshold <- as.numeric(gsub("\\.tsv", "", unlist(strsplit(parts[length(parts)], "_"))[1]))
  ROH_freq_data <- read.table(file_path, header = TRUE, comment.char = "#", stringsAsFactors = FALSE, sep = "\t")
  ROH_freq_data <- ROH_freq_data[1:(nrow(ROH_freq_data)/2), ]
  # Renaming POS to POS1 and add POS2 = POS1 + 1e5
  ROH_freq_data <- transform(ROH_freq_data, POS1 = POS, POS2 = POS + 1e5 -1)
  # Remove the original POS column
  ROH_freq_data <- ROH_freq_data[, c("CHR", "POS1", "POS2", "COUNT", "FREQUENCY")]
  # Add chromosome_name as an attribute to the data frame
  sim_num <- as.numeric(gsub(tolower(sim_number_pattern), "\\1", tolower(file)))
  attr(ROH_freq_data, "Simulation_number") <- sim_num
  # Create a list with table name and corresponding data frame
  table_info <- list(Simulation_number = sim_num, filename = file, data = ROH_freq_data,ROH_Hotspot_threshold = simulation_ROH_hotspot_threshold)  # Added chromosome_name here
  # Append the table info to the list
  ROH_freq_tables_Neutral_Model <- c(ROH_freq_tables_Neutral_Model, list(table_info))
}
# Extract all ROH-hotspot thresholds from ROH_freq_tables_Neutral_Model
all_ROH_hotspot_thresholds <- unlist(lapply(ROH_freq_tables_Neutral_Model, function(table) table$ROH_Hotspot_threshold))
# Calculate the overall average F_ROH
Avg_ROH_hotspot_threshold <- mean(all_ROH_hotspot_thresholds)
ROH_freq_tables_Neutral_Model$Avg_ROH_hotspot_threshold <- Avg_ROH_hotspot_threshold
# Calculate the confidence interval of the point estimate ROH-hotspot threshold across all technical replicates simulations
ROH_freq_tables_Neutral_Model$SE_CI_ROH_hotspot_threshold <- standard_error_confidence_interval_fun(all_ROH_hotspot_thresholds)
#View(ROH_freq_tables_Neutral_Model)
```

<!-- ### 2.1.3: Selection Models - ROH frequency  --> 

```{r 2.1.3: Selection Models - ROH frequency,echo = FALSE,results= 'hide',warning = FALSE}
# Set the working directory to the directory containing the selection model ROH frequency files
# setwd(Selection_model_autosome_ROH_freq_dir)
# Pattern for finding files containing "ROH_freq" and ending with ".tsv"
pattern <- ".*ROH_freq.*\\.tsv$"
selection_model_ROH_freq_files <- list.files(path = Selection_model_autosome_ROH_freq_dir, pattern = pattern)


# Extract simulation numbers from the filename
sim_number_pattern <- ".*sim_(\\d+)_.*" 
sim_numbers <- as.numeric(gsub(tolower(sim_number_pattern), "\\1", tolower(selection_model_ROH_freq_files)))
sim_name <- sub(tolower("^(.*?)_ROH_freq.*"), "\\1", tolower(selection_model_ROH_freq_files))
# Preallocate sim_info as an empty data frame
sim_info <- data.frame(sim_name = character(), simulation_number = numeric(), file_name = character(), stringsAsFactors = FALSE)
# Combine simulation name, number, and file name
sim_info <- data.frame(sim_name = sim_name, simulation_number = sim_numbers, file_name =selection_model_ROH_freq_files)
sim_info <- sim_info[order(sim_info$simulation_number), ]
# Initialize an empty list to store the selection model tables
ROH_freq_tables_Selection_Model <- list()

# Loop through each sorted .tsv file
for (i in 1:length(sim_info$sim_name)) {
  # Get the file name
  file <- sim_info$file_name[i]
  file_path <- file.path(Selection_model_autosome_ROH_freq_dir,file)
  # Extract simname from the file name
  simname_from_file <- sub(tolower("^(.*?)_ROH_freq.*"), "\\1", tolower(file))
  # Check if the simname from the file matches with the simname from the dataframe
  if (simname_from_file != sim_info$sim_name[i]) {
    print(paste0("simname_from_file:", simname_from_file))
    print(paste0("sim_info$sim_name[i]:", sim_info$sim_name[i]))
    stop("Error: Simname from file does not match with simname from dataframe.")
  }
  # Extracting the ROH-hotspot threshold value from the suffix of the filename
  parts <- unlist(strsplit(file, "threshold_")) # Split the string by "threshold_"
  # Extract the decimal number using regular expressions
  simulation_ROH_hotspot_threshold <- as.numeric(gsub("\\.tsv", "", unlist(strsplit(parts[length(parts)], "_"))[1]))
  ROH_freq_data <- read.table(file_path, header = TRUE, comment.char = "#", stringsAsFactors = FALSE, sep = "\t")
  ROH_freq_data <- ROH_freq_data[1:(nrow(ROH_freq_data)/2), ]
  # Renaming POS to POS1 and add POS2 = POS1 + 1e5
  ROH_freq_data <- transform(ROH_freq_data, POS1 = POS, POS2 = POS + 1e5 -1)
  # Remove the original POS column
  ROH_freq_data <- ROH_freq_data[, c("CHR", "POS1", "POS2", "COUNT", "FREQUENCY")]
  # Add simulation_number as an attribute to the data frame
  sim_num <- as.numeric(gsub(tolower(sim_number_pattern), "\\1", tolower(file)))
  attr(ROH_freq_data, "Simulation_number") <- sim_num
  # Extract the selection coefficient from the file name
  selection_coefficient <- sub(tolower(".*(selection_model_s\\d+_chr\\d+).*"), "\\1", tolower(file))
  # Check if the selection coefficient already exists in the list
  if (!(selection_coefficient %in% names(ROH_freq_tables_Selection_Model))) {
    # If it doesn't exist, create a list for it
    ROH_freq_tables_Selection_Model[[selection_coefficient]] <- list()
  }
  table_info
  # Create a list with table name and corresponding data frame
  table_info <- list(Simulation_number = sim_num, filename = file,ROH_Hotspot_threshold =    simulation_ROH_hotspot_threshold, data = ROH_freq_data)  # Added ROH_Hotspot_threshold here
  # Append the table info to the list under selection_coefficient
  ROH_freq_tables_Selection_Model[[selection_coefficient]] <- c(ROH_freq_tables_Selection_Model[[selection_coefficient]], list(table_info))
}

# Calculate overall average ROH hotspot threshold for each selection coefficient
for (selection_coefficient in names(ROH_freq_tables_Selection_Model)) {
  all_thresholds <- unlist(lapply(ROH_freq_tables_Selection_Model[[selection_coefficient]], function(table) table$ROH_Hotspot_threshold))
  overall_avg_threshold <- mean(all_thresholds)
  ROH_freq_tables_Selection_Model[[selection_coefficient]]$Avg_ROH_hotspot_threshold <- overall_avg_threshold
  # Calculate the confidence interval of the point estimate ROH-hotspot threshold across all technical replicates simulations
  ROH_freq_tables_Selection_Model[[selection_coefficient]]$SE_CI_ROH_hotspot_threshold <- standard_error_confidence_interval_fun(all_thresholds)
}
# View the resulting nested structure
#View(ROH_freq_tables_Selection_Model)
```

## 2.2: ROH Hotspot Threshold Summary
The following table shows a comparison between the empirical ROH hotspot-threshold and each simulation model type.
Lower CI and Upper CI correspond to the standard-error based confidence intervals of the ROH hotspot threshold with a confidence level of 95%.
```{r 2.2: ROH hotspot threshold Summary, echo = FALSE,warning = FALSE, results='asis'}
# cat("ROH-hotspot selection testing results://n")
# Initialize an empty vector to store F_ROH values for the different selection coefficients
selection_model_values_list <- c()
selection_model_names_list <- c()
selection_model_lower_ci <- c()
selection_model_upper_ci <- c()

# Loop through each selection_coefficient in ROH_freq_tables_Selection_Model
for (selection_coefficient in names(ROH_freq_tables_Selection_Model)) {
  # Extract the Avg_ROH_hotspot_threshold value from the selection_coefficient
  Avg_ROH_hotspot_threshold <- round(100*ROH_freq_tables_Selection_Model[[selection_coefficient]]$Avg_ROH_hotspot_threshold,ROH_frequency_decimals)
  CI <- ROH_freq_tables_Selection_Model[[selection_coefficient]]$SE_CI_ROH_hotspot_threshold
  # Formatting the selection coefficient for when displaying it. Removing "chr[0-9]" and adding a decimal point to the selection coefficient 
  formatted_selection_coefficient_labels <- sub(tolower("^.*_s(0?)(\\d+)_chr\\d+$"), tolower("s=\\1.\\2"), tolower(selection_coefficient))
  # Append values to the lists
  selection_model_values_list <- c(selection_model_values_list, Avg_ROH_hotspot_threshold)
  selection_model_lower_ci <- c(selection_model_lower_ci, 100*CI[1])
  selection_model_upper_ci <- c(selection_model_upper_ci, 100*CI[2])
  selection_model_names_list <- c(selection_model_names_list, formatted_selection_coefficient_labels)
}
# Add overAvg_ROH_hotspot_threshold from ROH_freq_tables_Neutral_Model
neutral_model_value <- round(100*ROH_freq_tables_Neutral_Model[["Avg_ROH_hotspot_threshold"]],ROH_frequency_decimals)
# neutral_lower_ci <- round(100*ROH_freq_tables_Neutral_Model$SE_CI_ROH_hotspot_threshold[1],ROH_frequency_decimals)
neutral_lower_ci <- round(100*ROH_freq_tables_Neutral_Model[["SE_CI_ROH_hotspot_threshold"]][1],ROH_frequency_decimals)
neutral_upper_ci <- round(100*ROH_freq_tables_Neutral_Model[["SE_CI_ROH_hotspot_threshold"]][2],ROH_frequency_decimals)
# Add Avg_ROH_hotspot_threshold from ROH_freq_table_Empirical_Data
empirical_model_value <- round(100*ROH_freq_table_Empirical_Data[["ROH_hotspot_threshold"]],ROH_frequency_decimals)
empirical_lower_ci <- NA # Placeholder for confidence interval lower bound
empirical_upper_ci <- NA # Placeholder for confidence interval upper bound

# Combine all values into a data frame
ROH_hotspot_threshold_values <- data.frame(
  Model = c(rep("Selection", length(selection_model_values_list)), "Neutral", "Empirical"),
  Avg_ROH_hotspot_threshold = c(selection_model_values_list, neutral_model_value, empirical_model_value),
  Lower_CI = c(selection_model_lower_ci, neutral_lower_ci, empirical_lower_ci),
  Upper_CI = c(selection_model_upper_ci, neutral_upper_ci, empirical_upper_ci)
)

# FOrmatting the confidence interval values
ROH_hotspot_threshold_values$Lower_CI <- round(ROH_hotspot_threshold_values$Lower_CI,ROH_frequency_decimals)
ROH_hotspot_threshold_values$Upper_CI <- round(ROH_hotspot_threshold_values$Upper_CI,ROH_frequency_decimals)
# Update the Model column for selection models
ROH_hotspot_threshold_values$Model[ROH_hotspot_threshold_values$Model == "Selection"] <- selection_model_names_list
# Sort the data frame based on the ROH-hotspot threshold
ROH_hotspot_threshold_values_sorted <- ROH_hotspot_threshold_values[order(ROH_hotspot_threshold_values$Avg_ROH_hotspot_threshold), ]
# Define the filename with the output directory path
filename <- file.path(output_dir, paste("ROH-hotspot_threshold_comparison",".csv", sep = ""))
# Write data to CSV file without quotes
write.table(ROH_hotspot_threshold_values_sorted, file = filename, sep = ",", row.names = FALSE, quote = FALSE)
# Use the write_latex_table() function to write the data to a LaTeX-compatible text file
write_latex_table(
  data_frame = ROH_hotspot_threshold_values,
  sort_column = "Avg_ROH_hotspot_threshold",  
  output_dir = output_dir,
  output_filename = "ROH-hotspot_threshold_comparison"  # File name without extension
)
# Print the table using knitr::kable()
knitr::kable(ROH_hotspot_threshold_values_sorted, row.names = FALSE)
```

<!-- ## 2.3: ROH-hotspots - ROH Frequency and Length --> 

```{r 2.3: ROH-hotspots - ROH Frequency and Length, echo = FALSE,warning = FALSE}
# setwd(Empirical_data_ROH_hotspots_dir)
# Pattern for finding files containing "F_ROH" and ending with ".tsv"
pattern <- "^.*ROH_Hotspot_windows*.bed$"
empirical_roh_hotspot_bed_files <- list.files(path = Empirical_data_ROH_hotspots_dir, pattern = pattern)
# chromosome_number_pattern <- "^german_shepherd_CHR(\\d+)_.*"
chromosome_number_pattern <- paste0("^",empirical_breed,"_chr(\\d+)_.*")
# Extract chromosome numbers
chr_numbers <- sub(tolower(chromosome_number_pattern), "\\1", tolower(empirical_roh_hotspot_bed_files))
# Sort the files based on chromosome numbers
empirical_roh_hotspot_bed_files <- empirical_roh_hotspot_bed_files[order(as.numeric(chr_numbers))]
# Create an empty list to store information for the different ROH-hotspots in
empirical_hotspot_tables <- list()

# Loop through each .bed file (ROH-hotspot allele frequency window-file)
for (file in empirical_roh_hotspot_bed_files) {
  file_path <- file.path(Empirical_data_ROH_hotspots_dir,file) 
  # Extract chromosome number and window number from file name
  chromosome <- as.numeric(sub(tolower(chromosome_number_pattern), "\\1", tolower(file)))
  column_names <- c("CHR","POS1","POS2")
  # Read the .bed file into a data frame, skipping commented lines
  chromosome_bed_file_data <- read.table(file_path, header = FALSE, comment.char = "#", stringsAsFactors = FALSE, col.names = column_names)
  
  # Loop through each hotspot for the current chromosome
  for (i in 1:nrow(chromosome_bed_file_data)) {
    Hotspot_region_data <- data.frame(CHR = chromosome_bed_file_data[i, ][1],POS1 = chromosome_bed_file_data[i, ][2],POS2 = chromosome_bed_file_data[i, ][3])
    Hotspot_length_bp <- Hotspot_region_data$POS2-Hotspot_region_data$POS1 + 1
    Hotspot_length_Mb <- Hotspot_length_bp / 1e6
    Hotspot_name <- paste("Hotspot_chr",chromosome, "_window_",i, sep = "")
    # Find the row where the variant_position_bp is within POS1 and POS2, and CHR equals chr_number
    roh_freq_windows_in_hotspot <- ROH_freq_table_Empirical_Data[[chromosome]][["data"]][ Hotspot_region_data$POS1 <= ROH_freq_table_Empirical_Data[[chromosome]][["data"]]$POS1 & ROH_freq_table_Empirical_Data[[chromosome]][["data"]]$POS2 <= Hotspot_region_data$POS2, ]
    avg_frequency <- mean(roh_freq_windows_in_hotspot$FREQUENCY)
    # Check if the selection coefficient already exists in the list
    if (!(Hotspot_name %in% names(empirical_hotspot_tables))) {
      # If it doesn't exist, create an empty data frame
      empirical_hotspot_tables[[Hotspot_name]] <- data.frame()
    }
    # Create a list with table name and corresponding data frame
    table_info <- list(Filename = file,Hotspot_length_bp=Hotspot_length_bp,Hotspot_length_Mb=Hotspot_length_Mb,Avg_frequency = avg_frequency, Hotspot_region_data = Hotspot_region_data) 
    # Append the table info to the list under selection_scenario
    empirical_hotspot_tables[[Hotspot_name]] <- c(empirical_hotspot_tables[[Hotspot_name]], table_info)
           }
}
# View(empirical_hotspot_tables)
```

# 3: Inbreeding Coefficient ($F_{ROH}$)
In this section, the distribution of the inbreeding coefficient ($F_{ROH}$) is plotted for both the empirical dataset and the simulated models (neutral and selection models). For the simulation models, the distribution reflects the variation in the population average $F_{ROH}$ across all technical replicates.

<!-- ## 3.1: Empirical data  -->

```{r 3.1: Empirical data, echo = FALSE,warning = FALSE, results='asis'}
# Set the working directory to the directory containing the F_ROH files for the empirical data
# setwd(Empirical_data_F_ROH_dir)
# Pattern for finding files containing "F_ROH" and ending with ".tsv"
pattern <- "^.*F_ROH.*.tsv$"
population_F_ROH_file <- list.files(path = Empirical_data_F_ROH_dir, pattern = pattern)

# Extract the population name from the file names
empirical_population_name <- sub(tolower("^(.*?)_F_ROH.*"), "\\1", tolower(population_F_ROH_file))
# Combine population name, number, and file name
population_info <- data.frame(empirical_population_name = empirical_population_name, file_name = population_F_ROH_file)
population_info <- population_info[order(population_info$file_name), ]
# Initialize an empty list to store the data
F_ROH_table_Empirical_Data <- list()

# Loop through each .tsv file
for (i in 1:length(population_info$empirical_population_name)) {
  # Get the file name
  file <- population_info$file_name[i]
  file_path <- file.path(Empirical_data_F_ROH_dir,file)
  # Read the header line
  con <- file(file_path, "r")
  header <- readLines(con, n = 1)
  close(con)
  # Remove "#" from the header and split it into column names
  column_names <- sub("#", "", header)
  column_names <- strsplit(column_names, "\t")[[1]]
  # Read the .tsv frequency file into a data frame
  F_ROH_data <- read.table(file_path, header = FALSE, comment.char = "#", stringsAsFactors = FALSE, col.names = column_names)
  # Add empirical_population_name as an attribute to the data frame
  attr(F_ROH_data, "empirical_population_name") <- population_info$empirical_population_name[i]
  # Add filename as an attribute to the data frame
  attr(F_ROH_data, "filename") <- file_name
  # Calculate the mean of the "F_ROH" column
  avg_F_ROH_population <- mean(F_ROH_data$F_ROH)
  # Create a list with table name and corresponding data frame
  table_info <- list(empirical_population_name = population_info$empirical_population_name[i], filename = file, data = F_ROH_data,Avg_F_ROH = avg_F_ROH_population )  # Added empirical_population_name here
  # Append the table info to the list
  F_ROH_table_Empirical_Data <- c(F_ROH_table_Empirical_Data, table_info)
}
# Creating a histogram showing the spread in F_ROH values across the empirical population 
histogram_title <- paste0("F_ROH distribution for ",empirical_population_name)
hist(F_ROH_data$F_ROH, main = histogram_title, xlab = "F_ROH", ylab = "Frequency", col = "skyblue")
empirical_avg_F_ROH_legend_text <- paste(empirical_population_name," Average: ", round(F_ROH_table_Empirical_Data[["Avg_F_ROH"]], 3))
# Add a vertical line for the average F_ROH of the empirical population
abline(v = F_ROH_table_Empirical_Data[["Avg_F_ROH"]], col = empirical_data_color, lwd = histogram_line_sizes)
# Add legend
legend("topright", legend = empirical_avg_F_ROH_legend_text,
       col = empirical_data_color, lty = 1, cex = 0.8, text.col = "black")
# Print the overall average Avg_F_ROH
cat("\n\n**Overall Average $F_{ROH}$ for ",empirical_population_name,":**\n\n",F_ROH_table_Empirical_Data[["Avg_F_ROH"]], "\n\n")
# View the modified data structure
#View(F_ROH_table_Empirical_Data)
```

<!-- ## 3.2: Neutral Model  -->

```{r 3.2: Neutral Model, echo = FALSE,warning = FALSE, results='asis'}
# Set the working directory to the directory containing the F_ROH files for the empirical data
# setwd(Neutral_model_F_ROH_dir)
# Pattern for finding files containing "F_ROH" and ending with ".tsv"
pattern <- "^.*F_ROH.*.tsv$"
simulation_F_ROH_files <- list.files(path = Neutral_model_F_ROH_dir, pattern = pattern)
# Extract the simulation name from the file names
sim_name <- sub(tolower("^(.*?)_F_ROH.*"), "////1", tolower(simulation_F_ROH_files))
# Extract the simulation number after "sim_"
simulation_numbers <- as.integer(sub(tolower("^sim_(////d+)_.*"), "////1", tolower(simulation_F_ROH_files)))
# Combine simulation name, number, and file name
sim_info <- data.frame(sim_name = sim_name, simulation_number = simulation_numbers, file_name = simulation_F_ROH_files)
sim_info <- sim_info[order(sim_info$simulation_number), ]
# Initialize an empty list to store Simulated model tables
F_ROH_tables_Neutral_Model <- list()
# Loop through each .tsv file
for (i in 1:length(sim_info$sim_name)) {
  # Get the file name
  file <- sim_info$file_name[i]
  file_path <- file.path(Neutral_model_F_ROH_dir,file)
  # Extract the table name from the file name
  file_name <- gsub("////.tsv$", "", file)
  # Read the header line
  con <- file(file_path, "r")
  header <- readLines(con, n = 1)
  close(con)
  # Remove "#" from the header and split it into column names
  column_names <- sub("#", "", header)
  column_names <- strsplit(column_names, "\t")[[1]]
  # Read the .tsv frequency file into a data frame
  F_ROH_data <- read.table(file_path, header = FALSE, comment.char = "#", stringsAsFactors = FALSE, col.names = column_names)
  # Add sim_name as an attribute to the data frame
  attr(F_ROH_data, "sim_name") <- sim_info$sim_name[i]
  # Create a list with table name and corresponding data frame
  table_info <- list(sim_name = sim_info$sim_name[i], filename = file_name, data = F_ROH_data)  # Added sim_name here
  # Append the table info to the list
  F_ROH_tables_Neutral_Model <- c(F_ROH_tables_Neutral_Model, list(table_info))
}
# Calculating Population F_ROH for each simulation (subtable)
# Loop through each table in F_ROH_tables_Neutral_Model
for (i in seq_along(F_ROH_tables_Neutral_Model)) {
  # Calculate the population average from the "F_ROH" column in the current simulation (subtable)
  F_ROH_tables_Neutral_Model[[i]]$Population_F_ROH <- mean(F_ROH_tables_Neutral_Model[[i]]$data$F_ROH)
}
#View(F_ROH_tables_Neutral_Model)
# Extract all population F_ROH values from F_ROH_tables_Neutral_Model
All_Population_F_ROH <- unlist(lapply(F_ROH_tables_Neutral_Model, function(table) table$Population_F_ROH))

# Remove any non-numeric values
All_Population_F_ROH <- All_Population_F_ROH[!is.na(All_Population_F_ROH) & is.numeric(All_Population_F_ROH)]
# Calculate the point estimate F_ROH across all technical replicates
F_ROH_tables_Neutral_Model$Estimated_Mean_Population_F_ROH <- mean(All_Population_F_ROH)

# Calculate the Standard Error Confidence Interval
F_ROH_tables_Neutral_Model$SE_CI_Estimated_Mean_Population_F_ROH <- standard_error_confidence_interval_fun(All_Population_F_ROH)
# Set the plot size
options(repr.plot.width = 10, repr.plot.height = 6)
# Create histogram for simulated data
hist(All_Population_F_ROH, main = "Population F_ROH for the Neutral Model simulations", xlab = "F_ROH", ylab = "Frequency", col = "skyblue")
# Determine the location of the legend based on the comparison
if (F_ROH_tables_Neutral_Model$Estimated_Mean_Population_F_ROH > F_ROH_table_Empirical_Data[["Avg_F_ROH"]]) {
  simulated_line_location <- "topright"
  empirical_line_location <- "topleft"
} else {
  simulated_line_location <- "topleft"
  empirical_line_location <- "topright"
}
# Add a red vertical line for the point estimate F_ROH across all technical replicates simulations
abline(v = F_ROH_tables_Neutral_Model$Estimated_Mean_Population_F_ROH, col = neutral_model_color, lwd = histogram_line_sizes)
# Add legend for the red line
legend(simulated_line_location, legend = paste("Neutral - F_ROH Point estimate: ", round(F_ROH_tables_Neutral_Model$Estimated_Mean_Population_F_ROH, 4)),
       col = neutral_model_color, lty = 1, cex = 0.8, text.col = "black")
# Add a blue vertical line for the average F_ROH of the empirical population
abline(v = F_ROH_table_Empirical_Data[["Avg_F_ROH"]], col = empirical_data_color, lwd = histogram_line_sizes)
# Add legend for the green line
legend(empirical_line_location, legend = empirical_avg_F_ROH_legend_text,
       col = empirical_data_color, lty = 1, cex = 0.8, text.col = "black", xjust = 1, yjust = 1)
# Reset par settings to default after plotting
par(mfrow = c(1, 1))
# Print the Point estimate of F_ROH across all technical replicates 
cat("\n\n**The point estimate of $F_{ROH}$ across all",n_simulation_replicates,"simulations for the Neutral Model:**\n\n", F_ROH_tables_Neutral_Model$Estimated_Mean_Population_F_ROH, "\n\n")
cat("\n\n**Standard Error 95% Confidence Interval:**\n\n [", 
    F_ROH_tables_Neutral_Model$SE_CI_Estimated_Mean_Population_F_ROH[1], ", ", 
    F_ROH_tables_Neutral_Model$SE_CI_Estimated_Mean_Population_F_ROH[2], "]")
```

 <!-- ## 3.3: Selection Models --> 

```{r 3.3: Selection Models, echo = FALSE,warning = FALSE, results='asis'}
# Set the working directory to the directory containing the F_ROH files for the empirical data
# setwd(Selection_model_F_ROH_dir)
# Pattern for finding files containing "F_ROH" and ending with ".tsv"
pattern <- "^.*F_ROH.*.tsv$"
simulation_F_ROH_files <- list.files(path = Selection_model_F_ROH_dir, pattern = pattern)
# Extract simulation numbers from the filename
sim_number_pattern <- ".*sim_(\\d+)_.*" 
simulation_numbers <- as.numeric(gsub(tolower(sim_number_pattern), "\\1", tolower(simulation_F_ROH_files)))
sim_name <- sub(tolower("^(.*?)_F_ROH.*"), "\\1", tolower(simulation_F_ROH_files))
# Combine simulation name, number, and file name
sim_info <- data.frame(sim_name = sim_name, simulation_number = simulation_numbers, file_name = simulation_F_ROH_files)
sim_info <- sim_info[order(sim_info$simulation_number), ]
# Initialize an empty list to store Simulated model tables
F_ROH_tables_Selection_Model <- list()
# Loop through each .tsv file
for (i in 1:length(sim_info$sim_name)) {
  # Get the file name
  file <- sim_info$file_name[i]
  file_path <- file.path(Selection_model_F_ROH_dir,file)
  # Extract the selection_model_type from the file name
  selection_model_type <- sub(tolower("^sim_[0-9]+_(.*?)_F_ROH.*"), "\\1", tolower(file))
  # Check if the selection_model_type already exists in the list
  if (!(selection_model_type %in% names(F_ROH_tables_Selection_Model))) {
    # If it doesn't exist, create a list for it
    F_ROH_tables_Selection_Model[[selection_model_type]] <- list()
  }
  # Extract simname from the file name
  simname_from_file <- sub(tolower("^(.*?)_F_ROH.*"), "\\1", tolower(file))
  # Check if the simname from the file matches with the simname from the dataframe
  if (simname_from_file != sim_info$sim_name[i]) {
    stop("Error: Simname from file does not match with simname from dataframe.")
  }
  # Read the header line
  con <- file(file_path, "r")
  header <- readLines(con, n = 1)
  close(con)
  # Remove "#" from the header and split it into column names
  column_names <- sub("#", "", header)
  column_names <- strsplit(column_names, "\\t")[[1]]
  # Read the .tsv frequency file into a data frame
  F_ROH_data <- read.table(file_path, header = FALSE, comment.char = "#", stringsAsFactors = FALSE, col.names = column_names)
  # Add sim_name as an attribute to the data frame
  attr(F_ROH_data, "sim_name") <- sim_info$sim_name[i]
  # Assign the file name to file_name
  file_name <- sub("\\.tsv$", "", sim_info$file_name[i])
  # Create a list with table name and corresponding data frame
  table_info <- list(sim_name = sim_info$sim_name[i], filename = file_name, data = F_ROH_data)  
  # Append the table info to the list under selection_model_type
  F_ROH_tables_Selection_Model[[selection_model_type]] <- c(F_ROH_tables_Selection_Model[[selection_model_type]], list(table_info))
}

# Calculating Average F_ROH for each table
# Loop through each selection_coefficient
for (selection_coefficient in names(F_ROH_tables_Selection_Model)) {
  # Loop through each table in the selection_coefficient
  for (i in seq_along(F_ROH_tables_Selection_Model[[selection_coefficient]])) {
    # Calculate the population average from the "F_ROH" column in the current simulation (subtable)
    # of the current selection coefficient
    F_ROH_tables_Selection_Model[[selection_coefficient]][[i]]$Population_F_ROH <- mean(F_ROH_tables_Selection_Model[[selection_coefficient]][[i]]$data$F_ROH)
  }
  # Extract all pop_Avg_F_ROH values from F_ROH_tables_Selection_Model
  All_Population_F_ROH <- unlist(lapply(F_ROH_tables_Selection_Model[[selection_coefficient]], function(table) table$Population_F_ROH))
  # Remove any non-numeric values
  All_Population_F_ROH <- All_Population_F_ROH[!is.na(All_Population_F_ROH) & is.numeric(All_Population_F_ROH)]
  # print(All_Population_F_ROH)
  # Calculate the point estimate F_ROH across all technical replicates simulations for the current selection coefficient
  F_ROH_tables_Selection_Model[[selection_coefficient]]$Estimated_Mean_Population_F_ROH <- mean(All_Population_F_ROH)

  # Calculate the Standard Error confidence interval of the point estimate F_ROH across all technical replicates simulations for the current selection coefficient
  # Store the Standard Error confidence interval in the F_ROH_tables_Selection_Model table
  F_ROH_tables_Selection_Model[[selection_coefficient]]$SE_CI_Estimated_Mean_Population_F_ROH <- standard_error_confidence_interval_fun(All_Population_F_ROH)
  # Set the plot size
  options(repr.plot.width = 10, repr.plot.height = 6)
  # Creating a histogram showing the spread in average F_ROH values across each technical replicate 
  # for the current selection coefficient!
  histogram_title <- paste0("Population F_ROH for ",selection_coefficient)
  hist(All_Population_F_ROH, main = histogram_title, xlab = "F_ROH", ylab = "Frequency", col = "skyblue")
  # Determine the location of the legend based on the comparison
  if (F_ROH_tables_Selection_Model[[selection_coefficient]]$Estimated_Mean_Population_F_ROH > F_ROH_table_Empirical_Data[["Avg_F_ROH"]]) {
    simulated_line_location <- "topright"
    empirical_line_location <- "topleft"
  } else {
    simulated_line_location <- "topleft"
    empirical_line_location <- "topright"
  }
  # Add a vertical line for the overall average Avg_F_ROH of the current selection model
  abline(v = F_ROH_tables_Selection_Model[[selection_coefficient]]$Estimated_Mean_Population_F_ROH, col = selection_model_color, lwd = histogram_line_sizes)
  # Add legend for the red line
  legend(simulated_line_location, legend = paste("Selection Coefficient F_ROH Point estimate:", round(F_ROH_tables_Selection_Model[[selection_coefficient]]$Estimated_Mean_Population_F_ROH, F_ROH_values_decimals)),
       col = selection_model_color, lty = 1, cex = 0.8, text.col = "black")
  # Add a vertical line for the average F_ROH of the empirical population
  abline(v = F_ROH_table_Empirical_Data[["Avg_F_ROH"]], col = empirical_data_color, lwd = histogram_line_sizes)
  # Add legend for the empirical line
  legend(empirical_line_location, legend = empirical_avg_F_ROH_legend_text,
         col = empirical_data_color, lty = 1, cex = 0.8, text.col = "black", xjust = 1, yjust = 1)
  # Reset par settings to default after plotting
  par(mfrow = c(1, 1))
  # Print the Point estimate of F_ROH across all technical replicates simulations
  cat("\n\n**The point estimate of $F_{ROH}$ across all",n_simulation_replicates,"simulations for ",selection_coefficient,":**\n\n", F_ROH_tables_Selection_Model[[selection_coefficient]]$Estimated_Mean_Population_F_ROH, "\n\n")
  
  cat("\n\n**Standard Error-based 95% Confidence Interval:**\n\n [", 
  F_ROH_tables_Selection_Model[[selection_coefficient]]$SE_CI_Estimated_Mean_Population_F_ROH[1], ", ", 
  F_ROH_tables_Selection_Model[[selection_coefficient]]$SE_CI_Estimated_Mean_Population_F_ROH[2], "]\n\n")
}
#View(F_ROH_tables_Selection_Model)
```

## 3.4: $F_{ROH}$ Summary
This section presents a comparison of the population average inbreeding coefficient ($F_{ROH}$) between each simulation type and the empirical data. The displayed inbreeding coefficients for the different simulation types represents the point estimate of $F_{ROH}$ across all technical replicates. 
The Lower CI and Upper CI represent the boundaries of the sample standard-error-based confidence intervals for the population $F_{ROH}$, with a confidence level of 95%.
 
```{r 3.4: F_ROH summary, echo = FALSE,warning = FALSE, results='asis'}
# Initialize vectors to store F_ROH values and CI bounds for the different selection coefficients
selection_model_avg_values <- c()
selection_model_lower_ci <- c()
selection_model_upper_ci <- c()
selection_model_names <- c()
# Loop through each selection_coefficient in F_ROH_tables_Selection_Model
for (selection_coefficient in names(F_ROH_tables_Selection_Model)) {
  # Formatting the selection coefficient for when displaying it. Removing "chr[0-9]" and adding a decimal point to the selection coefficient 
  formatted_selection_coefficient_labels <- sub(tolower("^.*_s(0?)(\\d+)_chr\\d+$"), tolower("s=\\1.\\2"), tolower(selection_coefficient))
  # Extract the all_avg_F_ROH value from the selection_coefficient
  all_avg_F_ROH <- F_ROH_tables_Selection_Model[[selection_coefficient]]$Estimated_Mean_Population_F_ROH
  CI <- F_ROH_tables_Selection_Model[[selection_coefficient]]$SE_CI_Estimated_Mean_Population_F_ROH
  # Append values to the lists
  selection_model_names <- c(selection_model_names,formatted_selection_coefficient_labels)
  selection_model_avg_values <- c(selection_model_avg_values, all_avg_F_ROH)
  selection_model_lower_ci <- c(selection_model_lower_ci, CI[1])
  selection_model_upper_ci <- c(selection_model_upper_ci, CI[2])
}
# Extract neutral model values and CI bounds
neutral_avg_F_ROH <- F_ROH_tables_Neutral_Model[["Estimated_Mean_Population_F_ROH"]]
neutral_lower_ci <- F_ROH_tables_Neutral_Model[["SE_CI_Estimated_Mean_Population_F_ROH"]][1]
neutral_upper_ci <- F_ROH_tables_Neutral_Model[["SE_CI_Estimated_Mean_Population_F_ROH"]][2]
# Extract empirical model value
empirical_avg_F_ROH <- F_ROH_table_Empirical_Data[["Avg_F_ROH"]]
empirical_lower_ci <- NA # Placeholder for confidence interval lower bound
empirical_upper_ci <- NA # Placeholder for confidence interval upper bound

# Combine all values into a data frame
F_ROH_values <- data.frame(
  Model = c(rep("Selection", length(selection_model_avg_values)), "Neutral", "Empirical"),
  F_ROH = c(selection_model_avg_values, neutral_avg_F_ROH, empirical_avg_F_ROH),
  Lower_CI = c(selection_model_lower_ci, neutral_lower_ci, empirical_lower_ci),
  Upper_CI = c(selection_model_upper_ci, neutral_upper_ci, empirical_upper_ci)
)
# Format all numeric values to have the number of decimals defined by F_ROH_values_decimals
F_ROH_values$F_ROH <- round(F_ROH_values$F_ROH,F_ROH_values_decimals)
F_ROH_values$Lower_CI <- as.numeric(round(F_ROH_values$Lower_CI,F_ROH_values_decimals))
F_ROH_values$Upper_CI <- as.numeric(round(F_ROH_values$Upper_CI,F_ROH_values_decimals))
# Extract labels for the different selection coefficients
selection_labels <- gsub(tolower(".*_(s\\d+)_.*"), "\\1", tolower(selection_model_names))
F_ROH_values$Model[1:length(selection_model_names)] <- selection_labels
# Sort the data frame based on F_ROH column
F_ROH_values_sorted <- F_ROH_values[order(as.numeric(F_ROH_values$F_ROH)), ]
# Define the filename with the output directory path
filename <- file.path(output_dir, paste("F_ROH_comparison",".csv", sep = ""))
# Write data to CSV file without quotes
write.table(F_ROH_values_sorted, file = filename, sep = ",", row.names = FALSE, quote = FALSE)
# Use the write_latex_table() function to write the data to a LaTeX-compatible text file
write_latex_table(
  data_frame = F_ROH_values,
  sort_column = "F_ROH",  # Sorting was done using this column
  output_dir = output_dir,
  output_filename = "F_ROH_comparison"  # File name without extension
)
# Print the table using knitr::kable()
knitr::kable(F_ROH_values_sorted, row.names = FALSE)
```

# 4: Expected Heterozygosity ($H_{e}$)

<!-- ## 4.1: Empirical - Expected Heterozygosity  --> 

```{r 4.1: Empirical - Expected Heterozygosity, echo = FALSE,warning = FALSE, results='asis'}
# setwd(Empirical_data_H_e_dir)
# Pattern for finding the specific file containing "5th_percentiles_of_H_e_distribution.tsv"
pattern <- "^.*H_e_distribution_.*.tsv$"
empirical_H_e_distribution_file <- list.files(path = Empirical_data_H_e_dir, pattern = pattern)

# Check if exactly one file is found
if (length(empirical_H_e_distribution_file) != 1) {
  stop("There should be exactly one file matching the pattern.")
}
# Read the file
file <- empirical_H_e_distribution_file[1]
file_path <- file.path(Empirical_data_H_e_dir,file) 
# Read the .tsv file into a data frame
empirical_H_e_distribution_table <- read.table(file_path, header = TRUE, sep = "\t", stringsAsFactors = FALSE)
# View(empirical_H_e_distribution_table)
# # Set the working directory to the directory containing the H_e files for the empirical data
# setwd(Empirical_data_H_e_dir)
# 
# # List all PNG files in the directory
# # png_files <- list.files(pattern = "//.png$", full.names = TRUE)
# png_files <- list.files(pattern = "//.png$")
# 
# # Display each PNG file
# for (file in png_files) {
#   cat("File:", file, "/n")
#   # Open a PNG device
#   png::png(filename = file)
#   # Display image using readPNG() from the png package
#   raster <- png::readPNG(file)
#   graphics::plot.new()
#   graphics::plot.window(xlim = c(0, 1), ylim = c(0, 1), asp = 1)
#   graphics::rasterImage(raster, 0, 0, 1, 1)
#   # Close the PNG device
#   dev.off()
# }
# 
```

<!-- ## 4.2: Neutral Model - Expected Heterozygosity  --> 

```{r 4.2: Neutral Model - Expected Heterozygosity, echo = FALSE,warning = FALSE }
# setwd(Neutral_model_H_e_dir)
# Pattern for finding the specific file containing "5th_percentiles_of_H_e_distribution.tsv"
pattern <- "^.*5th_percentiles_of_H_e_distribution.tsv$"
neutral_model_5th_percentiles_of_H_e_files <- list.files(path = Neutral_model_H_e_dir, pattern = pattern)
# Check if exactly one file is found
if (length(neutral_model_5th_percentiles_of_H_e_files) != 1) {
  stop("There should be exactly one file matching the pattern.")
}
# Read the file
file <- neutral_model_5th_percentiles_of_H_e_files[1]
file_path <- file.path(Neutral_model_H_e_dir,file)
# Read the .tsv file into a data frame
data <- read.table(file_path, header = TRUE, sep = "\t", stringsAsFactors = FALSE)
# Store the data frame in a list as a subtable called "data"
H_e_5th_percentiles_Neutral_model <- list(results = data)
H_e_5th_percentiles_Neutral_model$Estimated_Mean_H_e_5th_percentile <- mean(H_e_5th_percentiles_Neutral_model[["results"]][["Fifth_Percentile"]])
# Calculate the Standard Error confidence interval of the point estimate F_ROH across all technical replicates simulations
# Store the Standard Error confidence interval in the F_ROH_tables_Neutral_Model
H_e_5th_percentiles_Neutral_model$SE_CI_Estimated_Mean_H_e_5th_percentile <- standard_error_confidence_interval_fun(H_e_5th_percentiles_Neutral_model[["results"]][["Fifth_Percentile"]])
#View(H_e_5th_percentiles_Neutral_model)
```

```{r H_E disitrubtion plot - Neutral Model, echo = FALSE,warning = FALSE }
# setwd(Neutral_model_H_e_dir)
# # Set the working directory to the directory containing the H_e files for the Neutral Model
# new_dir <- file.path(Neutral_model_H_e_dir,"test")
# #setwd(Neutral_model_H_e_dir)
# setwd(new_dir)
# # List all PNG files in the directory
# #png_files <- list.files(pattern = "//.png$", full.names = TRUE)
# png_files <- list.files(pattern = "//.png$")
# 
# library(png)
# 
# 
# # Display each PNG file
# for (file in png_files) {
#   file_path <- file.path(new_dir, file)
#   cat("File:", file, "/n")
#   # Display the image using include_graphics() from the knitr package
#   knitr::include_graphics(file_path)
# }
# 
# knitr::include_graphics("img",/rmarkdown_hex.png")


# # Display each PNG file
# for (file in png_files) {
#   cat("File:", file, "/n")
#   file_path <- file.path(Neutral_model_H_e_dir,file)
#   # Open a PNG device
#   png(filename = file_path)
#   # Display image using base R graphics functions
#   img <- readPNG(file)
#   graphics::plot.new()
#   graphics::plot.window(xlim = c(0, 1), ylim = c(0, 1), asp = 1)
#   graphics::rasterImage(img, 0, 0, 1, 1)
#   #Close the PNG device
#   dev.off()
# }
```

<!-- ## 4.3: Selection Models - Expected Heterozygosity --> 

```{r 4.3: Selection Models - Expected Heterozygosity ,echo = FALSE,warning = FALSE}
# setwd(Selection_model_H_e_dir)
# Pattern for finding the specific file containing "5th_percentiles_of_H_e_distribution.tsv"
pattern <- "^.*5th_percentiles_of_H_e_distribution.tsv$"
selection_model_5th_percentiles_of_H_e_files <- list.files(path = Selection_model_H_e_dir, pattern = pattern)
# Initialize an empty list to store H_e_5th_percentiles_Selection_models
H_e_5th_percentiles_Selection_models <- list()

# Loop through each selection coefficient and its associated file
for (i in seq_along(selection_model_5th_percentiles_of_H_e_files)) {
  file_path <- file.path(Selection_model_H_e_dir,selection_model_5th_percentiles_of_H_e_files[i])
  # Extract the selection coefficient from the file name
  selection_coefficient <- sub(tolower(".*(selection_model_s\\d+_chr\\d+).*"), "\\1", tolower(selection_model_5th_percentiles_of_H_e_files[i]))
  # Read the .tsv file into a data frame
  subtable <- read.table(file_path, header = TRUE,sep = "\t", stringsAsFactors = FALSE)
  H_e_5th_percentiles_Selection_models[[selection_coefficient]]$file_name <- selection_model_5th_percentiles_of_H_e_files[i]
  # Add the subtable to the list with the selection coefficient as its name
  H_e_5th_percentiles_Selection_models[[selection_coefficient]]$results <- subtable
}
# Loop through each selection_coefficient
for (selection_coefficient in names(H_e_5th_percentiles_Selection_models)) {
  # Calculate the point estimate F_ROH across all technical replicates simulations for the current selection coefficient
  H_e_5th_percentiles_Selection_models[[selection_coefficient]]$Estimated_Mean_H_e_5th_percentile <- mean(H_e_5th_percentiles_Selection_models[[selection_coefficient]][["results"]][["Fifth_Percentile"]])
  # Calculate the Standard Error confidence interval of the point estimate F_ROH across all technical replicates simulations for the current selection coefficient
  # Store the Standard Error confidence interval in the H_e_5th_percentiles_Selection_models table
  H_e_5th_percentiles_Selection_models[[selection_coefficient]]$SE_CI_Estimated_Mean_H_e_5th_percentile <- standard_error_confidence_interval_fun(H_e_5th_percentiles_Selection_models[[selection_coefficient]][["results"]][["Fifth_Percentile"]])
}
 # View the dataframe
# View(H_e_5th_percentiles_Selection_models)
```

## 4.4: Genomewide Average $H_{e}$ Summary
This section presents a summary of the mean point estimation of the genome-wide average expected heterozygosity ($H_{e}$), calculated across all 100 kbp binned genomic regions.  The Lower CI and Upper CI represent the boundaries of the sample standard-error based confidence intervals for the average $H_{e}$, with a confidence level of 95%.

```{r 4.4: Genomewide Average H_e Summary, echo = FALSE,warning = FALSE, results='asis'}
# Initialize vectors to store F_ROH values and CI bounds for the different selection coefficients
selection_model_avg_values <- c()
selection_model_lower_ci <- c()
selection_model_upper_ci <- c()
selection_model_names <- c(rownames(summary(H_e_5th_percentiles_Selection_models)))

# Loop through each selection_coefficient in H_es_Selection_models
for (selection_coefficient in H_e_5th_percentiles_Selection_models) {
  selection_coefficient$Estimated_Mean_Population_H_e <- mean(selection_coefficient$results$Avg_H_e)
  CI <- standard_error_confidence_interval_fun(selection_coefficient$results$Avg_H_e)
  # Append values to the lists
  selection_model_avg_values <- c(selection_model_avg_values, selection_coefficient$Estimated_Mean_Population_H_e)
  selection_model_lower_ci <- c(selection_model_lower_ci, CI[1])
  selection_model_upper_ci <- c(selection_model_upper_ci, CI[2])
}
# Extract neutral model values and CI bounds
H_e_5th_percentiles_Neutral_model$Estimated_Mean_Population_H_e <- mean(H_e_5th_percentiles_Neutral_model[["results"]][["Avg_H_e"]])
H_e_5th_percentiles_Neutral_model$SE_CI_Estimated_Mean_H_e <- standard_error_confidence_interval_fun(H_e_5th_percentiles_Neutral_model[["results"]][["Avg_H_e"]])
neutral_avg_H_e <- H_e_5th_percentiles_Neutral_model$Estimated_Mean_Population_H_e 
neutral_lower_ci <- H_e_5th_percentiles_Neutral_model$SE_CI_Estimated_Mean_H_e[1]
neutral_upper_ci <- H_e_5th_percentiles_Neutral_model$SE_CI_Estimated_Mean_H_e[2]
# Extract empirical model value
empirical_avg_H_e <- empirical_H_e_distribution_table$Avg_H_e
empirical_lower_ci <- NA # Placeholder for confidence interval lower bound
empirical_upper_ci <- NA # Placeholder for confidence interval upper bound
# Combine all values into a data frame
H_e_values <- data.frame(
  Model = c(rep("Selection", length(selection_model_avg_values)), "Neutral", "Empirical"),
  H_e = c(selection_model_avg_values, neutral_avg_H_e, empirical_avg_H_e),
  Lower_CI = c(selection_model_lower_ci, neutral_lower_ci, empirical_lower_ci),
  Upper_CI = c(selection_model_upper_ci, neutral_upper_ci, empirical_upper_ci)
)
# Format all numeric values to 5 decimal places
H_e_values$H_e <- round(H_e_values$H_e, H_e_values_decimals)
H_e_values$Lower_CI <- round(H_e_values$Lower_CI,H_e_values_decimals)
H_e_values$Upper_CI <- round(H_e_values$Upper_CI,H_e_values_decimals)

formatted_selection_coefficient_labels <-sub(tolower("s(\\d)(\\d+)_.*"), tolower("s=\\1.\\2"), tolower(selection_model_names))
formatted_selection_coefficient_labels <- sub(tolower("selection_model_"), "", tolower(formatted_selection_coefficient_labels))

H_e_values$Model[1:length(selection_model_names)] <- formatted_selection_coefficient_labels
H_e_values$H_e <- as.numeric(round(H_e_values$H_e,H_e_values_decimals))
# Sort the data frame based on H_e column
H_e_values_sorted <- H_e_values[order(as.numeric(H_e_values$H_e)), ]
# Define the filename with the output directory path
filename <- file.path(output_dir, paste("Genomic_Average_Expected_Heterozygosity_Summary",".csv", sep = ""))
# Write data to CSV file without quotes
write.table(H_e_values_sorted, file = filename, sep = ",", row.names = FALSE, quote = FALSE)

# # Use the write_latex_table() function to write the data to a LaTeX-compatible text file
# write_latex_table(
#   data_frame = H_e_values,
#   sort_column = "H_e",  # Column used for sorting
#   output_dir = output_dir,
#   output_filename = "Expected_Heterozygosity_Summary"  # File name without extension
# )
# Print the table using knitr::kable()
knitr::kable(H_e_values_sorted, row.names = FALSE)
```

## 4.5: Genomewide 5th Percentile of Expected Heterozygosity Summary
Summary of the mean point estimation of expected heterozygosity ($H_{e}$) 5th percentile values with standard error-based confidence intervals. \n\n
```{r 4.5: Genomewide 5th percentile of Expected Heterozygosity Summary, echo = FALSE,warning = FALSE, results='asis'}
# Initialize vectors to store F_ROH values and CI bounds for the different selection coefficients
selection_model_avg_values <- c()
selection_model_lower_ci <- c()
selection_model_upper_ci <- c()
selection_model_names <- c(rownames(summary(window_H_e_causative_variant_tables)))

# Loop through each selection_coefficient in H_e_5th_percentiles_Selection_models
for (selection_coefficient in H_e_5th_percentiles_Selection_models) {
  CI <- selection_coefficient$SE_CI_Estimated_Mean_H_e_5th_percentile

  # Append values to the lists
  selection_model_avg_values <- c(selection_model_avg_values, selection_coefficient$Estimated_Mean_H_e_5th_percentile)
  selection_model_lower_ci <- c(selection_model_lower_ci, CI[1])
  selection_model_upper_ci <- c(selection_model_upper_ci, CI[2])
}
# Extract neutral model values and CI bounds
neutral_avg_H_e_5th_percentile <- H_e_5th_percentiles_Neutral_model[["Estimated_Mean_H_e_5th_percentile"]]
neutral_lower_ci <- H_e_5th_percentiles_Neutral_model[["SE_CI_Estimated_Mean_H_e_5th_percentile"]][1]
neutral_upper_ci <- H_e_5th_percentiles_Neutral_model[["SE_CI_Estimated_Mean_H_e_5th_percentile"]][2]
# Extract empirical model value
empirical_avg_H_e_5th_percentile <- empirical_H_e_distribution_table$Fifth_Percentile
empirical_lower_ci <- NA # Placeholder for confidence interval lower bound
empirical_upper_ci <- NA # Placeholder for confidence interval upper bound
# Combine all values into a data frame
H_e_5th_percentile_values <- data.frame(
  Model = c(rep("Selection", length(selection_model_avg_values)), "Neutral", "Empirical"),
  H_e_5th_percentile = c(selection_model_avg_values, neutral_avg_H_e_5th_percentile, empirical_avg_H_e_5th_percentile),
  Lower_CI = c(selection_model_lower_ci, neutral_lower_ci, empirical_lower_ci),
  Upper_CI = c(selection_model_upper_ci, neutral_upper_ci, empirical_upper_ci)
)
# Format all numeric values to 5 decimal places
H_e_5th_percentile_values$H_e_5th_percentile <- round(H_e_5th_percentile_values$H_e_5th_percentile, H_e_values_decimals)
H_e_5th_percentile_values$Lower_CI <- round(H_e_5th_percentile_values$Lower_CI,H_e_values_decimals)
H_e_5th_percentile_values$Upper_CI <- round(H_e_5th_percentile_values$Upper_CI,H_e_values_decimals)

# Formatting the selection coefficient for when displaying it. Removing "chr[0-9]" and adding a decimal point to the selection coefficient 
formatted_selection_coefficient_labels <-sub(tolower("s(\\d)(\\d+)_.*"), tolower("s=\\1.\\2"), tolower(selection_model_names))

H_e_5th_percentile_values$Model[1:length(selection_model_names)] <- formatted_selection_coefficient_labels

H_e_5th_percentile_values$H_e_5th_percentile <- as.numeric(round(H_e_5th_percentile_values$H_e_5th_percentile,H_e_values_decimals))

# Sort the data frame based on H_e_5th_percentile column
H_e_5th_percentile_values_sorted <- H_e_5th_percentile_values[order(as.numeric(H_e_5th_percentile_values$H_e_5th_percentile)), ]
# Define the filename with the output directory path
filename <- file.path(output_dir, paste("Expected_Heterozygosity_Summary",".csv", sep = ""))
# Write data to CSV file without quotes
write.table(H_e_5th_percentile_values_sorted, file = filename, sep = ",", row.names = FALSE, quote = FALSE)

# Use the write_latex_table() function to write the data to a LaTeX-compatible text file
write_latex_table(
  data_frame = H_e_5th_percentile_values,
  sort_column = "H_e_5th_percentile",  # Column used for sorting
  output_dir = output_dir,
  output_filename = "Expected_Heterozygosity_Summary"  # File name without extension
)
# Print the table using knitr::kable()
knitr::kable(H_e_5th_percentile_values_sorted, row.names = FALSE)
```

# 5. OMIA Phenotypes
<!-- Extracting all phenotypes -->
```{r OMIA Phenotypes, echo=FALSE,results= 'hide',warning = FALSE}

generate_vbo_links <- function(vbo_string) {
  vbo_list <- trimws(unlist(strsplit(vbo_string, ",")))  # Split by comma and trim spaces
  # base_url <- "https://www.ebi.ac.uk/ols4/search?lang=en&q=VBO%3A"
  base_url <- "http://purl.obolibrary.org/obo/VBO_" # http://purl.obolibrary.org/obo/VBO_0200800
  
  vbo_list <- sapply(vbo_list, function(id) {
    if (grepl("^VBO_", id)) {  # Check if it starts with "VBO_"
      vbo_number <- sub("VBO_", "", id)  # Extract number
    } else if (grepl("^VBO:", id)) {  # Check if it starts with "VBO:"
      vbo_number <- sub("VBO:", "", id)  # Extract number
    } else {
      return(id)  # Return unchanged if not a VBO ID
    }
    
    url <- paste0(base_url, vbo_number)
    return(paste0('<a href="', url, '" target="_blank">', id, '</a>'))  # Create hyperlink
  }, USE.NAMES = FALSE)
  
  return(paste(vbo_list, collapse = ", "))  # Join back into a string
}

generate_ensembl_gene_links <- function(gene_name) {
  # base_url <- "https://www.ensembl.org/Multi/Search/Results?q=" #https://www.ensembl.org/Multi/Search/Results?q=DCC  
  base_url <- "https://www.ncbi.nlm.nih.gov/gene/?term=" #https://www.ncbi.nlm.nih.gov/gene/?term=DCC  
  url <- paste0(base_url, gene_name)
  return(paste0('<a href="', url, '" target="_blank">', gene_name, '</a>'))  # Use gene_name instead of id
}

vertebrate_breed_ontology_ids_vector <- unlist(strsplit(vertebrate_breed_ontology_ids, ","))

file <- file.path(omia_phenotypes_filepath)
#  # Read the header (the line starting with #)
header_line <- readLines(file, n = 1)  # Read the first line
header <- unlist(strsplit(sub("^#", "", header_line), "\t"))  # Remove the "#" and split by tab

# Read the data (skip the first line since it's the header)
omia_phenotype_data <- read.table(file, header = FALSE, comment.char = "#", stringsAsFactors = FALSE, sep = "\t", skip = 1)

# Assign the extracted header as column names
colnames(omia_phenotype_data) <- header

# ---- Rename Columns for POS1 and POS2 ----
colnames(omia_phenotype_data)[1] <- "CHR"  # V5 as POS1 (start position)
colnames(omia_phenotype_data)[2] <- "POS1"  # V5 as POS1 (start position)
colnames(omia_phenotype_data)[3] <- "POS2"  # V6 as POS2 (end position)
colnames(omia_phenotype_data)[4] <- "PHENE"  
colnames(omia_phenotype_data)[5] <- "PHENE_CATEGORY" 
colnames(omia_phenotype_data)[6] <- "SINGLE_GENE_TRAIT_OR_DISORDER"  
colnames(omia_phenotype_data)[7] <- "DISEASE_RELATED" 
colnames(omia_phenotype_data)[8] <- "GENE_SYMBOL"  
colnames(omia_phenotype_data)[9] <- "GENE_DESCRIPTION" 
colnames(omia_phenotype_data)[10] <- "PHENE_URL"  
colnames(omia_phenotype_data)[11] <- "GENE_DETAILS_URL" 
colnames(omia_phenotype_data)[12] <- "BREEDS" 

# ---- Ensure POS1 and POS2 are Numeric ----
omia_phenotype_data$POS1 <- as.numeric(omia_phenotype_data$POS1)
omia_phenotype_data$POS2 <- as.numeric(omia_phenotype_data$POS2)
# omia_phenotype_data$BREEDS <- generate_vbo_links(omia_phenotype_data$BREEDS)
omia_phenotype_data$BREEDS <- sapply(omia_phenotype_data$BREEDS, generate_vbo_links)
omia_phenotype_data$GENE_SYMBOL <- sapply(omia_phenotype_data$GENE_SYMBOL, generate_ensembl_gene_links)


# View(omia_phenotype_data)
```

## 5.1 All Breed-Specific Non-Defect (Non-Disease-Related) Phenotypes 
```{r 5.1 All Breed-Specific Non-Defect Phenotypes, echo=FALSE, warning=FALSE, results='asis'}

# Read header and data
header_line <- readLines(omia_scraped_phenotypes_data_filepath, n = 1)
header <- unlist(strsplit(sub("^#", "", header_line), ","))
omia_raw_phenotype_data <- read.table(omia_scraped_phenotypes_data_filepath, 
                                      header = FALSE, 
                                      comment.char = "#", 
                                      stringsAsFactors = FALSE, 
                                      sep = ",", 
                                      skip = 1)
colnames(omia_raw_phenotype_data) <- header

omia_raw_phenotype_data[[12]] <- sapply(omia_raw_phenotype_data[[12]], generate_vbo_links)
omia_raw_phenotype_data[[8]] <- sapply(omia_raw_phenotype_data[[8]], generate_ensembl_gene_links)
# Print VBO IDs used
cat("\n\n **The following Vertebrate Breed Ontology (VBO) ID(s) were used for associating, or could potentially be associated with the empirical dataset:**\n\n", 
    generate_vbo_links(vertebrate_breed_ontology_ids), "\n\n")

cat("\n\n**Below are the non-defect phenotypes discovered on OMIA, associated with these VBO IDs.**\n\n",
    "These phenotypes include cases where no known links to a specific genomic region or breed have been reported on OMIA so far.",
    
    "Additionally, some phenotypes may have genomic coordinates mapped to a different reference assembly, which could result in misalignment relative to the identified ROH hotspot regions, and thus, may be misclassified as 'not overlapping with any ROH hotspot region'. ",
    "\n\nTherefore, these table(s) could serve as a valuable resource for identifying phenotypes that   otherwise may have been overlooked due to incomplete genomic mappings or lack of direct breed associations.\n They offer an opportunity for further investigation, particularly (if applicable) through re-mapping coordinates using a LiftOver process to potentially align them with the discovered ROH hotspot regions.")

# Create list to hold phenotype tables
Breed_phenotypes_tables <- list()

for (i in seq_along(vertebrate_breed_ontology_ids_vector)) {
  current_id <- vertebrate_breed_ontology_ids_vector[i]
  
  if (tolower(current_id) == "unspecified") {
    matching_OMIA_phenotypes <- omia_raw_phenotype_data[
      omia_raw_phenotype_data[, 12] == "" & 
      tolower(omia_raw_phenotype_data$DISEASE_RELATED) == "no", ]
    
    matching_OMIA_phenotypes[, 12] <- "Unspecified"
    matching_OMIA_phenotypes <- matching_OMIA_phenotypes[!grepl("disease", matching_OMIA_phenotypes[, 5], ignore.case = TRUE), ]
    matching_OMIA_phenotypes <- matching_OMIA_phenotypes[order(as.numeric(matching_OMIA_phenotypes$CHR)), ]
  } else {
    matching_OMIA_phenotypes <- omia_raw_phenotype_data[
      grepl(current_id, omia_raw_phenotype_data[, 12]) & 
      tolower(omia_raw_phenotype_data$DISEASE_RELATED) != "yes", ]
  }
  
  Breed_phenotypes_tables[[current_id]] <- matching_OMIA_phenotypes
}

# Loop through each table and render with kableExtra for improved styling
for(tbl in Breed_phenotypes_tables) {
  if (nrow(tbl) > 0) {
    # Create a styled HTML table
    table_html <- knitr::kable(tbl, format = "html", 
                               row.names = FALSE, 
                               digits = kable_table_digits,
                               escape = FALSE,
                               table.attr = "class='table table-bordered table-striped'") %>%
      kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover", "condensed")) %>%
      # Adjust column width; change "3cm" to a width that suits your data
      column_spec(1:ncol(tbl), width = "3cm")
    
    # Output the table and add spacing
    cat(table_html)
    cat("<br><br>\n")
  }
}
```

## 5.2 Species-Specific Phenotypes Overlapping With The Detected Empirical ROH Hotspot(s)
```{r 5.2 Species-Specific Phenotypes Overlapping With The Detected Empirical ROH Hotspot(s), echo=FALSE,warning = FALSE, results='asis'}

# View(empirical_hotspot_tables)
for (i in seq_along(empirical_hotspot_tables)) {
  # Extract chromosome and hotspot region boundaries
  CHR <- empirical_hotspot_tables[[i]][["Hotspot_region_data"]][["CHR"]]
  POS1 <- empirical_hotspot_tables[[i]][["Hotspot_region_data"]][["POS1"]]
  POS2 <- empirical_hotspot_tables[[i]][["Hotspot_region_data"]][["POS2"]]
  # cat("Hotspot Window -> POS1:", POS1, " POS2:", POS2, "\n")
  
  # Find phenotypes that partially or fully overlap the hotspot region
  overlapping_phenotypes <- omia_phenotype_data[
    omia_phenotype_data$CHR == CHR &
    omia_phenotype_data$POS2 >= POS1 &  # Phenotype end is after or at the region start
    omia_phenotype_data$POS1 <= POS2,   # Phenotype start is before or at the region end
  ]

  # Compute Overlap_Percentage for each phenotype
  if (nrow(overlapping_phenotypes) > 0) {
    overlapping_phenotypes$Overlap_Percentage <- apply(overlapping_phenotypes, 1, function(phenotype) {
      phenotype_start <- as.numeric(phenotype["POS1"])
      phenotype_end <- as.numeric(phenotype["POS2"])
      phenotype_length <- phenotype_end - phenotype_start + 1  # Total phenotype length

      # Compute upstream and downstream outside portions
      upstream_outside <- max(0, POS1 - phenotype_start)  # If phenotype starts before hotspot
      downstream_outside <- max(0, phenotype_end - POS2)  # If phenotype ends after hotspot
      outside_portion <- upstream_outside + downstream_outside

      # Compute Overlap Percentage
      Overlap_Percentage <- 100 * (1 - (outside_portion / phenotype_length))
      return(Overlap_Percentage)
    })
  } else {
    overlapping_phenotypes$Hotspot_Overlap_Perc <- numeric(0)  # Empty case
  }

  # Store results
  empirical_hotspot_tables[[i]][["Hotspot_species_phenotypes"]] <- overlapping_phenotypes
}

# Initialize the empty list
All_phenotypes_for_all_hotspots <- list()

hotspots_with_overlapping_phenotypes <- ""

# Loop through each hotspot and filter under selection
for (hotspot in names(empirical_hotspot_tables)) {
      # Extract the phenotypes for the selected hotspot
      phenotypes_data <- empirical_hotspot_tables[[hotspot]][["Hotspot_species_phenotypes"]]
      
      if (!is.null(phenotypes_data) && nrow(phenotypes_data) > 0) {
        All_phenotypes_for_all_hotspots[[hotspot]] <- phenotypes_data
        hotspots_with_overlapping_phenotypes <- paste0(hotspots_with_overlapping_phenotypes,", ", hotspot)
      }
    
}

# All_phenotypes_for_all_hotspots[[hotspot]] <- Breed_phenotypes_tables[[1]] # Debugging purposes
# hotspots_with_overlapping_phenotypes <- "" # Debugging purposes


# Check if there are any phenotypes under selection and display a message with the tables
if (length(All_phenotypes_for_all_hotspots) > 0) {
  # Print a phenotyperal message before displaying tables
  cat("\n\nThe following table(s) shows all defect and non-defect phenotypes (for the studied species) overlapping with the empirical ROH hotspots. \n\n**The hotspots are displayed in the following order:**\n\n",hotspots_with_overlapping_phenotypes,"")
  
  # # Display the entire table for all hotspots
  # knitr::kable(All_phenotypes_for_all_hotspots, row.names = FALSE,
  #              caption = "All defect and non-defect phenotypes (for the studied species) overlapping with the empirical ROH hotspots")
  
  # Loop through each table and render with kableExtra for improved styling
  for(tbl in All_phenotypes_for_all_hotspots) {
    if (nrow(tbl) > 0) {
      # Create a styled HTML table
      table_html <- knitr::kable(tbl, format = "html", 
                                 row.names = FALSE, 
                                 digits = kable_table_digits,
                                 escape = FALSE,
                                 table.attr = "class='table table-bordered table-striped'") %>%
        kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover", "condensed")) %>%
        # Adjust column width; change "3cm" to a width that suits your data
        column_spec(1:ncol(tbl), width = "3cm")
      
      # Output the table and add spacing
      cat(table_html)
      cat("<br><br>\n")
    }
  }

  
} else {
        cat("\n\n**Result:**\n\nNo non-defect (non-disease) species-specific phenotypes were found to overlap with the empirical ROH hotspot regions.\n")

}

```

# 6: Summary
## 6.0: Detected Empirical ROH Hotspots
Summary of the detected ROH hotspot windows in the empirical dataset.
```{r 6.0: Detected Empirical ROH hotspots, echo = FALSE,warning = FALSE, results='asis'}
Hotspot <- c()
Chr <- c()
Start <- c()
End <- c()
Length_Mb <- c()

# Loop through each selection_coefficient in H_e_5th_percentiles_Selection_models
for (hotspot in names(empirical_hotspot_tables)) {
  # Append values to the lists
  Hotspot <- c(Hotspot, hotspot)
  Chr <- c(Chr, empirical_hotspot_tables[[hotspot]][["Hotspot_region_data"]][["CHR"]])
  Start <- c(Start ,empirical_hotspot_tables[[hotspot]][["Hotspot_region_data"]][["POS1"]])
  End <- c(End , empirical_hotspot_tables[[hotspot]][["Hotspot_region_data"]][["POS2"]])
  Length_Mb <- c(Length_Mb, empirical_hotspot_tables[[hotspot]][["Hotspot_length_Mb"]])
}


# Combine all values into a data frame
Detected_ROH_hotspots <- data.frame(
  Name = Hotspot,
  Chr = Chr,
  Start = Start,
  End = End,
  Length_Mb = Length_Mb
)

# Display the entire table for all hotspots
knitr::kable(Detected_ROH_hotspots, row.names = FALSE )



```
## 6.1: General Comparison
### 6.1.1: ROH Hotspot Threshold Comparison

```{r 6.1.1: ROH-hotspot threshold comparison ,echo = FALSE,warning = FALSE, results='asis'}
cat("\n ROH-hotspot threshold comparison between the different datasets")
# Print the table using knitr::kable()
knitr::kable(ROH_hotspot_threshold_values_sorted, row.names = FALSE)
```

### 6.1.2: $F_{ROH}$ Comparison
This section shows a plot comparing the population $F_{ROH}$ (y-axis) between each simulation type (x-axis) and the empirical data.

The dashed horizontal red line represents the population $F_{ROH}$ for Labrador
Retriever. The circle for each simulation type represents the point estimate $F_{ROH}$ across all 
simulations. The upper and lower error margins of these point estimates represents the lower
and upper standard error-based confidence intervals with a confidence level of 95%. 
```{r 6.1.2: F_ROH comparison, echo = FALSE,warning = FALSE, results='asis'}
setwd(output_dir)

cat("\n\n")
##############################################
#### Saving the Inbreeding coefficient Plot
##############################################

# Creating an image of the F_ROH plot
png(filename = "Population_F_ROH_comparison_with_CI.png",width = 1920, height = 1080, res = 300)
# Remove the empirical model from the plotting data
plotting_data <- F_ROH_values[F_ROH_values$Model != "Empirical", ]
# Add a column indicating whether the empirical F_ROH is within the CI of each model
empirical_F_ROH <- empirical_avg_F_ROH
plotting_data$Empirical_Within_CI <- (plotting_data$Lower_CI <= empirical_F_ROH) & (plotting_data$Upper_CI >= empirical_F_ROH)

# Create the plot
p <- ggplot(plotting_data, aes(x = Model, y = F_ROH, color = Empirical_Within_CI)) +
  geom_point(size = 3) +
  geom_errorbar(aes(ymin = Lower_CI, ymax = Upper_CI), width = 0.2) +
  # Force the empirical F_ROH line to always be shown
  geom_hline(aes(yintercept = empirical_F_ROH), linetype = "dashed", color = "red", linewidth = 1, show.legend = TRUE) +
  labs(title = "F_ROH Values and Confidence Intervals by Model",
       x = "Model",
       y = "F_ROH",
       color = "Empirical F_ROH\nwithin CI",
       linetype = "Empirical F_ROH") +
  scale_linetype_manual(name = "Empirical F_ROH", values = c("dashed")) +
  scale_color_manual(values = c("TRUE" = "blue", "FALSE" = "black"), labels = c("TRUE" = "Inside CI", "FALSE" = "Outside CI")) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Print the plot
print(p)
# Close the graphics device
dev.off()

##############################################
#### Displaying Inbreeding coefficient Plot
##############################################

# Remove the empirical model from the plotting data
plotting_data <- F_ROH_values[F_ROH_values$Model != "Empirical", ]
# Add a column indicating whether the empirical F_ROH is within the CI of each model
empirical_F_ROH <- empirical_avg_F_ROH
plotting_data$Empirical_Within_CI <- (plotting_data$Lower_CI <= empirical_F_ROH) & (plotting_data$Upper_CI >= empirical_F_ROH)

# Create the plot
p <- ggplot(plotting_data, aes(x = Model, y = F_ROH, color = Empirical_Within_CI)) +
  geom_point(size = 3) +
  geom_errorbar(aes(ymin = Lower_CI, ymax = Upper_CI), width = 0.2) +
  # Force the empirical F_ROH line to always be shown
  geom_hline(aes(yintercept = empirical_F_ROH), linetype = "dashed", color = "red", linewidth = 1, show.legend = TRUE) +
  labs(title = "F_ROH Values and Confidence Intervals by Model",
       x = "Model",
       y = "F_ROH",
       color = "Empirical F_ROH\nwithin CI",
       linetype = "Empirical F_ROH") +
  scale_linetype_manual(name = "Empirical F_ROH", values = c("dashed")) +
  scale_color_manual(values = c("TRUE" = "blue", "FALSE" = "black"), labels = c("TRUE" = "Inside CI", "FALSE" = "Outside CI")) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Print the plot
print(p)
# Print which models the empirical F_ROH is inside of
inside_models <- plotting_data$Model[plotting_data$Empirical_Within_CI]
outside_models <- plotting_data$Model[!plotting_data$Empirical_Within_CI]
cat("\n\n**Models the empirical $F_{ROH}$ is within the CI of:**\n\n")
print(inside_models)
cat("\n**Models the empirical $F_{ROH}$ is outside the CI of:**\n\n")
print(outside_models)


# Print the table using knitr::kable()
knitr::kable(F_ROH_values_sorted, row.names = FALSE)
```

## 6.2: Selection Testing of Empirical ROH Hotspots

### 6.2.1: Selection Test (Sweep Test)
This section shows the selection testing results of the different ROH hotspots based on the window average expected heterozygosity ($H_{e}$).
The Table is sorted by expected heterozygosity in ascending order. 

The threshold value for selection used in this selection test, comes from the lower boundary of the standard-error-based confidence interval for the 5th percentile extreme value of the neutral model simulations.

```{r 6.2.1: Selection test (Sweep test), echo = FALSE,warning = FALSE, results='asis'}
# setwd(Sweep_test_dir)
# Pattern for finding files containing "F_ROH" and ending with ".tsv"
pattern <- "^.*neutral_model.*.tsv$"
selection_testing_files <- list.files(path = Sweep_test_dir, pattern = pattern)


# Extracting the ROH-hotspot threshold value from the suffix of the filename
parts <- unlist(strsplit(selection_testing_files[1], "thr_")) # Split the string by "threshold_"
# Extract the decimal number using regular expressions
fifth_percentile_H_e_neutral_model <- as.numeric(gsub("\\.tsv", "", unlist(strsplit(parts[length(parts)], "_"))[1]))

for (file in selection_testing_files) {
  file_name <- file
  file_path <- file.path(Sweep_test_dir,file)
  # Read the header line
  con <- file(file_path, "r")
  header <- readLines(con, n = 1)
  close(con)
  # Remove "#" from the header and split it into column names
  column_names <- sub("#", "", header)
  column_names <- strsplit(column_names, "\t")[[1]]
  # Read the .tsv frequency file into a data frame
  # Debug
    Selection_testing_results <- read.table(file_path, header = TRUE, comment.char = "#", stringsAsFactors = FALSE, col.names = column_names)

  Selection_testing_results[3] <- round(Selection_testing_results[3],H_e_values_decimals)
  # Remove "_allele_freq" from the names
  Selection_testing_results$Name <- gsub(tolower("_allele_freq$"), "", tolower(Selection_testing_results$Name))

}

# cat("Selection Testing Results. \n\n")
cat("ROH-hotspot windows with a mean $H_{e}$ Value lower than or equal to the lower boundary of the confidence interval for the fifth percentile of the neutral model are classified as being under selection.\n\n")
cat("**The lower boundary of the standard-error-based confidence interval for the 5th percentile of the $H_{e}$-distribution for the neutral model is:**\n\n",fifth_percentile_H_e_neutral_model)

# Print the table using knitr::kable()
knitr::kable(Selection_testing_results, row.names = FALSE) 
formatted_selection_H_e_threshold <- round(fifth_percentile_H_e_neutral_model,H_e_values_decimals)
#Define the filename with the output directory path
filename_csv <- file.path(output_dir, paste("ROH_hotspots_Sweep_test_H_E_threshold_",formatted_selection_H_e_threshold,".csv", sep = ""))
Selection_testing_results_latex <- Selection_testing_results
# Escape underscores in the Name column
Selection_testing_results_latex$Name <- gsub("_", "\\_", Selection_testing_results_latex$Name, fixed = TRUE)
# Write data to CSV file without quotes
write.table(Selection_testing_results_latex, file = filename_csv, sep = ",", row.names = FALSE, quote = FALSE)
# Define the filename with the output directory path
filename <- file.path(paste("ROH_hotspots_Selection_testing_neutral_model_H_E_threshold_",formatted_selection_H_e_threshold,".csv", sep = ""))
# Use the write_latex_table() function to write the data to a LaTeX-compatible text file
write_latex_table(
  data_frame = Selection_testing_results,
  sort_column = "Window_based_Average_H_e",  #
  output_dir = output_dir,
  output_filename = filename  
)
# Subset the dataframe to extract rows where Under_selection is "Yes"
under_selection_rows <- subset(Selection_testing_results, Under_selection == "Yes")
cat("\n\n**ROH hotspots marked as candidate regions for selection:**\n\n")
knitr::kable(under_selection_rows, row.names = FALSE) 
#View(Selection_testing_results)
```

### (Optional) 6.2.2: Sweep Test of Causative Variant Windows

This optional "quality control" step verifies whether the Causative Variant Windows in the simulated selection models are accurately identified as candidate regions for selection based on the results of the sweep test.

```{r (Optional) 6.2.2: Sweep Test of Causative Variant Windows, echo = FALSE,warning = FALSE, results='asis'}
# Initialize vectors to store H_e values and CI bounds for the different selection coefficients
selection_model_avg_values <- c()
selection_model_lower_ci <- c()
selection_model_upper_ci <- c()
selection_model_names <- c()

# Loop through each selection_coefficient in H_e_5th_percentiles_Selection_models
for (selection_coefficient in names(window_H_e_causative_variant_tables)) {
    # Formatting the selection coefficient for when displaying it. Removing "chr[0-9]" and adding a decimal point to the selection coefficient 
  formatted_selection_coefficient_labels <- sub(tolower("s(\\d)(\\d+)_.*"), tolower("s=\\1.\\2"), tolower(selection_coefficient))
  CI <- window_H_e_causative_variant_tables[[selection_coefficient]]$SE_CI_Estimated_Mean_Population_H_e
  # Append values to the lists
  selection_model_names <- c(selection_model_names,formatted_selection_coefficient_labels)
  selection_model_avg_values <- c(selection_model_avg_values, window_H_e_causative_variant_tables[[selection_coefficient]]$Estimated_Mean_Population_H_e)
  selection_model_lower_ci <- c(selection_model_lower_ci, CI[1])
  selection_model_upper_ci <- c(selection_model_upper_ci, CI[2])
}
# Extract neutral model values and CI bounds
neutral_avg_H_e_5th_percentile <- H_e_5th_percentiles_Neutral_model[["Estimated_Mean_H_e_5th_percentile"]]
neutral_lower_ci <- H_e_5th_percentiles_Neutral_model[["SE_CI_Estimated_Mean_H_e_5th_percentile"]][1]
neutral_upper_ci <- H_e_5th_percentiles_Neutral_model[["SE_CI_Estimated_Mean_H_e_5th_percentile"]][2]
# Combine all values into a data frame
H_e_values <- data.frame(
  Model = c(selection_model_names, "Neutral"),
  H_e = c(selection_model_avg_values, neutral_avg_H_e_5th_percentile),
  Lower_CI = c(selection_model_lower_ci, neutral_lower_ci),
  Upper_CI = c(selection_model_upper_ci, neutral_upper_ci)
)
# Format all numeric values to have the number of decimals defined by H_e_values_decimals
H_e_values$H_e <- round(H_e_values$H_e,H_e_values_decimals)
H_e_values$Lower_CI <- as.numeric(round(H_e_values$Lower_CI,H_e_values_decimals))
H_e_values$Upper_CI <- as.numeric(round(H_e_values$Upper_CI,H_e_values_decimals))
# # Update the Model column for selection models
H_e_values$Model[1:length(selection_model_names)] <- selection_model_names
# Extract labels for the different selection coefficients
selection_labels <- gsub(tolower(".*_(s\\d+)_.*"), "\\1", tolower(selection_model_names))
# Add a new column 'under_selection' to the data frame
H_e_values$Under_Selection <- ifelse(H_e_values$H_e < neutral_lower_ci, "Yes", "No")
# Filter the rows where 'under_selection' is 'Yes' and exclude 'Neutral'
Causative_windows_under_selection <- subset(H_e_values, Under_Selection == "Yes" & Model != "Neutral")
Causative_windows_under_selection <- Causative_windows_under_selection[, -which(names(Causative_windows_under_selection) == "Under_Selection")]
H_e_Causative_windows <- subset(H_e_values, Model != "Neutral")
# Sort the results table based on H_e
H_e_values_sorted <- H_e_values[order(as.numeric(H_e_values$H_e)), ]
# Define the filename with the output directory path
filename <- file.path(output_dir, paste("Causative_windows_under_selection",".csv", sep = ""))
# Write data to CSV file without quotes
write.table(H_e_values_sorted, file = filename, sep = ",", row.names = FALSE, quote = FALSE)
# Use the write_latex_table() function to write the data to a LaTeX-compatible text file
write_latex_table(
  data_frame = H_e_values,
  sort_column = "H_e",  # Column used for sorting
  output_dir = output_dir,
  output_filename = "Causative_windows_under_selection"  
)
# Print the table using knitr::kable()
knitr::kable(H_e_values_sorted, row.names = FALSE)
```

<!-- ### 6.2.3: Extracting Hotspot candidate regions for selection --> 

```{r 6.2.3: Extracting Hotspot candidate regions for selection,echo = FALSE,warning = FALSE}
# Initialize an empty list to store the new table
hotspot_under_selection_H_e_table <- list()

# If no Hotspot is under selection, then display all hotspots instead
if (nrow(under_selection_rows) == 0) {
  under_selection_rows <- Selection_testing_results
}
# Loop through each row in under_selection_rows
for (i in 1:nrow(under_selection_rows)) {
  # Extract information for the current ROH-hotspot window
  current_window <- under_selection_rows[i, "Name"]
  under_selection <- under_selection_rows[i, "Under_selection"]
  Hotspot_Avg_H_e <- under_selection_rows[i, "Window_based_Average_H_e"]
  # Initialize a subtable for the current ROH-hotspot window
  subtable <- list()
  # Remove the 'Under_Selection' column from the table
  subtable <- Causative_windows_under_selection
  # Create a list with table name and corresponding data frame
  table_info <- list(Hotspot_Avg_H_e = Hotspot_Avg_H_e, coefficient_data = subtable)
  # Add the subtable for the current ROH-hotspot window to the new table
  hotspot_under_selection_H_e_table[[current_window]] <- c(hotspot_under_selection_H_e_table[[current_window]],table_info)
}
# View the new table
# View(hotspot_under_selection_H_e_table)
```

## 6.3 Functional Assessment of Candidate Regions for Selection
### 6.3.1 Genes Identified in Candidate Regions
This section presents the results of the mapping of genes to the empirical ROH hotspot candidate region(s) for selection.

```{r 6.3.1 Genes Identified in Candidate Regions, echo=FALSE,warning = FALSE, results='asis'}
# setwd(Empirical_data_hotspot_gene_mapping_dir)

#################################################################################### 
### Step 1: Mapping genes to the empirical ROH hotspots
####################################################################################

# Pattern for finding the gene mapping files
pattern <- ".*gene_mapping*\\.txt$"
hotspot_gene_mapping_files <- list.files(path = Empirical_data_hotspot_gene_mapping_dir, pattern = pattern)

# Extract chromosome numbers from the filenames
chr_number_pattern <- ".*_chr(\\d+)_.*\\.txt$"
chr_numbers <- as.numeric(gsub(tolower(chr_number_pattern), "\\1", tolower(hotspot_gene_mapping_files)))

# Create a data frame with file and chromosome information
chr_info <- data.frame(
  chr_number = chr_numbers, 
  file_name = hotspot_gene_mapping_files, 
  stringsAsFactors = FALSE
)

# Sort the dataframe by chromosome number
chr_info <- chr_info[order(chr_info$chr_number), ]

# Initialize an empty list to store the gene mapping tables by chromosome
gene_mapping_tables <- list()
gene_location_tables <- list()   # Simplified table with Gene, POS1, and POS2

# Loop through each file and store data by chromosome
for (i in 1:nrow(chr_info)) {
  file <- chr_info$file_name[i]
  file_path <- file.path(Empirical_data_hotspot_gene_mapping_dir,file)
  chr <- chr_info$chr_number[i]
  
  # Read the file into a data frame
  gene_mapping_data <- read.table(file_path, header = FALSE, comment.char = "#", stringsAsFactors = FALSE, sep = "\t")
  
  # Add chromosome number as an attribute
  attr(gene_mapping_data, "Chromosome_number") <- chr
  
  # Store full gene mapping data
  gene_mapping_tables[[paste0("chr", chr)]] <- gene_mapping_data
  
  # ---- Rename Columns for POS1 and POS2 ----
  colnames(gene_mapping_data)[4] <- "POS1"  # V5 as POS1 (start position)
  colnames(gene_mapping_data)[5] <- "POS2"  # V6 as POS2 (end position)
  
  # ---- Extract Gene Name and Clean It ----
  gene_mapping_data$Gene <- gsub(".*gene_name ([^;]+);.*", "\\1", gene_mapping_data$V13)  # Extract gene name
  gene_mapping_data$Gene <- gsub(";", "", gene_mapping_data$Gene)  # Remove trailing semicolon if any
  
  # ---- Ensure POS1 and POS2 are Numeric ----
  gene_mapping_data$POS1 <- as.numeric(gene_mapping_data$POS1)
  gene_mapping_data$POS2 <- as.numeric(gene_mapping_data$POS2)
  
  # ---- Remove Rows with Missing POS1 or POS2 ----
  gene_mapping_data <- gene_mapping_data[!is.na(gene_mapping_data$POS1) & !is.na(gene_mapping_data$POS2), ]
  
  # ---- Find Unique Genes ----
  unique_genes <- unique(gene_mapping_data$Gene)
  
  # ---- Initialize an Empty Data Frame for Aggregated Data ----
  aggregated_gene_data <- data.frame(Gene = character(), POS1 = numeric(), POS2 = numeric(), stringsAsFactors = FALSE)
  
  # ---- Inner Loop: Aggregate Data for Each Unique Gene ----
  for (gene in unique_genes) {
    gene_rows <- gene_mapping_data[gene_mapping_data$Gene == gene, ]  # Filter rows for the gene
    
    min_pos1 <- min(gene_rows$POS1)  # Find minimum POS1 for this gene
    max_pos2 <- max(gene_rows$POS2)  # Find maximum POS2 for this gene
    
    # Append the result to aggregated_gene_data
    aggregated_gene_data <- rbind(aggregated_gene_data, data.frame(Gene = gene, POS1 = min_pos1, POS2 = max_pos2))
  }
  
  # Store the result in gene_location_tables
  gene_location_tables[[paste0("chr", chr)]] <- aggregated_gene_data
}

# Output the results
# View(gene_mapping_tables)     # Full tables
# View(gene_location_tables)    # Only Gene, POS1, and POS2

#################################################################################### 
### Step 2: Detect genes overlapping with ROH-hotspots
####################################################################################
# Convert gene location list to a single dataframe
gene_location_tables_flat <- do.call(rbind, lapply(names(gene_location_tables), function(chr) {
  df <- gene_location_tables[[chr]]
  df$CHR <- gsub("chr", "", chr)  # Remove "chr" prefix
  df[c("CHR", "POS1", "POS2", "Gene")]  # Reorder columns
}))

# Convert CHR column to numeric if needed
gene_location_tables_flat$CHR <- as.numeric(gene_location_tables_flat$CHR)

gene_location_tables_flat$Gene <- sapply(gene_location_tables_flat$Gene, generate_ensembl_gene_links)

# # Print the final merged table
# print(gene_location_tables_flat)

# View(gene_location_tables)
# View(empirical_hotspot_tables)
for (i in seq_along(empirical_hotspot_tables)) {
  # Extract chromosome and hotspot region boundaries
  CHR <- empirical_hotspot_tables[[i]][["Hotspot_region_data"]][["CHR"]]
  POS1 <- empirical_hotspot_tables[[i]][["Hotspot_region_data"]][["POS1"]]
  POS2 <- empirical_hotspot_tables[[i]][["Hotspot_region_data"]][["POS2"]]
  # cat("Hotspot Window -> POS1:", POS1, " POS2:", POS2, "\n")
  
  # Find genes that partially or fully overlap the hotspot region
  overlapping_genes <- gene_location_tables_flat[
    gene_location_tables_flat$CHR == CHR & 
    gene_location_tables_flat$POS2 >= POS1 &  # Gene end is after or at the region start
    gene_location_tables_flat$POS1 <= POS2,   # Gene start is before or at the region end
  ]

  # Compute Overlap_Percentage for each gene
  if (nrow(overlapping_genes) > 0) {
    overlapping_genes$Overlap_Percentage <- apply(overlapping_genes, 1, function(gene) {
      gene_start <- as.numeric(gene["POS1"])
      gene_end <- as.numeric(gene["POS2"])
      gene_length <- gene_end - gene_start + 1  # Total gene length

      # Compute upstream and downstream outside portions
      upstream_outside <- max(0, POS1 - gene_start)  # If gene starts before hotspot
      downstream_outside <- max(0, gene_end - POS2)  # If gene ends after hotspot
      outside_portion <- upstream_outside + downstream_outside

      # Compute Overlap Percentage
      Overlap_Percentage <- 100 * (1 - (outside_portion / gene_length))
      return(Overlap_Percentage)
    })
  } else {
    overlapping_genes$Hotspot_Overlap_Perc <- numeric(0)  # Empty case
  }

  # Store results
  empirical_hotspot_tables[[i]][["Hotspot_genes"]] <- overlapping_genes
}

#################################################################################### 
### Step 3: Show genes for Hotspots under selection
####################################################################################
#echo = FALSE,warning = FALSE
# Initialize the empty list
Genes_hotspots_under_selection <- list()

# Sorting in alphanumerical order
hotspots_under_selection <- under_selection_rows[order(under_selection_rows$Name), ]

# Loop through each hotspot and filter under selection
for (hotspot in names(empirical_hotspot_tables)) {
  for (selection_hotspot_index in 1:nrow(hotspots_under_selection)) {
    if (tolower(hotspot) == tolower(hotspots_under_selection$Name[selection_hotspot_index])) {
      
      # Extract the genes for the selected hotspot
      genes_data <- empirical_hotspot_tables[[hotspot]][["Hotspot_genes"]]
      
      # Append to the list if genes are found
      if (!is.null(genes_data) && nrow(genes_data) > 0) {
        Genes_hotspots_under_selection[[hotspot]] <- genes_data
      }
      else {
        # Create an empty table for this hotspot and append
        Genes_hotspots_under_selection[[hotspot]] <- data.frame(CHR = character(0),
                                                                POS1 = numeric(0),
                                                                POS2 = numeric(0),
                                                                Gene = character(0),
                                                                Overlap_Percentage = numeric(0))
    }}
  }
}


cat("\n\n**The following gene annotation file was used to map genes to the empirical candidate region(s) for selection:**\n\n", gene_annotations_filepath)

# Check if there are any genes under selection and display a message with the tables
if (length(Genes_hotspots_under_selection) > 0) {
  
  # Print message before displaying tables
  if (length(Genes_hotspots_under_selection) == 1) {
      cat("\n\n**The table below displays the gene(s) that overlap with the ROH hotspot candidate region for selection: ", names(Genes_hotspots_under_selection), ".**\n\n")
  } else {
      cat("\n\n**The tables below show the gene(s) overlapping with the following ROH hotspot candidate regions for selection, listed in order:**", 
          paste(names(Genes_hotspots_under_selection), collapse=", "), ".\n\n")
  }

  cat("**Note:** The column 'Overlap_Percentage' represents the percentage of the gene that overlaps with the candidate region.\n\n")
  
  
  # Loop through each table and render with kableExtra for improved styling
  for(tbl in Genes_hotspots_under_selection) {
    if (nrow(tbl) > 0) {
      # Create a styled HTML table
      table_html <- knitr::kable(tbl, format = "html", 
                                 row.names = FALSE, 
                                 digits = kable_table_digits,
                                 escape = FALSE,
                                 table.attr = "class='table table-bordered table-striped'") %>%
        kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover", "condensed")) %>%
        # Adjust column width; change "3cm" to a width that suits your data
        column_spec(1:ncol(tbl), width = "3cm")
      
      # Output the table and add spacing
      cat(table_html)
      cat("<br><br>\n")
    }
  }
  
  
} else {
  cat("\n\nNo matching hotspots found under selection.\n\n")  # If no hotspots found
}

```

### 6.3.2 Non-Defect (Non-Disease-Related) Phenotypes Identified in Candidate Regions
This section presents the results of the search for known favorable/non-defect (non-disease-related) phenotypes from OMIA that overlap with the ROH hotspot candidate region(s) for selection.

The search was breed-specific and the Vertebrate Breed Ontology (VBO) IDs used were defined in the 'vertebrate_breed_ontology_ids' parameter of the main pipeline script.

```{r 6.3.2 Non-Defect (Non-Disease-Related) Phenotypes Identified in Candidate Regions, echo=FALSE,warning = FALSE, results='asis'}

#############################################################################################
### Step 1: Detect All Breed-specific Non-Defect (Non-Disease-Related) phenotypes overlapping with the ROH-hotspots
#############################################################################################

# Convert phenotype location list to a single dataframe
Breed_phenotypes_tables_flat <- do.call(rbind, lapply(names(Breed_phenotypes_tables), function(VBO_ID) {
  df <- Breed_phenotypes_tables[[VBO_ID]]
}))

# Convert CHR column to numeric if needed
Breed_phenotypes_tables_flat$CHR <- as.numeric(Breed_phenotypes_tables_flat$CHR)


# View(Breed_phenotypes_tables)
# View(empirical_hotspot_tables)
for (i in seq_along(empirical_hotspot_tables)) {
  # Extract chromosome and hotspot region boundaries
  CHR <- empirical_hotspot_tables[[i]][["Hotspot_region_data"]][["CHR"]]
  POS1 <- empirical_hotspot_tables[[i]][["Hotspot_region_data"]][["POS1"]]
  POS2 <- empirical_hotspot_tables[[i]][["Hotspot_region_data"]][["POS2"]]
  # cat("Hotspot Window -> POS1:", POS1, " POS2:", POS2, "\n")
  
  # Find phenotypes that partially or fully overlap the hotspot region
  overlapping_phenotypes <- Breed_phenotypes_tables_flat[
    Breed_phenotypes_tables_flat$CHR == CHR & 
    Breed_phenotypes_tables_flat$POS2 >= POS1 &  # Phenotype end is after or at the region start
    Breed_phenotypes_tables_flat$POS1 <= POS2,   # Phenotype start is before or at the region end
  ]

  # Compute Overlap_Percentage for each phenotype
  if (nrow(overlapping_phenotypes) > 0) {
    overlapping_phenotypes$Overlap_Percentage <- apply(overlapping_phenotypes, 1, function(phenotype) {
      phenotype_start <- as.numeric(phenotype["POS1"])
      phenotype_end <- as.numeric(phenotype["POS2"])
      phenotype_length <- phenotype_end - phenotype_start + 1  # Total phenotype length

      # Compute upstream and downstream outside portions
      upstream_outside <- max(0, POS1 - phenotype_start)  # If phenotype starts before hotspot
      downstream_outside <- max(0, phenotype_end - POS2)  # If phenotype ends after hotspot
      outside_portion <- upstream_outside + downstream_outside

      # Compute Overlap Percentage
      Overlap_Percentage <- 100 * (1 - (outside_portion / phenotype_length))
      return(Overlap_Percentage)
    })
  } else {
    overlapping_phenotypes$Hotspot_Overlap_Perc <- numeric(0)  # Empty case
  }

  # Store results
  empirical_hotspot_tables[[i]][["Hotspot_phenotypes"]] <- overlapping_phenotypes
}


##################################################################################################
### Step 2: Show all non-defect (non-disease-related) phenotypes overlapping with the candidate regions for selection
##################################################################################################

All_phenotypes_hotspots_under_selection <- list()

# Sorting in alphanumerical order
hotspots_under_selection <- under_selection_rows[order(under_selection_rows$Name), ]

# Loop through each hotspot and filter under selection
for (hotspot in names(empirical_hotspot_tables)) {
  for (selection_hotspot_index in 1:nrow(hotspots_under_selection)) {
    if (tolower(hotspot) == tolower(hotspots_under_selection$Name[selection_hotspot_index])) {
      
      # Extract the phenotypes for the selected hotspot
      phenotypes_data <- empirical_hotspot_tables[[hotspot]][["Hotspot_species_phenotypes"]]
      
      # Append to the list if phenotypes are found
      if (!is.null(phenotypes_data) && nrow(phenotypes_data) > 0) {
        All_phenotypes_hotspots_under_selection[[hotspot]] <- phenotypes_data
      }

      }
  }
}

cat("**The following Vertebrate Breed Ontology (VBO) ID(s) were used to map phenotypes from OMIA with each candidate region for selection:** ", generate_vbo_links(vertebrate_breed_ontology_ids))


cat("\n\n**The following OMIA phenotype file was used to map phenotypes to the empirical candidate region(s) for selection:**\n\n", omia_phenotypes_filepath)

# Debugging purposes
# All_phenotypes_hotspots_under_selection[["hotspot_1"]] <- Breed_phenotypes_tables[[1]][1, ] 
# All_phenotypes_hotspots_under_selection[["hotspot_2"]] <- Breed_phenotypes_tables[[1]][2, ] 


# Check if there are any phenotypes under selection and display a message with the tables
if (length(All_phenotypes_hotspots_under_selection) > 0) {
  
  # Print a phenotyperal message before displaying tables
  if (length(All_phenotypes_hotspots_under_selection) == 1) {
      cat("\n\n**The table below displays the phenotype(s) that overlap with the ROH hotspot candidate region for selection,",names(All_phenotypes_hotspots_under_selection),".**\n\n")

  } else {
    cat("\n\n**The tables below displays the phenotypes that overlap with the following ROH hotspot candidate regions for selection, listed in order: ", paste(names(All_phenotypes_hotspots_under_selection), collapse=", "), ".**\n\n")
  }

  # Loop through each table and render with kableExtra for improved styling
  for(tbl in All_phenotypes_hotspots_under_selection) {
    if (nrow(tbl) > 0) {
      # Create a styled HTML table
      table_html <- knitr::kable(tbl, format = "html", 
                                 row.names = FALSE, 
                                 digits = kable_table_digits,
                                 escape = FALSE,
                                 table.attr = "class='table table-bordered table-striped'") %>%
        kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover", "condensed")) %>%
        # Adjust column width; change "3cm" to a width that suits your data
        column_spec(1:ncol(tbl), width = "3cm")
      
      # Output the table and add spacing
      cat(table_html)
      cat("<br><br>\n")
    }
  }
  
  
} else {
  cat("\n\n**Result:**\n\nNo Non-Defect (Non-Disease-Related) phenotypes were discovered for the ROH hotspot candidate region(s) for selection \n") 
}

```

## 6.4: Selection Strength Estimation of Empirical ROH Hotspot Candidate Region(s) For Selection
In this section, the selection coefficients of empirical ROH-Hotspots, identified as candidate regions for selection, are estimated by comparing these regions with the Causative Variant Windows of the simulated selection models.

By identifying the selection model that produces Causative Variant Windows most similar to the empirical region in terms of:

--   **ROH frequency**

--   **Expected heterozygosity ($H_{e}$)**

--   **Window length**

one can infer that the selection coefficient of the empirical candidate region likely corresponds to the selection coefficient of the matched selection model.

### 6.4.1: Comparison of ROH Hotspots and Causative Variant Windows
The following section compares the empirical ROH hotspot candidate region(s) for selection with the causative variant windows from the different selection models. The table is sorted by the selection strength of the models in descending alphanumerical order.

```{r 6.4.1: Comparison of ROH-Hotspots and Causative Variant Windows, echo = FALSE,warning = FALSE, results='asis'}
# Initialize an empty data frame to store the results
results_df <- data.frame()
hotspot_avg_H_e <- c()
hotspot_under_selection <- c()
hotspot_lengths_mb <- c()
hotspot_names <- c()
hotspot_avg_roh_freq <- c()
for (i in seq_along(empirical_hotspot_tables)) {
  hotspot_name <- names(empirical_hotspot_tables)[i]
  if (tolower(hotspot_name) %in% tolower(under_selection_rows$Name)) {
      matching_row <- Selection_testing_results[tolower(Selection_testing_results$Name) == tolower(hotspot_name), ]
      hotspot_avg_H_e <- c(hotspot_avg_H_e,matching_row$Window_based_Average_H_e)  
      # hotspot_under_selection <- matching_row$Under_selection
      hotspot_under_selection <- c(hotspot_under_selection,matching_row$Under_selection)
      capitalized_hotspot_name <- paste0(toupper(substring(hotspot_name, 1, 1)), substring(hotspot_name, 2))
      hotspot_length_mb <- empirical_hotspot_tables[[i]][["Hotspot_length_Mb"]]
      hotspot_lengths_mb <- c(hotspot_lengths_mb,hotspot_length_mb)
      hotspot_names <- c(hotspot_names,capitalized_hotspot_name)
      hotspot_avg_freq <- empirical_hotspot_tables[[i]][["Avg_frequency"]]
      hotspot_avg_roh_freq <- c(hotspot_avg_roh_freq,hotspot_avg_freq)
} else {
}

}
# Scaling to percentage
hotspot_avg_roh_freq <- 100*hotspot_avg_roh_freq
causative_variant_windows_he <- subset(H_e_values, Model != "Neutral")
selection_coefficient_variant_windows_length_mb <- causative_variant_window_results_df$Length_Mb
selection_coefficient_variant_windows_length_mb_lower_ci <- causative_variant_window_results_df$Length_lower_CI
selection_coefficient_variant_windows_length_mb_upper_ci <- causative_variant_window_results_df$Length_Upper_CI
selection_coefficient_variant_windows_ROH_freq <- causative_variant_window_results_df$ROH_freq
selection_coefficient_variant_windows_ROH_freq_lower_ci <- causative_variant_window_results_df$ROH_freq_lower_CI
selection_coefficient_variant_windows_ROH_freq_upper_ci <- causative_variant_window_results_df$ROH_freq_upper_CI
selection_coefficient_variant_windows_avg_H_e <- causative_variant_window_results_df$Avg_H_e
selection_coefficient_variant_windows_H_e_lower_ci <- causative_variant_window_results_df$H_e_lower_CI
selection_coefficient_variant_windows_H_e_upper_ci <- causative_variant_window_results_df$H_e_upper_CI
selection_coefficient_name <- causative_variant_window_results_df$Sel.coeff
empirical_na <- NA
# Combine all values into a data frame
Hotspots_and_Causative_windows_comparison <- data.frame(
  Model = c(hotspot_names, selection_coefficient_name),
  Lengths_Mb = c(hotspot_lengths_mb, selection_coefficient_variant_windows_length_mb),
  Length_lower_ci = c(rep(NA, length(hotspot_names)), selection_coefficient_variant_windows_length_mb_lower_ci),
  Length_upper_ci = c(rep(NA, length(hotspot_names)), selection_coefficient_variant_windows_length_mb_upper_ci),
  ROH_Freq = c(hotspot_avg_roh_freq, selection_coefficient_variant_windows_ROH_freq),
  ROH_freq_lower_ci = c(rep(NA, length(hotspot_names)), selection_coefficient_variant_windows_ROH_freq_lower_ci),
  ROH_freq_upper_ci = c(rep(NA, length(hotspot_names)), selection_coefficient_variant_windows_ROH_freq_upper_ci),
  H_e = c(hotspot_avg_H_e, selection_coefficient_variant_windows_avg_H_e),
  H_e_lower_ci = c(rep(NA, length(hotspot_names)), selection_coefficient_variant_windows_H_e_lower_ci),
  H_e_upper_ci = c(rep(NA, length(hotspot_names)), selection_coefficient_variant_windows_H_e_upper_ci)
)
Hotspots_and_Causative_windows_comparison$ROH_Freq <- round(Hotspots_and_Causative_windows_comparison$ROH_Freq,ROH_frequency_decimals)
Hotspots_and_Causative_windows_comparison$H_e <- round(Hotspots_and_Causative_windows_comparison$H_e,H_e_values_decimals)
Hotspots_and_Causative_windows_comparison$Lengths_Mb <- round(Hotspots_and_Causative_windows_comparison$Lengths_Mb,Window_lengths_decimals)
# Sort the data frame based on the 'Model' column in descending order
Hotspots_and_Causative_windows_comparison_sorted <- Hotspots_and_Causative_windows_comparison[order(Hotspots_and_Causative_windows_comparison$Model, decreasing = TRUE), ]
# Now, create a new data frame with confidence intervals as tuples
Hotspots_and_Causative_windows_CI_tuples <- data.frame(
  Model = Hotspots_and_Causative_windows_comparison$Model,
  Lengths_Mb = Hotspots_and_Causative_windows_comparison$Lengths_Mb,
  Length_CI = ifelse(is.na(Hotspots_and_Causative_windows_comparison$Length_lower_ci), NA, 
                     paste0("(", Hotspots_and_Causative_windows_comparison$Length_lower_ci, ", ", Hotspots_and_Causative_windows_comparison$Length_upper_ci, ")")),
  ROH_Freq = Hotspots_and_Causative_windows_comparison$ROH_Freq,
  ROH_Freq_CI = ifelse(is.na(Hotspots_and_Causative_windows_comparison$ROH_freq_lower_ci), NA, 
                       paste0("(", Hotspots_and_Causative_windows_comparison$ROH_freq_lower_ci, ", ", Hotspots_and_Causative_windows_comparison$ROH_freq_upper_ci, ")")),
  H_e = Hotspots_and_Causative_windows_comparison$H_e,
  H_e_CI = ifelse(is.na(Hotspots_and_Causative_windows_comparison$H_e_lower_ci), NA, 
                  paste0("(", Hotspots_and_Causative_windows_comparison$H_e_lower_ci, ", ", Hotspots_and_Causative_windows_comparison$H_e_upper_ci, ")"))
)
# Sort the new data frame with tuples based on the 'Model' column in descending order
Hotspots_and_Causative_windows_CI_tuples_sorted <- Hotspots_and_Causative_windows_CI_tuples[order(Hotspots_and_Causative_windows_CI_tuples$Model, decreasing = TRUE), ]

Hotspots_and_Causative_windows_CI_tuples_sorted$Model <- gsub("_", "\\_", Hotspots_and_Causative_windows_CI_tuples_sorted$Model, fixed = TRUE)
Hotspots_and_Causative_windows_CI_tuples_sorted$Length_CI <- gsub(",", "\\,", Hotspots_and_Causative_windows_CI_tuples_sorted$Length_CI, fixed = TRUE)
Hotspots_and_Causative_windows_CI_tuples_sorted$ROH_Freq_CI <- gsub(",", "\\,", Hotspots_and_Causative_windows_CI_tuples_sorted$ROH_Freq_CI, fixed = TRUE)
Hotspots_and_Causative_windows_CI_tuples_sorted$H_e_CI <- gsub(",", "\\,", Hotspots_and_Causative_windows_CI_tuples_sorted$H_e_CI, fixed = TRUE)

# Define the filename for the new data frame with CI tuples
filename_tuples <- file.path(output_dir, paste("ROH_Hotspots_and_Causative_Windows_comparison",".csv", sep = ""))
# Write the new sorted data frame to CSV file without quotes
write.table(Hotspots_and_Causative_windows_CI_tuples_sorted, file = filename_tuples, sep = ",", row.names = FALSE, quote = FALSE)
kable(Hotspots_and_Causative_windows_comparison_sorted, row.names = FALSE)
# View(causative_variant_window_results_df)


# # Comparison Sorted after the different metrics
#  kable(Hotspots_and_Causative_windows_comparison[order(-Hotspots_and_Causative_windows_comparison$Lengths_Mb), ])
#  kable(Hotspots_and_Causative_windows_comparison[order(-Hotspots_and_Causative_windows_comparison$ROH_Freq), ])
#  kable(Hotspots_and_Causative_windows_comparison[order(-Hotspots_and_Causative_windows_comparison$H_e), ])

```

### 6.4.2: 3D Plot Comparison of Mean Values
This section presents a 3D-scatterplot comparing the ROH hotspot candidate region(s) for selection in the empirical dataset with the causative variant windows from different selection models (displayed in monochromatic color).
The axes are defined as follows:

- **x-axis:** Represents the average ROH frequency of 100 kbp windows in the respective regions (percentage).

- **y-axis:** Represents the average $H_{e}$ of 100 kbp windows in the respective regions.

- **z-axis:** Represents the average length of the respective regions (in megabases).

To enhance the readability of the plots have vertical lines been added for each data point, projecting the regions onto the x-y plane.

```{r 6.4.2: 3D Plot Comparison of Mean Values, echo = FALSE,warning = FALSE, results='asis'}
setwd(output_dir)

add_2d_shadows_to_3d_plot <- TRUE
# add_2d_shadows_to_3d_plot <- FALSE

plot_title <- paste("ROH Hotspot(s) & Causative Windows comparison")
# Modify the labels by removing "Hotspot_" prefix and "_window" suffix from hotspot models
Hotspots_and_Causative_windows_comparison_sorted$Label <- ifelse(
  grepl("Hotspot", Hotspots_and_Causative_windows_comparison_sorted$Model), 
  gsub("Hotspot_|_window", "", Hotspots_and_Causative_windows_comparison_sorted$Model), 
  Hotspots_and_Causative_windows_comparison_sorted$Model
)
# Removing the "s=" part from the selection coefficients for the plot display
Hotspots_and_Causative_windows_comparison_sorted$Label <- gsub("^s=", "", Hotspots_and_Causative_windows_comparison_sorted$Label)
# Create a new column for identifying the type
Hotspots_and_Causative_windows_comparison_sorted$Type <- ifelse(
  grepl("Hotspot", Hotspots_and_Causative_windows_comparison_sorted$Model), 
  "Hotspot", 
  "Selection Coefficient"
)
# Generate a color palette for the hotspots
hotspot_models <- unique(Hotspots_and_Causative_windows_comparison_sorted$Model[Hotspots_and_Causative_windows_comparison_sorted$Type == "Hotspot"])
num_hotspots <- length(hotspot_models)
# Choose the color palette based on the number of hotspots
if (num_hotspots == 2) {
  color_palette_name <- "Set2"
} else {
  color_palette_name <- "Set3"
}
# Get the colors for the hotspots
hotspot_colors <- setNames(brewer.pal(n = num_hotspots, name = color_palette_name), hotspot_models)
# Assign colors to each point
Hotspots_and_Causative_windows_comparison_sorted$Color <- ifelse(
  Hotspots_and_Causative_windows_comparison_sorted$Type == "Hotspot", 
  hotspot_colors[Hotspots_and_Causative_windows_comparison_sorted$Model], 
  "blue"
)
x_value <- Hotspots_and_Causative_windows_comparison_sorted$ROH_Freq
x_axis_label <- "Avg ROH-frequency (%)"
y_value <- Hotspots_and_Causative_windows_comparison_sorted$Lengths_Mb
y_axis_label <- "Length (Mb)"
z_value <- Hotspots_and_Causative_windows_comparison_sorted$H_e
z_axis_label <- "Avg H_e"

x_value <- Hotspots_and_Causative_windows_comparison_sorted$ROH_Freq
x_axis_label <- "Avg ROH-frequency (%)"
y_value <- Hotspots_and_Causative_windows_comparison_sorted$H_e
y_axis_label <- "Avg H_e"
z_value <- Hotspots_and_Causative_windows_comparison_sorted$Lengths_Mb
z_axis_label <- "Length (Mb)"


# # Create and save the 3D scatter plot as a PNG file
# png(filename = "3dplot_Hotspot_Causative_Window_Comparison.png", width = 1920, height = 1080, res = 300)
# png(filename = "3dplot_Hotspot_Causative_Window_Comparison.png",width = 800, height = 600, res = 300)


# Create the 3D scatter plot
s3d <- scatterplot3d(
  x_value,
  y_value,
  z_value,
  color = Hotspots_and_Causative_windows_comparison_sorted$Color,
  pch = 19, # Solid circle
  # pch = 20, # Solid circle
  xlab = x_axis_label,
  ylab = y_axis_label,
  zlab = z_axis_label,
  main = plot_title,
  angle=65,
  type = "h",
  scale.y = 1,
  axis = TRUE,
  grid = TRUE,
  box = TRUE,
  # highlight.3d = TRUE
  
)

# Convert coordinates for adding labels
s3d.coords <- s3d$xyz.convert(
  x_value,
  y_value,
  z_value
)

# Add labels to the original points
text(s3d.coords$x, s3d.coords$y, 
     labels = Hotspots_and_Causative_windows_comparison_sorted$Label, 
     pos = 2.5, cex = 0.5, font = 2) # pos=3 means above


# # Close the graphics device
# dev.off()

```

### 6.4.3: Visualization of Confidence Intervals and Means

In this section, plots of the standard error-based confidence intervals, alongside mean values, are created to account for the distribution of values, rather than relying solely on the mean (as is the case in the 3D-plot).

These plots are generated individually for each empirical candidate region for selection, allowing a more detailed comparison between each empirical ROH Hotspot and the Causative Variant Windows of the simulated selection models.

#### 6.4.3.1: Standard Error CI for $H_{e}$
The following section displays plot(s) comparing the average expected heterozygosity of the empirical ROH Hotspot(s) with the corresponding standard error-based confidence intervals for
the different causative variant windows.

```{r 6.4.3.1: Standard Error CI for H_e, echo = FALSE,warning = FALSE, results='asis'}
setwd(output_dir)
generate_H_e_plot <- function(hotspot_name, empirical_value) {
  image_name <- paste0("Selection_strength_H_e_plot_", hotspot_name)
  # Create and save the 3D scatter plot as a PNG file
  png(filename = paste0(image_name, ".png"), width = 1920, height = 1080, res = 300)
  # Initialize plotting_data by directly selecting relevant columns from causative_variant_window_results_df
  plotting_data <- data.frame(
    sim_mean_value = causative_variant_window_results_df$Avg_H_e,
    Lower_CI = causative_variant_window_results_df$H_e_lower_CI,
    Upper_CI = causative_variant_window_results_df$H_e_upper_CI,
    Model = causative_variant_window_results_df$Sel.coeff
  )
  # Add a column indicating whether the empirical H_e is within the CI of each model
  plotting_data$Empirical_Within_CI <- (plotting_data$Lower_CI <= empirical_value) & (plotting_data$Upper_CI >= empirical_value)
  # Determine the y-axis limits
  min_y <- min(c(plotting_data$Lower_CI, empirical_value))
  max_y <- max(c(plotting_data$Upper_CI, empirical_value))
  # Create the plot
  p <- ggplot(plotting_data, aes(x = Model, y = sim_mean_value, color = Empirical_Within_CI)) +
    geom_point(size = H_e_values_decimals) +
    geom_errorbar(aes(ymin = Lower_CI, ymax = Upper_CI), width = 0.2) +
    geom_hline(aes(yintercept = empirical_value), linetype = "dashed", color = "red", linewidth = 1, show.legend = TRUE) +
    labs(title = paste("H_e Comparison with CI:s - ", hotspot_name),
         x = "Model",
         y = "H_e",
         color = "Hotspot Average H_e (Red) \nin relation to CI") +
    scale_color_manual(values = c("TRUE" = "darkgreen", "FALSE" = "black"), labels = c("TRUE" = "Inside CI", "FALSE" = "Outside CI")) +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    scale_y_continuous(
      limits = c(min_y, max_y),
      breaks = round(seq(min_y, max_y, length.out = 10), 5),
      labels = scales::number_format(accuracy = 0.001)  # Format y-axis to 3 decimal places
    )
  # Print the plot
  print(p)
  # Print which models the empirical H_e is inside of
  inside_models <- plotting_data$Model[plotting_data$Empirical_Within_CI]
  outside_models <- plotting_data$Model[!plotting_data$Empirical_Within_CI]
  # Close the graphics device
  dev.off()
}

display_H_e_plot <- function(hotspot_name, empirical_value) {
  # Initialize plotting_data by directly selecting relevant columns from causative_variant_window_results_df
  plotting_data <- data.frame(
    sim_mean_value = causative_variant_window_results_df$Avg_H_e,
    Lower_CI = causative_variant_window_results_df$H_e_lower_CI,
    Upper_CI = causative_variant_window_results_df$H_e_upper_CI,
    Model = causative_variant_window_results_df$Sel.coeff
  )
  # Add a column indicating whether the empirical H_e is within the CI of each model
  plotting_data$Empirical_Within_CI <- (plotting_data$Lower_CI <= empirical_value) & (plotting_data$Upper_CI >= empirical_value)
  # Determine the y-axis limits
  min_y <- min(c(plotting_data$Lower_CI, empirical_value))
  max_y <- max(c(plotting_data$Upper_CI, empirical_value))
  # Create the plot
  p <- ggplot(plotting_data, aes(x = Model, y = sim_mean_value, color = Empirical_Within_CI)) +
    geom_point(size = H_e_values_decimals) +
    geom_errorbar(aes(ymin = Lower_CI, ymax = Upper_CI), width = 0.2) +
    geom_hline(aes(yintercept = empirical_value), linetype = "dashed", color = "red", linewidth = 1, show.legend = TRUE) +
    labs(title = paste("H_e Comparison with CI:s - ", hotspot_name),
         x = "Model",
         y = "H_e",
         color = "Hotspot Average H_e (Red) \nin relation to CI") +
    scale_color_manual(values = c("TRUE" = "darkgreen", "FALSE" = "black"), labels = c("TRUE" = "Inside CI", "FALSE" = "Outside CI")) +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    scale_y_continuous(
      limits = c(min_y, max_y),
      breaks = round(seq(min_y, max_y, length.out = 10), 5),
      labels = scales::number_format(accuracy = 0.001)  # Format y-axis to 3 decimal places
    )
  # Print the plot
  print(p)
  # Print which models the empirical H_e is inside of
  inside_models <- plotting_data$Model[plotting_data$Empirical_Within_CI]
  outside_models <- plotting_data$Model[!plotting_data$Empirical_Within_CI]
  
  cat("\n\n**Models whose confidence intervals contain the empirical $H_{e}$ for", hotspot_name, ":**\n\n")

  if (length(inside_models) == 0) {
    cat("No models had confidence intervals containing the empirical $H_{e}$.")
  } else {
    print(inside_models)
  }
  
  cat("\n\n**Models in which the empirical $H_{e}$, for",hotspot_name, ", falls outside the confidence interval:**\n\n")
  if (length(outside_models) == 0) {
    cat("None – the empirical $H_{e}$ is within all confidence intervals of the simulated models.")
  } else {
    print(outside_models)
  }

  
}

# Loop through each hotspot and generate plots
for (i in 1:nrow(under_selection_rows)) {
  hotspot_name <- tools::toTitleCase(Selection_testing_results$Name[i])
  empirical_value <- Selection_testing_results$Window_based_Average_H_e[i]
  generate_H_e_plot(hotspot_name, empirical_value)
  display_H_e_plot(hotspot_name, empirical_value)
  cat("\n\n")
}
```

#### 6.4.3.2: Standard Error CI for Window Length
The following section displays plot(s) comparing the average Window length of the empirical ROH hotspot(s) with the corresponding standard error-based confidence intervals for
the different causative variant windows.

```{r 6.4.3.2: Standard Error CI for Window Length,echo = FALSE,warning = FALSE, results='asis'}
setwd(output_dir)
generate_window_length_plot <- function(hotspot_name, empirical_value) {
  image_name <- paste0("Selection_strength_window_lengths_plot_", hotspot_name)
  # Create and save the 3D scatter plot as a PNG file
  png(filename = paste0(image_name, ".png"), width = 1920, height = 1080, res = 300)
  plotting_data <- data.frame()
  # Initialize plotting_data by directly selecting relevant columns from causative_variant_window_results_df
  plotting_data <- data.frame(
    sim_mean_value = causative_variant_window_results_df$Length_Mb,
    Lower_CI = causative_variant_window_results_df$Length_lower_CI,
    Upper_CI = causative_variant_window_results_df$Length_Upper_CI,
    Model = causative_variant_window_results_df$Sel.coeff
  )
  # Add a column indicating whether the empirical Window Length is within the CI of each model
  plotting_data$Empirical_Within_CI <- (plotting_data$Lower_CI <= empirical_value) & (plotting_data$Upper_CI >= empirical_value)
  # print(plotting_data)
  # Determine the y-axis limits
  min_y <- min(c(plotting_data$Lower_CI, empirical_value))
  max_y <- max(c(plotting_data$Upper_CI, empirical_value))
  # Create the plot
  p <- ggplot(plotting_data, aes(x = Model, y = sim_mean_value, color = Empirical_Within_CI)) +
    geom_point(size = Window_lengths_decimals) +
    geom_errorbar(aes(ymin = Lower_CI, ymax = Upper_CI), width = 0.2) +
    geom_hline(aes(yintercept = empirical_value), linetype = "dashed", color = "red", linewidth = 1, show.legend = TRUE) +
    labs(title = paste("Length (Mb) Comparison with CI:s - ", hotspot_name),
         x = "Model",
         y = "Length (Mb)",
         color = "Hotspot Window Length (Red) \nin relation to CI") +
    scale_color_manual(values = c("TRUE" = "darkgreen", "FALSE" = "black"), labels = c("TRUE" = "Inside CI", "FALSE" = "Outside CI")) +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    scale_y_continuous(limits = c(min_y, max_y), 
                       breaks = round(seq(min_y, max_y, length.out = 10), 5),
                       labels = scales::number_format(accuracy = 1/(10^Window_lengths_decimals)))  # Format y-axis to 3 decimal places

       
  # Print the plot
  print(p)
  # Close the graphics device
  dev.off()
}

display_window_length_plot <- function(hotspot_name, empirical_value) {
  plotting_data <- data.frame()
  # Initialize plotting_data by directly selecting relevant columns from causative_variant_window_results_df
  plotting_data <- data.frame(
    sim_mean_value = causative_variant_window_results_df$Length_Mb,
    Lower_CI = causative_variant_window_results_df$Length_lower_CI,
    Upper_CI = causative_variant_window_results_df$Length_Upper_CI,
    Model = causative_variant_window_results_df$Sel.coeff
  )
  # Add a column indicating whether the empirical Window Length is within the CI of each model
  plotting_data$Empirical_Within_CI <- (plotting_data$Lower_CI <= empirical_value) & (plotting_data$Upper_CI >= empirical_value)
  # print(plotting_data)
  # Determine the y-axis limits
  min_y <- min(c(plotting_data$Lower_CI, empirical_value))
  max_y <- max(c(plotting_data$Upper_CI, empirical_value))
  # Create the plot
  p <- ggplot(plotting_data, aes(x = Model, y = sim_mean_value, color = Empirical_Within_CI)) +
    geom_point(size = Window_lengths_decimals) +
    geom_errorbar(aes(ymin = Lower_CI, ymax = Upper_CI), width = 0.2) +
    geom_hline(aes(yintercept = empirical_value), linetype = "dashed", color = "red", linewidth = 1, show.legend = TRUE) +
    labs(title = paste("Length (Mb) Comparison with CI:s - ", hotspot_name),
         x = "Model",
         y = "Length (Mb)",
         color = "Hotspot Window Length (Red) \nin relation to CI") +
    scale_color_manual(values = c("TRUE" = "darkgreen", "FALSE" = "black"), labels = c("TRUE" = "Inside CI", "FALSE" = "Outside CI")) +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    scale_y_continuous(limits = c(min_y, max_y), 
                       breaks = round(seq(min_y, max_y, length.out = 10), 5),
                       labels = scales::number_format(accuracy = 1/(10^Window_lengths_decimals)))  # Format y-axis to 3 decimal places

       
  # Print the plot
  print(p)
  # Print which models the empirical Window Length is inside of
  inside_models <- plotting_data$Model[plotting_data$Empirical_Within_CI]
  outside_models <- plotting_data$Model[!plotting_data$Empirical_Within_CI]
  
  cat("\n\n**Models whose confidence intervals contain the empirical window length for", hotspot_name, ":**\n\n")

  if (length(inside_models) == 0) {
    cat("No models had confidence intervals containing the empirical window length.")
  } else {
    print(inside_models)
  }
  
  cat("\n\n**Models in which the empirical window length, for",hotspot_name, ", falls outside the confidence interval:**\n\n")
  if (length(outside_models) == 0) {
    cat("None – the empirical window length is within all confidence intervals of the simulated models.")
  } else {
    print(outside_models)
  }
  
  
  
}


Hotspot_windows_sel_strength_test <- Hotspots_and_Causative_windows_comparison[grepl("Hotspot", Hotspots_and_Causative_windows_comparison$Model), ]

# Sort the data frame by the lowest H_e value (increasing order)
Hotspot_windows_sel_strength_test <- Hotspot_windows_sel_strength_test[order(Hotspot_windows_sel_strength_test$H_e), ]


# Loop through each hotspot and generate plots
for (i in 1:nrow(Hotspot_windows_sel_strength_test)) {
  hotspot_name <- tools::toTitleCase(Hotspot_windows_sel_strength_test$Model[i])
  empirical_value <- Hotspot_windows_sel_strength_test$Lengths_Mb[i]
  generate_window_length_plot(hotspot_name, empirical_value)
  display_window_length_plot(hotspot_name, empirical_value)
}
```

#### 6.4.3.3: Standard Error CI for ROH Frequency
The following section displays plot(s) comparing the average ROH-frequency of the empirical ROH hotspot(s) with the corresponding standard error-based confidence intervals for the different causative variant windows.
```{r 6.4.3.3: Standard Error CI for ROH Frequency,echo = FALSE,warning = FALSE, results='asis'}
setwd(output_dir)
generate_roh_freq_plot <- function(hotspot_name, empirical_value) {
  image_name <- paste0("Selection_strength_ROH_frequency_plot_", hotspot_name)
  # Create and save the 3D scatter plot as a PNG file
  png(filename = paste0(image_name, ".png"), width = 1920, height = 1080, res = 300)
  plotting_data <- data.frame()
  # Initialize plotting_data by directly selecting relevant columns from causative_variant_window_results_df
  plotting_data <- data.frame(
    sim_mean_value = causative_variant_window_results_df$ROH_freq,
    Lower_CI = causative_variant_window_results_df$ROH_freq_lower_CI,
    Upper_CI = causative_variant_window_results_df$ROH_freq_upper_CI,
    Model = causative_variant_window_results_df$Sel.coeff
  )
  # Add a column indicating whether the empirical ROH-frequency is within the CI of each model
  plotting_data$Empirical_Within_CI <- (plotting_data$Lower_CI <= empirical_value) & (plotting_data$Upper_CI >= empirical_value)
  # cat(plotting_data$Empirical_Within_CI)
  # print(plotting_data)

  # Determine the y-axis limits
  min_y <- min(c(plotting_data$Lower_CI, empirical_value))
  max_y <- max(c(plotting_data$Upper_CI, empirical_value))
  # Create the plot
  p <- ggplot(plotting_data, aes(x = Model, y = sim_mean_value, color = Empirical_Within_CI)) +
    geom_point(size = ROH_frequency_decimals) +
    geom_errorbar(aes(ymin = Lower_CI, ymax = Upper_CI), width = 0.2) +
    geom_hline(aes(yintercept = empirical_value), linetype = "dashed", color = "red", linewidth = 1, show.legend = TRUE) +
    labs(title = paste("ROH-Frequency Comparison with CI:s - ", hotspot_name),
         x = "Model",
         y = "ROH Freq (%)",
         color = "Hotspot ROH Freq (%) (Red) \nin relation to CI") +
    scale_color_manual(values = c("TRUE" = "darkgreen", "FALSE" = "black"), labels = c("TRUE" = "Inside CI", "FALSE" = "Outside CI")) +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    scale_y_continuous(
      limits = c(min_y, max_y),

      breaks = round(seq(min_y, max_y, length.out = 10), 5),

      labels = scales::number_format(accuracy = 1/(10^ROH_frequency_decimals)))  # Format y-axis to 3 decimal places
    # scale_y_continuous(limits = c(min_y, max_y), 
    #                    breaks = round(seq(min_y, max_y, length.out = 10), 5))

  # Print the plot
  print(p)
  # Close the graphics device
  dev.off()
}

display_roh_freq_plot <- function(hotspot_name, empirical_value) {
  plotting_data <- data.frame()
  # Initialize plotting_data by directly selecting relevant columns from causative_variant_window_results_df
  plotting_data <- data.frame(
    sim_mean_value = causative_variant_window_results_df$ROH_freq,
    Lower_CI = causative_variant_window_results_df$ROH_freq_lower_CI,
    Upper_CI = causative_variant_window_results_df$ROH_freq_upper_CI,
    Model = causative_variant_window_results_df$Sel.coeff
  )
  # Add a column indicating whether the empirical ROH-frequency is within the CI of each model
  plotting_data$Empirical_Within_CI <- (plotting_data$Lower_CI <= empirical_value) & (plotting_data$Upper_CI >= empirical_value)
  # cat(plotting_data$Empirical_Within_CI)
  # print(plotting_data)

  # Determine the y-axis limits
  min_y <- min(c(plotting_data$Lower_CI, empirical_value))
  max_y <- max(c(plotting_data$Upper_CI, empirical_value))
  # Create the plot
  p <- ggplot(plotting_data, aes(x = Model, y = sim_mean_value, color = Empirical_Within_CI)) +
    geom_point(size = ROH_frequency_decimals) +
    geom_errorbar(aes(ymin = Lower_CI, ymax = Upper_CI), width = 0.2) +
    geom_hline(aes(yintercept = empirical_value), linetype = "dashed", color = "red", linewidth = 1, show.legend = TRUE) +
    labs(title = paste("ROH-Frequency Comparison with CI:s - ", hotspot_name),
         x = "Model",
         y = "ROH Freq (%)",
         color = "Hotspot ROH Freq (%) (Red) \nin relation to CI") +
    scale_color_manual(values = c("TRUE" = "darkgreen", "FALSE" = "black"), labels = c("TRUE" = "Inside CI", "FALSE" = "Outside CI")) +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    scale_y_continuous(
      limits = c(min_y, max_y),

      breaks = round(seq(min_y, max_y, length.out = 10), 5),

      labels = scales::number_format(accuracy = 1/(10^ROH_frequency_decimals)))  # Format y-axis to 3 decimal places
    # scale_y_continuous(limits = c(min_y, max_y), 
    #                    breaks = round(seq(min_y, max_y, length.out = 10), 5))

  # Print the plot
  print(p)

  # Print which models the empirical ROH-frequency is inside of
  inside_models <- plotting_data$Model[plotting_data$Empirical_Within_CI]
  outside_models <- plotting_data$Model[!plotting_data$Empirical_Within_CI]
  

  cat("\n\n**Models whose confidence intervals contain the empirical ROH frequency for", hotspot_name, ":**\n\n")

  if (length(inside_models) == 0) {
    cat("No models had confidence intervals containing the empirical ROH frequency.")
  } else {
    print(inside_models)
  }
  
  cat("\n\n**Models in which the empirical ROH frequency, for",hotspot_name, ", falls outside the confidence interval:**\n\n")
  if (length(outside_models) == 0) {
    cat("None – the empirical ROH frequency is within all confidence intervals of the simulated models.")
  } else {
    print(outside_models)
  }
  
  
  
}


Hotspot_windows_sel_strength_test <- Hotspots_and_Causative_windows_comparison[grepl("Hotspot", Hotspots_and_Causative_windows_comparison$Model), ]

# Sort the data frame by the lowest H_e value (increasing order)
Hotspot_windows_sel_strength_test <- Hotspot_windows_sel_strength_test[order(Hotspot_windows_sel_strength_test$H_e), ]

# Loop through each hotspot and generate plots
for (i in 1:nrow(Hotspot_windows_sel_strength_test)) {
  hotspot_name <- tools::toTitleCase(Hotspot_windows_sel_strength_test$Model[i])
  empirical_value <- Hotspot_windows_sel_strength_test$ROH_Freq[i]
  generate_roh_freq_plot(hotspot_name, empirical_value)
  display_roh_freq_plot(hotspot_name, empirical_value)
}
```
